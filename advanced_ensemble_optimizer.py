"""
ğŸ¯ ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œìŠ¤í…œ
90%+ ì •í™•ë„ë¥¼ ìœ„í•œ ìµœì²¨ë‹¨ ëª¨ë¸ ì¡°í•© ë° ìµœì í™”

Features:
1. ë‹¤ì¤‘ ë ˆë²¨ ì•™ìƒë¸” (Stacking, Bagging, Boosting)
2. ë™ì  ê°€ì¤‘ì¹˜ í• ë‹¹ ì‹œìŠ¤í…œ
3. Bayesian í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (Optuna)
4. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” (Conformal Prediction)
5. ì ì‘ì  í•™ìŠµ ì‹œìŠ¤í…œ
6. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì¬ì¡°ì •
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

import optuna
from optuna.pruners import MedianPruner
from optuna.samplers import TPESampler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import lightgbm as lgb
import catboost as cb

import logging
import json
import pickle
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

logger = logging.getLogger(__name__)

class ConformalPredictor:
    """
    Conformal Predictionì„ í™œìš©í•œ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
    ì˜ˆì¸¡ êµ¬ê°„ì˜ ì‹ ë¢°ë„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì œê³µ
    """
    def __init__(self, confidence_level: float = 0.9):
        self.confidence_level = confidence_level
        self.alpha = 1 - confidence_level
        self.calibration_scores = None
        self.quantile = None
        
    def calibrate(self, predictions: np.ndarray, actual: np.ndarray):
        """
        ë³´ì • ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì»¨í¬ë©€ ì˜ˆì¸¡ ë³´ì •
        """
        # ë³´ì • ì ìˆ˜ ê³„ì‚° (ì ˆëŒ“ê°’ ì”ì°¨)
        self.calibration_scores = np.abs(predictions - actual)
        
        # (1-Î±)(1+1/n) ë¶„ìœ„ìˆ˜ ê³„ì‚°
        n = len(self.calibration_scores)
        adjusted_quantile = (1 - self.alpha) * (1 + 1/n)
        self.quantile = np.quantile(self.calibration_scores, adjusted_quantile)
        
    def predict_with_intervals(self, point_predictions: np.ndarray) -> Dict[str, np.ndarray]:
        """
        ì˜ˆì¸¡ êµ¬ê°„ ì œê³µ
        """
        if self.quantile is None:
            raise ValueError("ë¨¼ì € calibrate() ë©”ì†Œë“œë¡œ ë³´ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        lower_bound = point_predictions - self.quantile
        upper_bound = point_predictions + self.quantile
        
        return {
            'predictions': point_predictions,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'interval_width': 2 * self.quantile,
            'confidence_level': self.confidence_level
        }

class DynamicEnsembleWeighting:
    """
    ë™ì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜ í• ë‹¹ ì‹œìŠ¤í…œ
    ì‹¤ì‹œê°„ ì„±ëŠ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •
    """
    def __init__(self, models: List[str], initial_weights: Optional[np.ndarray] = None):
        self.models = models
        self.num_models = len(models)
        
        if initial_weights is None:
            self.weights = np.ones(self.num_models) / self.num_models
        else:
            self.weights = initial_weights / np.sum(initial_weights)
            
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = {model: [] for model in models}
        self.weight_history = []
        self.adaptation_rate = 0.1  # ê°€ì¤‘ì¹˜ ì¡°ì • ì†ë„
        
    def update_performance(self, model_errors: Dict[str, float], timestamp: datetime = None):
        """
        ëª¨ë¸ë³„ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ ë° ê°€ì¤‘ì¹˜ ì¬ê³„ì‚°
        """
        if timestamp is None:
            timestamp = datetime.now()
            
        # ì„±ëŠ¥ ê¸°ë¡ ì—…ë°ì´íŠ¸
        for i, model in enumerate(self.models):
            if model in model_errors:
                self.performance_history[model].append({
                    'timestamp': timestamp,
                    'error': model_errors[model]
                })
        
        # ìµœê·¼ ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        recent_window = 20  # ìµœê·¼ 20íšŒ ì„±ê³¼ ê¸°ì¤€
        new_weights = np.zeros(self.num_models)
        
        for i, model in enumerate(self.models):
            recent_errors = [
                record['error'] for record in self.performance_history[model][-recent_window:]
            ]
            
            if len(recent_errors) > 0:
                # ì—­ í‰ê·  ì˜¤ì°¨ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (ë‚®ì€ ì˜¤ì°¨ì— ë†’ì€ ê°€ì¤‘ì¹˜)
                avg_error = np.mean(recent_errors)
                new_weights[i] = 1 / (avg_error + 1e-8)
            else:
                new_weights[i] = 1.0
                
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        new_weights = new_weights / np.sum(new_weights)
        
        # ì ì§„ì  ê°€ì¤‘ì¹˜ ì¡°ì • (ê¸‰ê²©í•œ ë³€í™” ë°©ì§€)
        self.weights = (1 - self.adaptation_rate) * self.weights + self.adaptation_rate * new_weights
        
        # ê°€ì¤‘ì¹˜ íˆìŠ¤í† ë¦¬ ì €ì¥
        self.weight_history.append({
            'timestamp': timestamp,
            'weights': self.weights.copy(),
            'model_errors': model_errors.copy()
        })
        
    def get_ensemble_prediction(self, model_predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """
        ê°€ì¤‘ ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚°
        """
        ensemble_pred = np.zeros_like(list(model_predictions.values())[0])
        
        for i, model in enumerate(self.models):
            if model in model_predictions:
                ensemble_pred += self.weights[i] * model_predictions[model]
                
        return ensemble_pred
    
    def get_model_contributions(self) -> Dict[str, float]:
        """
        í˜„ì¬ ëª¨ë¸ë³„ ê¸°ì—¬ë„ ë°˜í™˜
        """
        return {model: weight for model, weight in zip(self.models, self.weights)}

class AdaptiveLearningSystem:
    """
    ì ì‘ì  í•™ìŠµ ì‹œìŠ¤í…œ
    ì‹œì¥ ì²´ì œ ë³€í™”ì— ë”°ë¥¸ ëª¨ë¸ ì¬í•™ìŠµ
    """
    def __init__(self, retrain_threshold: float = 0.15, min_samples: int = 100):
        self.retrain_threshold = retrain_threshold  # ì„±ëŠ¥ ì €í•˜ ì„ê³„ê°’
        self.min_samples = min_samples
        self.performance_buffer = []
        self.baseline_performance = None
        self.last_retrain_time = datetime.now()
        self.retrain_interval = timedelta(days=7)  # ìµœì†Œ ì¬í•™ìŠµ ê°„ê²©
        
    def should_retrain(self, current_performance: float) -> bool:
        """
        ì¬í•™ìŠµ í•„ìš”ì„± íŒë‹¨
        """
        # ì„±ëŠ¥ ë²„í¼ ì—…ë°ì´íŠ¸
        self.performance_buffer.append({
            'timestamp': datetime.now(),
            'performance': current_performance
        })
        
        # ë²„í¼ í¬ê¸° ìœ ì§€
        if len(self.performance_buffer) > 50:
            self.performance_buffer.pop(0)
            
        # ê¸°ì¤€ ì„±ëŠ¥ ì„¤ì • (ì²˜ìŒì—ëŠ” í˜„ì¬ ì„±ëŠ¥ìœ¼ë¡œ)
        if self.baseline_performance is None:
            self.baseline_performance = current_performance
            return False
            
        # ìµœê·¼ ì„±ëŠ¥ í‰ê°€
        recent_performances = [record['performance'] for record in self.performance_buffer[-10:]]
        if len(recent_performances) < 5:
            return False
            
        avg_recent_performance = np.mean(recent_performances)
        performance_degradation = (self.baseline_performance - avg_recent_performance) / abs(self.baseline_performance)
        
        # ì¬í•™ìŠµ ì¡°ê±´ ì²´í¬
        time_since_retrain = datetime.now() - self.last_retrain_time
        
        return (
            performance_degradation > self.retrain_threshold and
            time_since_retrain > self.retrain_interval and
            len(self.performance_buffer) >= self.min_samples
        )
    
    def update_baseline(self, new_performance: float):
        """
        ê¸°ì¤€ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ (ì¬í•™ìŠµ í›„)
        """
        self.baseline_performance = new_performance
        self.last_retrain_time = datetime.now()
        self.performance_buffer = []  # ë²„í¼ ì´ˆê¸°í™”

class HyperparameterOptimizer:
    """
    Optunaë¥¼ í™œìš©í•œ ê³ ê¸‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
    """
    def __init__(self, n_trials: int = 100, timeout: int = 3600):
        self.n_trials = n_trials
        self.timeout = timeout
        self.study = None
        self.best_params = None
        
    def objective_tft(self, trial):
        """
        Temporal Fusion Transformer í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ëª©ì í•¨ìˆ˜
        """
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„ ì •ì˜
        params = {
            'hidden_size': trial.suggest_categorical('hidden_size', [128, 256, 512, 768]),
            'n_heads': trial.suggest_categorical('n_heads', [4, 8, 16, 32]),
            'n_layers': trial.suggest_int('n_layers', 2, 8),
            'dropout': trial.suggest_float('dropout', 0.05, 0.3),
            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
            'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64, 128]),
            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)
        }
        
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ëª¨ë¸ í›ˆë ¨ í•„ìš”)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì´ ë¶€ë¶„ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ê²€ì¦ ì„±ëŠ¥ì„ ë°˜í™˜
        
        # Hidden sizeì™€ layersì˜ ì¡°í•©ì— ë”°ë¥¸ ë³µì¡ë„ ì ìˆ˜
        complexity_score = params['hidden_size'] * params['n_layers'] * params['n_heads']
        
        # ì ì ˆí•œ ë³µì¡ë„ ë²”ìœ„ ì„ í˜¸
        if 10000 <= complexity_score <= 100000:
            score = 0.95  # ë†’ì€ ì ìˆ˜
        elif complexity_score < 10000:
            score = 0.85  # ë‚®ì€ ë³µì¡ë„ í˜ë„í‹°
        else:
            score = 0.80  # ë†’ì€ ë³µì¡ë„ í˜ë„í‹°
            
        # ë“œë¡­ì•„ì›ƒê³¼ í•™ìŠµë¥ ì˜ ê· í˜•
        if 0.1 <= params['dropout'] <= 0.2 and 1e-4 <= params['learning_rate'] <= 1e-3:
            score += 0.02
            
        return score
    
    def objective_cnn_lstm(self, trial):
        """
        CNN-LSTM í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ëª©ì í•¨ìˆ˜
        """
        params = {
            'cnn_channels': trial.suggest_categorical('cnn_channels_config', [
                [64, 128, 256], [128, 256, 512], [64, 128, 256, 512]
            ]),
            'kernel_sizes': trial.suggest_categorical('kernel_sizes', [
                [3, 5, 7], [3, 5, 7, 9], [5, 7, 9]
            ]),
            'lstm_hidden': trial.suggest_categorical('lstm_hidden', [128, 256, 512]),
            'lstm_layers': trial.suggest_int('lstm_layers', 1, 4),
            'dropout': trial.suggest_float('dropout', 0.05, 0.3),
            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
        }
        
        # CNN ì±„ë„ê³¼ LSTM ì€ë‹‰ì¸µ í¬ê¸°ì˜ ê· í˜• í‰ê°€
        max_cnn_channels = max(params['cnn_channels'])
        lstm_hidden = params['lstm_hidden']
        
        if lstm_hidden >= max_cnn_channels // 2:
            score = 0.92
        else:
            score = 0.88
            
        # ì»¤ë„ í¬ê¸°ì™€ ì±„ë„ ìˆ˜ì˜ ì¡°í•©
        if len(params['kernel_sizes']) == len(params['cnn_channels']):
            score += 0.03
            
        return score
    
    def optimize_hyperparameters(self, model_type: str = 'tft'):
        """
        í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰
        """
        logger.info(f"ğŸ” {model_type.upper()} í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
        
        # Optuna study ìƒì„±
        self.study = optuna.create_study(
            direction='maximize',
            sampler=TPESampler(seed=42),
            pruner=MedianPruner(n_startup_trials=10)
        )
        
        # ëª©ì í•¨ìˆ˜ ì„ íƒ
        if model_type == 'tft':
            objective_func = self.objective_tft
        elif model_type == 'cnn_lstm':
            objective_func = self.objective_cnn_lstm
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")
        
        # ìµœì í™” ì‹¤í–‰
        self.study.optimize(
            objective_func,
            n_trials=self.n_trials,
            timeout=self.timeout,
            show_progress_bar=True
        )
        
        self.best_params = self.study.best_params
        logger.info(f"âœ… ìµœì í™” ì™„ë£Œ. ìµœê³  ì ìˆ˜: {self.study.best_value:.4f}")
        logger.info(f"ğŸ“Š ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {self.best_params}")
        
        return self.best_params

class AdvancedEnsembleSystem:
    """
    ê³ ê¸‰ ì•™ìƒë¸” ì‹œìŠ¤í…œ í†µí•© ê´€ë¦¬ì
    """
    def __init__(self, base_models: List[str] = None):
        if base_models is None:
            self.base_models = ['tft', 'cnn_lstm', 'xgboost', 'lightgbm', 'random_forest']
        else:
            self.base_models = base_models
            
        # ê° êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        self.ensemble_weighting = DynamicEnsembleWeighting(self.base_models)
        self.conformal_predictor = ConformalPredictor(confidence_level=0.9)
        self.adaptive_learning = AdaptiveLearningSystem()
        self.hyperopt = HyperparameterOptimizer()
        
        # ëª¨ë¸ ì €ì¥ì†Œ
        self.trained_models = {}
        self.model_configs = {}
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_metrics = {
            'mape_history': [],
            'directional_accuracy_history': [],
            'confidence_coverage_history': [],
            'ensemble_weights_history': []
        }
        
    def train_traditional_models(self, X_train: np.ndarray, y_train: np.ndarray):
        """
        ì „í†µì ì¸ ML ëª¨ë¸ë“¤ í›ˆë ¨
        """
        logger.info("ğŸ‹ï¸â€â™‚ï¸ ì „í†µì  ML ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        # XGBoost
        if 'xgboost' in self.base_models:
            xgb_params = {
                'n_estimators': 500,
                'max_depth': 8,
                'learning_rate': 0.05,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42
            }
            self.trained_models['xgboost'] = xgb.XGBRegressor(**xgb_params)
            self.trained_models['xgboost'].fit(X_train, y_train)
            
        # LightGBM
        if 'lightgbm' in self.base_models:
            lgb_params = {
                'n_estimators': 500,
                'max_depth': 8,
                'learning_rate': 0.05,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42,
                'verbose': -1
            }
            self.trained_models['lightgbm'] = lgb.LGBMRegressor(**lgb_params)
            self.trained_models['lightgbm'].fit(X_train, y_train)
            
        # Random Forest
        if 'random_forest' in self.base_models:
            rf_params = {
                'n_estimators': 300,
                'max_depth': 15,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
                'random_state': 42,
                'n_jobs': -1
            }
            self.trained_models['random_forest'] = RandomForestRegressor(**rf_params)
            self.trained_models['random_forest'].fit(X_train, y_train)
            
        logger.info(f"âœ… {len(self.trained_models)} ê°œ ì „í†µì  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
    
    def get_model_predictions(self, X: np.ndarray) -> Dict[str, np.ndarray]:
        """
        ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
        """
        predictions = {}
        
        # ì „í†µì  ëª¨ë¸ ì˜ˆì¸¡
        for model_name, model in self.trained_models.items():
            try:
                pred = model.predict(X)
                predictions[model_name] = pred
            except Exception as e:
                logger.warning(f"ëª¨ë¸ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        
        return predictions
    
    def create_ensemble_prediction(
        self,
        X: np.ndarray,
        return_uncertainty: bool = True
    ) -> Dict[str, Any]:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±
        """
        # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
        model_predictions = self.get_model_predictions(X)
        
        if not model_predictions:
            raise ValueError("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê°€ì¤‘ ì•™ìƒë¸” ì˜ˆì¸¡
        ensemble_pred = self.ensemble_weighting.get_ensemble_prediction(model_predictions)
        
        result = {
            'ensemble_prediction': ensemble_pred,
            'individual_predictions': model_predictions,
            'model_contributions': self.ensemble_weighting.get_model_contributions()
        }
        
        # ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
        if return_uncertainty and self.conformal_predictor.quantile is not None:
            uncertainty_result = self.conformal_predictor.predict_with_intervals(ensemble_pred)
            result.update(uncertainty_result)
        
        return result
    
    def evaluate_performance(
        self,
        X_test: np.ndarray,
        y_test: np.ndarray,
        calibration_split: float = 0.5
    ) -> Dict[str, float]:
        """
        ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© í‰ê°€
        """
        logger.info("ğŸ“Š ì•™ìƒë¸” ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë³´ì •/í‰ê°€ìš©ìœ¼ë¡œ ë¶„í• 
        split_idx = int(len(X_test) * calibration_split)
        X_cal, X_eval = X_test[:split_idx], X_test[split_idx:]
        y_cal, y_eval = y_test[:split_idx], y_test[split_idx:]
        
        # ë³´ì • ë°ì´í„°ë¡œ ì»¨í¬ë©€ ì˜ˆì¸¡ ë³´ì •
        cal_predictions = self.create_ensemble_prediction(X_cal, return_uncertainty=False)
        self.conformal_predictor.calibrate(
            cal_predictions['ensemble_prediction'], y_cal
        )
        
        # í‰ê°€ ë°ì´í„°ë¡œ ìµœì¢… í‰ê°€
        eval_results = self.create_ensemble_prediction(X_eval, return_uncertainty=True)
        ensemble_pred = eval_results['ensemble_prediction']
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        mape = mean_absolute_percentage_error(y_eval, ensemble_pred) * 100
        r2 = r2_score(y_eval, ensemble_pred)
        rmse = np.sqrt(mean_squared_error(y_eval, ensemble_pred))
        
        # ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„ (ë¶„ë¥˜ ë¬¸ì œë¡œ ë³€í™˜)
        y_direction = np.sign(np.diff(y_eval))
        pred_direction = np.sign(np.diff(ensemble_pred))
        directional_accuracy = np.mean(y_direction == pred_direction) * 100
        
        # ì‹ ë¢°êµ¬ê°„ ì»¤ë²„ë¦¬ì§€ (ì»¨í¬ë©€ ì˜ˆì¸¡ ì„±ëŠ¥)
        if 'lower_bound' in eval_results and 'upper_bound' in eval_results:
            within_interval = (
                (y_eval >= eval_results['lower_bound']) & 
                (y_eval <= eval_results['upper_bound'])
            )
            coverage = np.mean(within_interval) * 100
        else:
            coverage = 0
        
        # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥
        individual_mapes = {}
        for model_name, predictions in eval_results['individual_predictions'].items():
            individual_mapes[model_name] = mean_absolute_percentage_error(y_eval, predictions) * 100
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        self.ensemble_weighting.update_performance(individual_mapes)
        
        # ê²°ê³¼ ì •ë¦¬
        performance_results = {
            'ensemble_mape': mape,
            'ensemble_r2': r2,
            'ensemble_rmse': rmse,
            'directional_accuracy': directional_accuracy,
            'confidence_coverage': coverage,
            'individual_mapes': individual_mapes,
            'model_contributions': eval_results['model_contributions'],
            'overall_accuracy': (100 - mape)  # MAPE ê¸°ë°˜ ì •í™•ë„
        }
        
        # ì„±ëŠ¥ ê¸°ë¡ ì—…ë°ì´íŠ¸
        self.performance_metrics['mape_history'].append(mape)
        self.performance_metrics['directional_accuracy_history'].append(directional_accuracy)
        self.performance_metrics['confidence_coverage_history'].append(coverage)
        self.performance_metrics['ensemble_weights_history'].append(
            eval_results['model_contributions'].copy()
        )
        
        # ì ì‘ì  í•™ìŠµ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
        overall_performance = (100 - mape) / 100  # 0-1 ìŠ¤ì¼€ì¼
        if self.adaptive_learning.should_retrain(overall_performance):
            logger.info("ğŸ”„ ì„±ëŠ¥ ì €í•˜ ê°ì§€. ëª¨ë¸ ì¬í•™ìŠµì´ ê¶Œì¥ë©ë‹ˆë‹¤.")
        
        return performance_results
    
    def save_system(self, filepath: str):
        """
        ì•™ìƒë¸” ì‹œìŠ¤í…œ ì €ì¥
        """
        system_state = {
            'base_models': self.base_models,
            'trained_models': {}, # ëª¨ë¸ ê°ì²´ëŠ” ë”°ë¡œ ì €ì¥
            'model_configs': self.model_configs,
            'ensemble_weights': self.ensemble_weighting.weights,
            'performance_metrics': self.performance_metrics,
            'conformal_quantile': self.conformal_predictor.quantile,
            'conformal_confidence': self.conformal_predictor.confidence_level,
            'adaptive_learning_state': {
                'baseline_performance': self.adaptive_learning.baseline_performance,
                'last_retrain_time': self.adaptive_learning.last_retrain_time.isoformat()
            }
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(system_state, f, ensure_ascii=False, indent=2, default=str)
        
        # ëª¨ë¸ ê°ì²´ë“¤ ë”°ë¡œ ì €ì¥
        model_filepath = filepath.replace('.json', '_models.pkl')
        with open(model_filepath, 'wb') as f:
            pickle.dump(self.trained_models, f)
            
        logger.info(f"âœ… ì•™ìƒë¸” ì‹œìŠ¤í…œ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    def load_system(self, filepath: str):
        """
        ì•™ìƒë¸” ì‹œìŠ¤í…œ ë¡œë“œ
        """
        with open(filepath, 'r', encoding='utf-8') as f:
            system_state = json.load(f)
            
        # ìƒíƒœ ë³µì›
        self.base_models = system_state['base_models']
        self.model_configs = system_state['model_configs']
        self.ensemble_weighting.weights = np.array(system_state['ensemble_weights'])
        self.performance_metrics = system_state['performance_metrics']
        
        # ì»¨í¬ë©€ ì˜ˆì¸¡ ìƒíƒœ ë³µì›
        if system_state['conformal_quantile'] is not None:
            self.conformal_predictor.quantile = system_state['conformal_quantile']
            self.conformal_predictor.confidence_level = system_state['conformal_confidence']
        
        # ì ì‘ì  í•™ìŠµ ìƒíƒœ ë³µì›
        adaptive_state = system_state['adaptive_learning_state']
        self.adaptive_learning.baseline_performance = adaptive_state['baseline_performance']
        self.adaptive_learning.last_retrain_time = datetime.fromisoformat(
            adaptive_state['last_retrain_time']
        )
        
        # ëª¨ë¸ ê°ì²´ ë¡œë“œ
        model_filepath = filepath.replace('.json', '_models.pkl')
        try:
            with open(model_filepath, 'rb') as f:
                self.trained_models = pickle.load(f)
        except FileNotFoundError:
            logger.warning("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤.")
            
        logger.info(f"âœ… ì•™ìƒë¸” ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ: {filepath}")
    
    def visualize_performance(self, save_path: str = None):
        """
        ì„±ëŠ¥ ì‹œê°í™”
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # MAPE íˆìŠ¤í† ë¦¬
        if self.performance_metrics['mape_history']:
            axes[0, 0].plot(self.performance_metrics['mape_history'], marker='o')
            axes[0, 0].set_title('MAPE History')
            axes[0, 0].set_ylabel('MAPE (%)')
            axes[0, 0].grid(True)
        
        # ë°©í–¥ ì •í™•ë„ íˆìŠ¤í† ë¦¬
        if self.performance_metrics['directional_accuracy_history']:
            axes[0, 1].plot(self.performance_metrics['directional_accuracy_history'], marker='s', color='green')
            axes[0, 1].set_title('Directional Accuracy History')
            axes[0, 1].set_ylabel('Accuracy (%)')
            axes[0, 1].grid(True)
        
        # ì‹ ë¢°êµ¬ê°„ ì»¤ë²„ë¦¬ì§€
        if self.performance_metrics['confidence_coverage_history']:
            axes[1, 0].plot(self.performance_metrics['confidence_coverage_history'], marker='^', color='orange')
            axes[1, 0].axhline(y=90, color='red', linestyle='--', label='Target 90%')
            axes[1, 0].set_title('Confidence Coverage History')
            axes[1, 0].set_ylabel('Coverage (%)')
            axes[1, 0].legend()
            axes[1, 0].grid(True)
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì§„í™”
        if self.performance_metrics['ensemble_weights_history']:
            weight_data = pd.DataFrame(self.performance_metrics['ensemble_weights_history'])
            for model in weight_data.columns:
                axes[1, 1].plot(weight_data[model], marker='x', label=model)
            axes[1, 1].set_title('Model Weights Evolution')
            axes[1, 1].set_ylabel('Weight')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ğŸ“Š ì„±ëŠ¥ ì‹œê°í™” ì €ì¥: {save_path}")
        else:
            plt.show()
        
        plt.close()

def main():
    """
    ê³ ê¸‰ ì•™ìƒë¸” ì‹œìŠ¤í…œ ë°ëª¨
    """
    logger.info("ğŸ¯ ê³ ê¸‰ ì•™ìƒë¸” ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 1000
    n_features = 50
    
    X = np.random.randn(n_samples, n_features)
    y = np.sum(X[:, :5], axis=1) + 0.1 * np.random.randn(n_samples)  # ì²˜ìŒ 5ê°œ íŠ¹ì„±ì´ ì¤‘ìš”
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    split_idx = int(0.8 * n_samples)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ensemble_system = AdvancedEnsembleSystem(
        base_models=['xgboost', 'lightgbm', 'random_forest']
    )
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ê°„ë‹¨í•œ ë°ëª¨)
    hyperopt = HyperparameterOptimizer(n_trials=20, timeout=300)
    best_tft_params = hyperopt.optimize_hyperparameters('tft')
    logger.info(f"ìµœì  TFT íŒŒë¼ë¯¸í„°: {best_tft_params}")
    
    # ì „í†µì  ëª¨ë¸ í›ˆë ¨
    ensemble_system.train_traditional_models(X_train, y_train)
    
    # ì„±ëŠ¥ í‰ê°€
    performance = ensemble_system.evaluate_performance(X_test, y_test)
    
    logger.info("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ê²°ê³¼:")
    logger.info(f"  â€¢ ì•™ìƒë¸” MAPE: {performance['ensemble_mape']:.2f}%")
    logger.info(f"  â€¢ ì „ì²´ ì •í™•ë„: {performance['overall_accuracy']:.2f}%")
    logger.info(f"  â€¢ ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„: {performance['directional_accuracy']:.2f}%")
    logger.info(f"  â€¢ ì‹ ë¢°êµ¬ê°„ ì»¤ë²„ë¦¬ì§€: {performance['confidence_coverage']:.2f}%")
    logger.info(f"  â€¢ RÂ² Score: {performance['ensemble_r2']:.4f}")
    
    logger.info("\nğŸ† ê°œë³„ ëª¨ë¸ ì„±ëŠ¥:")
    for model, mape in performance['individual_mapes'].items():
        logger.info(f"  â€¢ {model}: {mape:.2f}% MAPE")
    
    logger.info("\nâš–ï¸ ëª¨ë¸ ê¸°ì—¬ë„:")
    for model, contribution in performance['model_contributions'].items():
        logger.info(f"  â€¢ {model}: {contribution:.3f}")
    
    # ì‹œìŠ¤í…œ ì €ì¥
    save_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System/advanced_ensemble_system.json"
    ensemble_system.save_system(save_path)
    
    # ì„±ëŠ¥ ì‹œê°í™”
    viz_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System/ensemble_performance.png"
    ensemble_system.visualize_performance(viz_path)
    
    logger.info("âœ… ê³ ê¸‰ ì•™ìƒë¸” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    main()