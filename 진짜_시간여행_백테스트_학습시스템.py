#!/usr/bin/env python3
"""
ğŸ•°ï¸ ì§„ì§œ ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‹œìŠ¤í…œ
- ê³¼ê±° ì‹œì ìœ¼ë¡œ ëŒì•„ê°€ì„œ ì˜ˆì¸¡ â†’ ì‹¤ì œê°’ ë¹„êµ â†’ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ â†’ í•™ìŠµ
- ëŒë°œë³€ìˆ˜ ì˜í–¥ë„ ë¶„ì„ ë° ì‹¤ì‹œê°„ ê°ì‹œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
- 100%ì— ê°€ê¹Œìš´ ì˜ˆì¸¡ ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•œ ì§€ì†ì  í•™ìŠµ
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import warnings
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')

class TimeravelBacktestLearningSystem:
    """ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.data_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.historical_data = None
        self.prediction_errors = []
        self.error_analysis = {}
        self.shock_variables = {}
        self.learning_progress = {}
        self.current_accuracy = 0.0
        self.target_accuracy = 99.0  # 100%ì— ê°€ê¹Œìš´ ëª©í‘œ
        
        # ëŒë°œë³€ìˆ˜ ì¹´í…Œê³ ë¦¬
        self.shock_categories = {
            'regulatory': ['SECê²°ì •', 'ê°êµ­ê·œì œ', 'ë²•ì ì´ìŠˆ'],
            'institutional': ['ê¸°ê´€ë§¤ìˆ˜', 'ê¸°ê´€ë§¤ë„', 'ETFì†Œì‹'],
            'technical': ['í•´í‚¹', 'ë„¤íŠ¸ì›Œí¬ì¥ì• ', 'ì—…ê·¸ë ˆì´ë“œ'], 
            'macro': ['ê¸ˆë¦¬ë³€í™”', 'ë‹¬ëŸ¬ê°•ì„¸', 'ê²½ì œìœ„ê¸°'],
            'social': ['ì¼ë¡ ë¨¸ìŠ¤í¬', 'ì†Œì…œë¯¸ë””ì–´', 'ì–¸ë¡ ë³´ë„']
        }
        
        print("ğŸ•°ï¸ ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        
    def load_historical_data(self) -> bool:
        """3ê°œì›”ì¹˜ í†µí•© ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“‚ 3ê°œì›”ì¹˜ í†µí•© ë°ì´í„° ë¡œë”©...")
        
        try:
            # AI ìµœì í™”ëœ 3ê°œì›” ë°ì´í„°
            csv_path = os.path.join(self.data_path, "ai_optimized_3month_data", "ai_matrix_complete.csv")
            df = pd.read_csv(csv_path)
            
            # timestamp ì»¬ëŸ¼ ì°¾ê¸° ë° ì •ë ¬
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.sort_values('timestamp').reset_index(drop=True)
                print("âœ… timestampë¡œ ì‹œê³„ì—´ ì •ë ¬ ì™„ë£Œ")
            else:
                print("âš ï¸ timestamp ì—†ìŒ - ì›ë³¸ ìˆœì„œ ì‚¬ìš©")
            
            # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            self.historical_data = df[['timestamp'] + list(numeric_cols) if 'timestamp' in df.columns else list(numeric_cols)].copy()
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            self.historical_data = self.historical_data.fillna(method='ffill').fillna(method='bfill').fillna(0)
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.historical_data.shape}")
            print(f"ğŸ“… ê¸°ê°„: {len(self.historical_data)}ê°œ ì‹œì ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def identify_btc_price_column(self) -> str:
        """BTC ê°€ê²© ì»¬ëŸ¼ ì‹ë³„"""
        price_candidates = [
            'onchain_blockchain_info_network_stats_market_price_usd',
            'btc_price', 'price', 'close', 'market_price'
        ]
        
        for candidate in price_candidates:
            if candidate in self.historical_data.columns:
                return candidate
        
        # ì²« ë²ˆì§¸ ìˆ«ì ì»¬ëŸ¼ì„ ê°€ê²©ìœ¼ë¡œ ì‚¬ìš©
        numeric_cols = self.historical_data.select_dtypes(include=[np.number]).columns
        return numeric_cols[0]
    
    def timetravel_backtest(self, start_date_idx: int, prediction_hours: int = 72) -> Dict:
        """
        ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        Args:
            start_date_idx: ì‹œì‘ ì‹œì  ì¸ë±ìŠ¤
            prediction_hours: ì˜ˆì¸¡í•  ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„)
        """
        print(f"\nğŸ•°ï¸ ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print(f"   ğŸ“… ì‹œì‘ì : {start_date_idx}ë²ˆì§¸ ë°ì´í„°")
        print(f"   ğŸ¯ ì˜ˆì¸¡: {prediction_hours}ì‹œê°„ í›„")
        
        try:
            # 1ë‹¨ê³„: ê³¼ê±° ì‹œì ìœ¼ë¡œ ì´ë™
            historical_point = self.historical_data.iloc[:start_date_idx].copy()
            
            if len(historical_point) < 100:  # ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„° í•„ìš”
                return {'success': False, 'error': 'í•™ìŠµ ë°ì´í„° ë¶€ì¡±'}
            
            # 2ë‹¨ê³„: í•´ë‹¹ ì‹œì ì˜ ì§€í‘œë“¤ë¡œ ë¯¸ë˜ ì˜ˆì¸¡
            btc_col = self.identify_btc_price_column()
            
            # í”¼ì²˜ ì¤€ë¹„
            X_historical = historical_point.drop(columns=['timestamp'] if 'timestamp' in historical_point.columns else []).drop(columns=[btc_col])
            y_historical = historical_point[btc_col]
            
            # ì‹œê³„ì—´ í”¼ì²˜ ì¶”ê°€
            X_enhanced = self.add_timeseries_features(X_historical, y_historical)
            
            # íƒ€ê²Ÿ: prediction_hours ì‹œê°„ í›„ ê°€ê²©
            target_idx = start_date_idx + prediction_hours
            
            if target_idx >= len(self.historical_data):
                return {'success': False, 'error': 'ì˜ˆì¸¡ íƒ€ê²Ÿ ì‹œì ì´ ë°ì´í„° ë²”ìœ„ ì´ˆê³¼'}
            
            actual_future_price = self.historical_data.iloc[target_idx][btc_col]
            current_price = self.historical_data.iloc[start_date_idx][btc_col]
            
            # 3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ (ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©)
            y_target = y_historical.shift(-prediction_hours).dropna()
            X_target = X_enhanced.iloc[:-prediction_hours]
            
            if len(X_target) < 50:
                return {'success': False, 'error': 'íƒ€ê²Ÿ í•™ìŠµ ë°ì´í„° ë¶€ì¡±'}
            
            # ìŠ¤ì¼€ì¼ë§
            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(X_target)
            
            # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            models = {
                'rf': RandomForestRegressor(n_estimators=50, random_state=42),
                'gb': GradientBoostingRegressor(n_estimators=50, random_state=42)
            }
            
            predictions = {}
            for name, model in models.items():
                model.fit(X_scaled, y_target)
                # í˜„ì¬ ì‹œì  ë°ì´í„°ë¡œ ì˜ˆì¸¡
                current_features = X_enhanced.iloc[-1:].values
                current_scaled = scaler.transform(current_features)
                pred = model.predict(current_scaled)[0]
                predictions[name] = pred
            
            # ì•™ìƒë¸” ì˜ˆì¸¡
            final_prediction = (predictions['rf'] + predictions['gb']) / 2
            
            # 4ë‹¨ê³„: ì‹¤ì œê°’ê³¼ ë¹„êµ
            prediction_error = abs(actual_future_price - final_prediction)
            prediction_error_pct = (prediction_error / actual_future_price) * 100
            
            # 5ë‹¨ê³„: ì—ëŸ¬ ì›ì¸ ë¶„ì„
            error_analysis = self.analyze_prediction_error(
                start_date_idx, target_idx, final_prediction, actual_future_price
            )
            
            result = {
                'success': True,
                'start_idx': start_date_idx,
                'target_idx': target_idx,
                'current_price': current_price,
                'predicted_price': final_prediction,
                'actual_price': actual_future_price,
                'error_absolute': prediction_error,
                'error_percentage': prediction_error_pct,
                'error_analysis': error_analysis,
                'model_predictions': predictions
            }
            
            # ì—ëŸ¬ ê¸°ë¡ ì €ì¥
            self.prediction_errors.append(result)
            
            return result
            
        except Exception as e:
            print(f"âŒ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    def add_timeseries_features(self, X: pd.DataFrame, price_series: pd.Series) -> pd.DataFrame:
        """ì‹œê³„ì—´ íŠ¹ì„± í”¼ì²˜ ì¶”ê°€"""
        X_enhanced = X.copy()
        
        # ê°€ê²© ê¸°ë°˜ í”¼ì²˜ë“¤
        X_enhanced['price_lag1'] = price_series.shift(1)
        X_enhanced['price_lag6'] = price_series.shift(6)
        X_enhanced['price_lag24'] = price_series.shift(24)
        
        X_enhanced['price_change_1h'] = price_series.pct_change(1) * 100
        X_enhanced['price_change_6h'] = price_series.pct_change(6) * 100
        X_enhanced['price_change_24h'] = price_series.pct_change(24) * 100
        
        X_enhanced['price_sma_12'] = price_series.rolling(12).mean()
        X_enhanced['price_sma_24'] = price_series.rolling(24).mean()
        X_enhanced['price_std_24'] = price_series.rolling(24).std()
        
        # NaN ì²˜ë¦¬
        X_enhanced = X_enhanced.fillna(method='bfill').fillna(0)
        
        return X_enhanced
    
    def analyze_prediction_error(self, start_idx: int, target_idx: int, 
                                prediction: float, actual: float) -> Dict:
        """ì˜ˆì¸¡ ì˜¤ë¥˜ ì›ì¸ ë¶„ì„"""
        
        # í•´ë‹¹ ê¸°ê°„ ë°ì´í„° ì¶”ì¶œ
        period_data = self.historical_data.iloc[start_idx:target_idx+1].copy()
        btc_col = self.identify_btc_price_column()
        
        analysis = {
            'error_magnitude': abs(actual - prediction),
            'error_direction': 'overpredict' if prediction > actual else 'underpredict',
            'price_volatility': period_data[btc_col].std(),
            'max_price_change': period_data[btc_col].max() - period_data[btc_col].min(),
            'potential_shock_events': []
        }
        
        # ê¸‰ê²©í•œ ë³€í™” ê°ì§€ (ì ì¬ì  ëŒë°œë³€ìˆ˜)
        price_changes = period_data[btc_col].pct_change().abs()
        shock_threshold = 0.05  # 5% ì´ìƒ ë³€í™”
        
        shock_points = price_changes[price_changes > shock_threshold]
        if len(shock_points) > 0:
            analysis['potential_shock_events'] = [
                {
                    'timestamp': period_data.iloc[idx]['timestamp'] if 'timestamp' in period_data.columns else f"index_{idx}",
                    'change_pct': change * 100,
                    'price_before': period_data.iloc[idx-1][btc_col] if idx > 0 else None,
                    'price_after': period_data.iloc[idx][btc_col]
                }
                for idx, change in shock_points.items()
            ]
        
        # ì§€í‘œë³„ ê¸°ì—¬ë„ ë¶„ì„ (ìƒìœ„ ë³€í™”ëŸ‰ ì§€í‘œë“¤)
        numeric_cols = period_data.select_dtypes(include=[np.number]).columns
        indicator_changes = {}
        
        for col in numeric_cols:
            if col != btc_col and len(period_data[col]) > 1:
                start_val = period_data[col].iloc[0]
                end_val = period_data[col].iloc[-1]
                if start_val != 0:
                    change_pct = abs((end_val - start_val) / start_val) * 100
                    indicator_changes[col] = change_pct
        
        # ìƒìœ„ 10ê°œ ë³€í™”ëŸ‰ ì§€í‘œ
        top_changed_indicators = sorted(indicator_changes.items(), 
                                      key=lambda x: x[1], reverse=True)[:10]
        analysis['top_changed_indicators'] = top_changed_indicators
        
        return analysis
    
    def run_massive_backtest(self, num_tests: int = 100) -> Dict:
        """ëŒ€ê·œëª¨ ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\nğŸš€ ëŒ€ê·œëª¨ ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"   ğŸ¯ í…ŒìŠ¤íŠ¸ íšŸìˆ˜: {num_tests}íšŒ")
        print("="*60)
        
        successful_tests = []
        failed_tests = []
        
        # ë°ì´í„° ë²”ìœ„ì—ì„œ ëœë¤í•˜ê²Œ ì‹œì‘ì  ì„ íƒ
        data_length = len(self.historical_data)
        prediction_hours = 72  # 3ì¼ í›„ ì˜ˆì¸¡
        
        valid_start_range = data_length - prediction_hours - 50  # ì¶©ë¶„í•œ ì—¬ìœ 
        
        for i in range(num_tests):
            start_idx = np.random.randint(100, valid_start_range)  # ìµœì†Œ 100ê°œ í•™ìŠµ ë°ì´í„°
            
            print(f"ğŸ” í…ŒìŠ¤íŠ¸ {i+1:3d}/{num_tests}: ì‹œì  {start_idx}", end="")
            
            result = self.timetravel_backtest(start_idx, prediction_hours)
            
            if result['success']:
                successful_tests.append(result)
                print(f" âœ… ì—ëŸ¬ {result['error_percentage']:.2f}%")
            else:
                failed_tests.append(result)
                print(f" âŒ {result.get('error', 'Unknown')}")
        
        # ê²°ê³¼ ë¶„ì„
        if successful_tests:
            errors = [test['error_percentage'] for test in successful_tests]
            avg_error = np.mean(errors)
            median_error = np.median(errors)
            std_error = np.std(errors)
            
            # ì •í™•ë„ ê³„ì‚° (ì—ëŸ¬ê°€ ì‘ì„ìˆ˜ë¡ ì •í™•ë„ ë†’ìŒ)
            accuracy = max(0, 100 - avg_error)
            
            print(f"\nğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
            print("="*50)
            print(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(successful_tests)}/{num_tests}")
            print(f"ğŸ“ˆ í‰ê·  ì—ëŸ¬ìœ¨: {avg_error:.2f}%")
            print(f"ğŸ“ˆ ì¤‘ê°„ ì—ëŸ¬ìœ¨: {median_error:.2f}%") 
            print(f"ğŸ“Š ì—ëŸ¬ í‘œì¤€í¸ì°¨: {std_error:.2f}%")
            print(f"ğŸ¯ ì¶”ì • ì •í™•ë„: {accuracy:.2f}%")
            
            self.current_accuracy = accuracy
            
            # ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
            self.analyze_error_patterns(successful_tests)
            
            # ëŒë°œë³€ìˆ˜ ì˜í–¥ë„ ë¶„ì„
            self.analyze_shock_variables(successful_tests)
            
        else:
            print("âŒ ëª¨ë“  ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            accuracy = 0
        
        summary = {
            'total_tests': num_tests,
            'successful_tests': len(successful_tests),
            'failed_tests': len(failed_tests),
            'accuracy': accuracy,
            'avg_error': avg_error if successful_tests else 100,
            'error_analysis': self.error_analysis,
            'shock_variables': self.shock_variables
        }
        
        # ê²°ê³¼ ì €ì¥
        self.save_learning_results(summary)
        
        return summary
    
    def analyze_error_patterns(self, test_results: List[Dict]):
        """ì—ëŸ¬ íŒ¨í„´ ë¶„ì„ - ì™œ í‹€ë ¸ëŠ”ê°€?"""
        print(f"\nğŸ” ì—ëŸ¬ íŒ¨í„´ ë¶„ì„")
        print("-"*40)
        
        # ì—ëŸ¬ í¬ê¸°ë³„ ë¶„ë¥˜
        small_errors = [t for t in test_results if t['error_percentage'] < 1]
        medium_errors = [t for t in test_results if 1 <= t['error_percentage'] < 5]
        large_errors = [t for t in test_results if t['error_percentage'] >= 5]
        
        print(f"ğŸ“Š ì†Œì—ëŸ¬ (<1%):   {len(small_errors)}ê±´")
        print(f"ğŸ“Š ì¤‘ì—ëŸ¬ (1-5%):  {len(medium_errors)}ê±´") 
        print(f"ğŸ“Š ëŒ€ì—ëŸ¬ (â‰¥5%):   {len(large_errors)}ê±´")
        
        # ëŒ€ì—ëŸ¬ ì‚¬ë¡€ ë¶„ì„
        if large_errors:
            print(f"\nğŸš¨ ëŒ€ì—ëŸ¬ ì‚¬ë¡€ ë¶„ì„:")
            for i, error in enumerate(large_errors[:3]):  # ìƒìœ„ 3ê°œë§Œ
                print(f"   {i+1}. ì—ëŸ¬ {error['error_percentage']:.1f}% - "
                      f"ëŒë°œì´ë²¤íŠ¸ {len(error['error_analysis']['potential_shock_events'])}ê±´")
        
        # ê³µí†µ ì‹¤íŒ¨ ì§€í‘œ ì°¾ê¸°
        all_changed_indicators = {}
        for test in large_errors:
            for indicator, change in test['error_analysis']['top_changed_indicators']:
                if indicator in all_changed_indicators:
                    all_changed_indicators[indicator] += change
                else:
                    all_changed_indicators[indicator] = change
        
        # ì‹¤íŒ¨ì™€ ê°€ì¥ ì—°ê´€ëœ ì§€í‘œë“¤
        problem_indicators = sorted(all_changed_indicators.items(), 
                                  key=lambda x: x[1], reverse=True)[:10]
        
        self.error_analysis = {
            'error_distribution': {
                'small': len(small_errors),
                'medium': len(medium_errors), 
                'large': len(large_errors)
            },
            'problem_indicators': problem_indicators,
            'avg_shock_events_per_large_error': np.mean([
                len(t['error_analysis']['potential_shock_events']) 
                for t in large_errors
            ]) if large_errors else 0
        }
        
        print(f"ğŸ“ˆ ë¬¸ì œ ì§€í‘œ TOP 5:")
        for i, (indicator, impact) in enumerate(problem_indicators[:5]):
            print(f"   {i+1}. {indicator[:50]}... (ì˜í–¥ë„: {impact:.1f})")
    
    def analyze_shock_variables(self, test_results: List[Dict]):
        """ëŒë°œë³€ìˆ˜ ì˜í–¥ë„ ë¶„ì„"""
        print(f"\nğŸ’¥ ëŒë°œë³€ìˆ˜ ì˜í–¥ë„ ë¶„ì„")
        print("-"*40)
        
        # ëŒë°œì´ë²¤íŠ¸ê°€ ìˆì—ˆë˜ í…ŒìŠ¤íŠ¸ë“¤ ë¶„ì„
        shock_tests = [t for t in test_results 
                      if len(t['error_analysis']['potential_shock_events']) > 0]
        
        no_shock_tests = [t for t in test_results 
                         if len(t['error_analysis']['potential_shock_events']) == 0]
        
        if shock_tests and no_shock_tests:
            shock_avg_error = np.mean([t['error_percentage'] for t in shock_tests])
            normal_avg_error = np.mean([t['error_percentage'] for t in no_shock_tests])
            
            print(f"ğŸ“Š ëŒë°œì´ë²¤íŠ¸ æœ‰: í‰ê·  ì—ëŸ¬ {shock_avg_error:.2f}% ({len(shock_tests)}ê±´)")
            print(f"ğŸ“Š ëŒë°œì´ë²¤íŠ¸ ç„¡: í‰ê·  ì—ëŸ¬ {normal_avg_error:.2f}% ({len(no_shock_tests)}ê±´)")
            print(f"ğŸ’¥ ëŒë°œë³€ìˆ˜ ì˜í–¥: +{shock_avg_error - normal_avg_error:.2f}% ì—ëŸ¬ ì¦ê°€")
            
            # ëŒë°œë³€ìˆ˜ ìœ„í—˜ë„ ë¶„ë¥˜
            shock_impact = shock_avg_error - normal_avg_error
            if shock_impact > 5:
                risk_level = "ğŸ”´ ê³ ìœ„í—˜"
            elif shock_impact > 2:
                risk_level = "ğŸŸ¡ ì¤‘ìœ„í—˜"
            else:
                risk_level = "ğŸŸ¢ ì €ìœ„í—˜"
            
            self.shock_variables = {
                'shock_impact_pct': shock_impact,
                'risk_level': risk_level,
                'shock_frequency': len(shock_tests) / len(test_results) * 100,
                'monitoring_priority': 'high' if shock_impact > 2 else 'medium'
            }
            
            print(f"ğŸ¯ ëŒë°œë³€ìˆ˜ ìœ„í—˜ë„: {risk_level}")
            print(f"ğŸ“Š ëŒë°œì´ë²¤íŠ¸ ë¹ˆë„: {self.shock_variables['shock_frequency']:.1f}%")
            
        else:
            print("ğŸ“Š ëŒë°œë³€ìˆ˜ ì˜í–¥ë„ ë¶„ì„ ë¶ˆê°€ (ë°ì´í„° ë¶€ì¡±)")
            self.shock_variables = {'analysis': 'insufficient_data'}
    
    def generate_monitoring_recommendations(self) -> Dict:
        """ì‹¤ì‹œê°„ ê°ì‹œ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        print(f"\nğŸ‘€ ì‹¤ì‹œê°„ ê°ì‹œ ê¶Œì¥ì‚¬í•­ ìƒì„±")
        print("-"*40)
        
        recommendations = {
            'critical_indicators': [],
            'shock_variables_to_monitor': [],
            'monitoring_frequency': {},
            'alert_thresholds': {}
        }
        
        # 1. ì¤‘ìš” ì§€í‘œ (ì—ëŸ¬ ë¶„ì„ ê¸°ë°˜)
        if hasattr(self, 'error_analysis') and 'problem_indicators' in self.error_analysis:
            top_indicators = self.error_analysis['problem_indicators'][:10]
            recommendations['critical_indicators'] = [
                {
                    'name': indicator,
                    'impact_score': impact,
                    'monitoring_priority': 'high' if impact > 50 else 'medium'
                }
                for indicator, impact in top_indicators
            ]
        
        # 2. ëŒë°œë³€ìˆ˜ ê°ì‹œ ë¦¬ìŠ¤íŠ¸
        if self.shock_variables.get('monitoring_priority') == 'high':
            recommendations['shock_variables_to_monitor'] = [
                {
                    'category': 'ê°€ê²© ê¸‰ë³€ë™',
                    'threshold': '5% ì´ìƒ 1ì‹œê°„ ë³€ë™',
                    'action': 'ì¦‰ì‹œ ì•Œë¦¼'
                },
                {
                    'category': 'ê±°ë˜ëŸ‰ ê¸‰ì¦',
                    'threshold': 'í‰ê·  ëŒ€ë¹„ 3ë°° ì´ìƒ',
                    'action': 'ì£¼ì˜ ê´€ì°°'
                },
                {
                    'category': 'ë‰´ìŠ¤/ì†Œì…œë¯¸ë””ì–´',
                    'threshold': 'ë¹„íŠ¸ì½”ì¸ ì–¸ê¸‰ëŸ‰ ê¸‰ì¦',
                    'action': 'ìˆ˜ë™ í™•ì¸'
                }
            ]
        
        # 3. ê°ì‹œ ë¹ˆë„
        recommendations['monitoring_frequency'] = {
            'price_data': '1ë¶„ë§ˆë‹¤',
            'technical_indicators': '5ë¶„ë§ˆë‹¤',
            'onchain_data': '1ì‹œê°„ë§ˆë‹¤',
            'news_sentiment': '30ë¶„ë§ˆë‹¤'
        }
        
        # 4. ì•Œë¦¼ ì„ê³„ê°’
        recommendations['alert_thresholds'] = {
            'prediction_confidence_drop': '95% ë¯¸ë§Œ',
            'unusual_market_activity': 'ì •ìƒ íŒ¨í„´ì—ì„œ 2Ïƒ ì´ìƒ ì´íƒˆ',
            'shock_variable_trigger': 'ì£¼ìš” ì§€í‘œ 10% ì´ìƒ ê¸‰ë³€'
        }
        
        print("âœ… ê°ì‹œ ê¶Œì¥ì‚¬í•­ ìƒì„± ì™„ë£Œ")
        print(f"   ğŸ¯ í•µì‹¬ ì§€í‘œ: {len(recommendations['critical_indicators'])}ê°œ")
        print(f"   ğŸ’¥ ëŒë°œë³€ìˆ˜: {len(recommendations['shock_variables_to_monitor'])}ê°œ")
        
        return recommendations
    
    def save_learning_results(self, summary: Dict):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        results = {
            'timestamp': timestamp,
            'summary': summary,
            'current_accuracy': self.current_accuracy,
            'target_accuracy': self.target_accuracy,
            'error_analysis': self.error_analysis,
            'shock_variables': self.shock_variables,
            'monitoring_recommendations': self.generate_monitoring_recommendations()
        }
        
        filename = f"timetravel_backtest_results_{timestamp}.json"
        filepath = os.path.join(self.data_path, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ í•™ìŠµ ê²°ê³¼ ì €ì¥: {filename}")
        return filepath
    
    def run_complete_learning_cycle(self):
        """ì™„ì „í•œ í•™ìŠµ ì‚¬ì´í´ ì‹¤í–‰"""
        print("ğŸš€ ì‹œê°„ì—¬í–‰ ë°±í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘")
        print("="*70)
        
        # 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
        if not self.load_historical_data():
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì¢…ë£Œ")
            return None
        
        # 2ë‹¨ê³„: ëŒ€ê·œëª¨ ë°±í…ŒìŠ¤íŠ¸
        summary = self.run_massive_backtest(num_tests=50)  # 50íšŒ í…ŒìŠ¤íŠ¸
        
        # 3ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥
        print(f"\n" + "="*70)
        print("ğŸ† ìµœì¢… í•™ìŠµ ê²°ê³¼")
        print("="*70)
        print(f"ğŸ¯ í˜„ì¬ ì •í™•ë„:     {self.current_accuracy:.2f}%")
        print(f"ğŸ¯ ëª©í‘œ ì •í™•ë„:     {self.target_accuracy:.2f}%")
        
        if self.current_accuracy >= self.target_accuracy:
            print("ğŸ‰ ëª©í‘œ ë‹¬ì„±!")
        else:
            needed = self.target_accuracy - self.current_accuracy
            print(f"âš ï¸ ì¶”ê°€ í•„ìš”:      +{needed:.2f}%")
        
        print(f"ğŸ’¥ ëŒë°œë³€ìˆ˜ ì˜í–¥:   +{self.shock_variables.get('shock_impact_pct', 0):.2f}% ì—ëŸ¬")
        print(f"ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ì„±ê³µ:   {summary['successful_tests']}/{summary['total_tests']}íšŒ")
        
        print("="*70)
        
        return summary

# ì‹¤í–‰ í•¨ìˆ˜
def main():
    system = TimeravelBacktestLearningSystem()
    return system.run_complete_learning_cycle()

if __name__ == "__main__":
    results = main()