#!/usr/bin/env python3
"""
ì²´ì œë³„ ì ì‘í˜• ëª¨ë¸ ì„ íƒ ë° ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
ê° ì‹œì¥ ì²´ì œì— ìµœì í™”ëœ ì˜ˆì¸¡ ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •

í•µì‹¬ ê¸°ëŠ¥:
1. ì²´ì œë³„ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ
2. ì‹¤ì‹œê°„ ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
3. ì²´ì œ ì „í™˜ì‹œ ëª¨ë¸ ìŠ¤ìœ„ì¹­
4. ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ìµœì í™”
5. ì„±ëŠ¥ ê¸°ë°˜ ëª¨ë¸ ìˆœìœ„ ì—…ë°ì´íŠ¸
"""

import os
import json
import sqlite3
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union, Any
import logging
from dataclasses import dataclass, asdict
import asyncio
import pickle
from collections import defaultdict, deque
import statistics
from abc import ABC, abstractmethod
import warnings
warnings.filterwarnings("ignore")

# ì„±ëŠ¥ ìµœì í™”
from concurrent.futures import ThreadPoolExecutor
import multiprocessing as mp

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ModelPerformanceMetrics:
    """ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ"""
    model_id: str
    regime_type: str
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    directional_accuracy: float
    profit_factor: float
    sharpe_ratio: float
    max_drawdown: float
    win_rate: float
    avg_return: float
    volatility_adjusted_return: float
    sample_size: int
    last_updated: datetime

@dataclass
class RegimeModelConfig:
    """ì²´ì œë³„ ëª¨ë¸ ì„¤ì •"""
    regime_type: str
    primary_model: str
    fallback_models: List[str]
    ensemble_weights: Dict[str, float]
    performance_threshold: float
    retraining_interval_days: int
    feature_importance_weights: Dict[str, float]
    risk_adjustment_factor: float

@dataclass
class PredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼"""
    regime_type: str
    prediction: Dict[str, Any]
    model_used: str
    confidence: float
    contributing_models: Dict[str, float]
    performance_score: float
    timestamp: datetime

class BaseRegimeModel(ABC):
    """ì²´ì œë³„ ëª¨ë¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model_id: str, regime_type: str):
        self.model_id = model_id
        self.regime_type = regime_type
        self.performance_history = deque(maxlen=1000)
        self.is_trained = False
        self.last_training_date = None
        
    @abstractmethod
    async def train(self, training_data: List[Dict]) -> Dict:
        """ëª¨ë¸ í•™ìŠµ"""
        pass
    
    @abstractmethod
    async def predict(self, features: np.ndarray) -> Dict:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        pass
    
    @abstractmethod
    def get_feature_importance(self) -> Dict[str, float]:
        """íŠ¹ì§• ì¤‘ìš”ë„ ë°˜í™˜"""
        pass
    
    def update_performance(self, actual: float, predicted: float, metadata: Dict = None):
        """ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        self.performance_history.append({
            'timestamp': datetime.now(),
            'actual': actual,
            'predicted': predicted,
            'error': abs(actual - predicted),
            'direction_correct': (actual - predicted) * (predicted - actual) >= 0,
            'metadata': metadata or {}
        })

class TrendFollowingModel(BaseRegimeModel):
    """íŠ¸ë Œë“œ ì¶”ì¢… ëª¨ë¸ (ê°•ì„¸ì¥ íŠ¹í™”)"""
    
    def __init__(self, model_id: str = "trend_following"):
        super().__init__(model_id, "BULL_MARKET")
        self.momentum_weights = {
            'price_trend_7d': 0.25,
            'price_trend_30d': 0.20,
            'rsi_14': 0.15,
            'volume_trend': 0.15,
            'macd_signal': 0.10,
            'bollinger_position': 0.10,
            'fear_greed_index': 0.05
        }
    
    async def train(self, training_data: List[Dict]) -> Dict:
        """íŠ¸ë Œë“œ ì¶”ì¢… ëª¨ë¸ í•™ìŠµ"""
        try:
            # ê°•ì„¸ì¥ ë°ì´í„°ë§Œ í•„í„°ë§
            bull_data = [d for d in training_data if d.get('regime') == 'BULL_MARKET']
            
            if len(bull_data) < 20:
                return {"error": "ê°•ì„¸ì¥ í•™ìŠµ ë°ì´í„° ë¶€ì¡±"}
            
            # ëª¨ë©˜í…€ ê¸°ë°˜ íŠ¹ì§• ê°€ì¤‘ì¹˜ ìµœì í™”
            features_array = []
            targets_array = []
            
            for data in bull_data:
                features = data.get('features', [])
                target = data.get('target')
                
                if len(features) >= 7 and target is not None:
                    # ëª¨ë©˜í…€ íŠ¹ì§•ë§Œ ì¶”ì¶œ
                    momentum_features = [
                        features[1],  # price_trend_7d
                        features[2],  # price_trend_30d  
                        features[11], # rsi_14
                        features[8],  # volume_trend
                        features[12], # macd_signal
                        features[13], # bollinger_position
                        features[20]  # fear_greed_index
                    ]
                    features_array.append(momentum_features)
                    targets_array.append(target)
            
            if len(features_array) < 10:
                return {"error": "ìœ íš¨í•œ íŠ¹ì§• ë°ì´í„° ë¶€ì¡±"}
            
            features_array = np.array(features_array)
            targets_array = np.array(targets_array)
            
            # ì„ í˜• íšŒê·€ë¡œ ìµœì  ê°€ì¤‘ì¹˜ ê³„ì‚°
            from sklearn.linear_model import Ridge
            model = Ridge(alpha=0.1)
            model.fit(features_array, targets_array)
            
            # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            feature_names = list(self.momentum_weights.keys())
            for i, feature in enumerate(feature_names):
                if i < len(model.coef_):
                    self.momentum_weights[feature] = abs(model.coef_[i])
            
            # ì •ê·œí™”
            total_weight = sum(self.momentum_weights.values())
            if total_weight > 0:
                self.momentum_weights = {k: v/total_weight for k, v in self.momentum_weights.items()}
            
            self.is_trained = True
            self.last_training_date = datetime.now()
            
            # ì„±ëŠ¥ í‰ê°€
            predictions = model.predict(features_array)
            accuracy = np.mean(np.abs(predictions - targets_array) < 0.02)  # 2% ì´ë‚´ ì •í™•ë„
            
            return {
                "training_completed": True,
                "samples": len(features_array),
                "accuracy": accuracy,
                "optimal_weights": self.momentum_weights
            }
            
        except Exception as e:
            logger.error(f"íŠ¸ë Œë“œ ì¶”ì¢… ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def predict(self, features: np.ndarray) -> Dict:
        """íŠ¸ë Œë“œ ì¶”ì¢… ì˜ˆì¸¡"""
        try:
            if not self.is_trained or len(features) < 24:
                return {"error": "ëª¨ë¸ ë¯¸í•™ìŠµ ë˜ëŠ” íŠ¹ì§• ë¶€ì¡±"}
            
            # ëª¨ë©˜í…€ íŠ¹ì§• ì¶”ì¶œ
            momentum_features = {
                'price_trend_7d': features[1],
                'price_trend_30d': features[2], 
                'rsi_14': features[11],
                'volume_trend': features[8],
                'macd_signal': features[12],
                'bollinger_position': features[13],
                'fear_greed_index': features[20]
            }
            
            # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
            momentum_score = sum(
                momentum_features[feature] * weight 
                for feature, weight in self.momentum_weights.items()
                if feature in momentum_features
            )
            
            # íŠ¸ë Œë“œ ê°•ë„ ë¶„ì„
            trend_strength = (momentum_features['price_trend_7d'] + momentum_features['price_trend_30d']) / 2
            
            # ì˜ˆì¸¡ ì‹ í˜¸ ìƒì„±
            if momentum_score > 0.3 and trend_strength > 0.02:
                direction = "BULLISH"
                confidence = min(momentum_score * 2, 1.0)
                price_change_prediction = trend_strength * 1.2  # íŠ¸ë Œë“œ ì¦í­
            elif momentum_score > 0.1:
                direction = "MILD_BULLISH"
                confidence = momentum_score
                price_change_prediction = trend_strength * 0.8
            else:
                direction = "NEUTRAL"
                confidence = 0.5
                price_change_prediction = 0.0
            
            return {
                "direction": direction,
                "confidence": confidence,
                "price_change_prediction": price_change_prediction,
                "momentum_score": momentum_score,
                "trend_strength": trend_strength,
                "model_type": "trend_following"
            }
            
        except Exception as e:
            logger.error(f"íŠ¸ë Œë“œ ì¶”ì¢… ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_feature_importance(self) -> Dict[str, float]:
        """íŠ¹ì§• ì¤‘ìš”ë„ ë°˜í™˜"""
        return self.momentum_weights.copy()

class MeanReversionModel(BaseRegimeModel):
    """í‰ê·  íšŒê·€ ëª¨ë¸ (ì•½ì„¸ì¥/íš¡ë³´ì¥ íŠ¹í™”)"""
    
    def __init__(self, model_id: str = "mean_reversion"):
        super().__init__(model_id, "BEAR_MARKET")
        self.reversion_weights = {
            'rsi_14': 0.30,
            'bollinger_position': 0.25,
            'fear_greed_index': 0.20,
            'whale_activity': 0.10,
            'exchange_flow': 0.10,
            'put_call_ratio': 0.05
        }
    
    async def train(self, training_data: List[Dict]) -> Dict:
        """í‰ê·  íšŒê·€ ëª¨ë¸ í•™ìŠµ"""
        try:
            # ì•½ì„¸ì¥/íš¡ë³´ì¥ ë°ì´í„° í•„í„°ë§
            reversion_data = [d for d in training_data 
                            if d.get('regime') in ['BEAR_MARKET', 'SIDEWAYS']]
            
            if len(reversion_data) < 20:
                return {"error": "í‰ê·  íšŒê·€ í•™ìŠµ ë°ì´í„° ë¶€ì¡±"}
            
            features_array = []
            targets_array = []
            
            for data in reversion_data:
                features = data.get('features', [])
                target = data.get('target')
                
                if len(features) >= 21 and target is not None:
                    reversion_features = [
                        features[11],  # rsi_14
                        features[13],  # bollinger_position
                        features[20],  # fear_greed_index
                        features[14],  # whale_activity
                        features[15],  # exchange_flow
                        features[19] if len(features) > 19 else 0.5  # put_call_ratio
                    ]
                    features_array.append(reversion_features)
                    targets_array.append(target)
            
            if len(features_array) < 10:
                return {"error": "ìœ íš¨í•œ íŠ¹ì§• ë°ì´í„° ë¶€ì¡±"}
            
            features_array = np.array(features_array)
            targets_array = np.array(targets_array)
            
            # í‰ê·  íšŒê·€ ìµœì í™”
            from sklearn.linear_model import ElasticNet
            model = ElasticNet(alpha=0.1, l1_ratio=0.5)
            model.fit(features_array, targets_array)
            
            # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            feature_names = list(self.reversion_weights.keys())
            for i, feature in enumerate(feature_names):
                if i < len(model.coef_):
                    self.reversion_weights[feature] = abs(model.coef_[i])
            
            # ì •ê·œí™”
            total_weight = sum(self.reversion_weights.values())
            if total_weight > 0:
                self.reversion_weights = {k: v/total_weight for k, v in self.reversion_weights.items()}
            
            self.is_trained = True
            self.last_training_date = datetime.now()
            
            predictions = model.predict(features_array)
            accuracy = np.mean(np.abs(predictions - targets_array) < 0.03)
            
            return {
                "training_completed": True,
                "samples": len(features_array),
                "accuracy": accuracy,
                "optimal_weights": self.reversion_weights
            }
            
        except Exception as e:
            logger.error(f"í‰ê·  íšŒê·€ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def predict(self, features: np.ndarray) -> Dict:
        """í‰ê·  íšŒê·€ ì˜ˆì¸¡"""
        try:
            if not self.is_trained or len(features) < 21:
                return {"error": "ëª¨ë¸ ë¯¸í•™ìŠµ ë˜ëŠ” íŠ¹ì§• ë¶€ì¡±"}
            
            # í‰ê·  íšŒê·€ íŠ¹ì§• ì¶”ì¶œ
            reversion_features = {
                'rsi_14': features[11],
                'bollinger_position': features[13],
                'fear_greed_index': features[20],
                'whale_activity': features[14],
                'exchange_flow': features[15],
                'put_call_ratio': features[19] if len(features) > 19 else 0.5
            }
            
            # ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ë¶„ì„
            rsi = reversion_features['rsi_14']
            bb_pos = reversion_features['bollinger_position']
            fear_greed = reversion_features['fear_greed_index']
            
            # í‰ê·  íšŒê·€ ì‹ í˜¸ ìƒì„±
            oversold_score = 0
            overbought_score = 0
            
            # RSI ê¸°ë°˜
            if rsi < 30:
                oversold_score += 0.4
            elif rsi > 70:
                overbought_score += 0.4
            
            # ë³¼ë¦°ì €ë°´ë“œ ê¸°ë°˜
            if bb_pos < 0.2:
                oversold_score += 0.3
            elif bb_pos > 0.8:
                overbought_score += 0.3
            
            # ê³µí¬íƒìš•ì§€ìˆ˜ ê¸°ë°˜
            if fear_greed < 25:
                oversold_score += 0.3
            elif fear_greed > 75:
                overbought_score += 0.3
            
            # ì˜ˆì¸¡ ìƒì„±
            if oversold_score > 0.6:
                direction = "BULLISH_REVERSAL"
                confidence = oversold_score
                price_change_prediction = 0.02 * oversold_score
            elif overbought_score > 0.6:
                direction = "BEARISH_REVERSAL"
                confidence = overbought_score
                price_change_prediction = -0.02 * overbought_score
            else:
                direction = "NEUTRAL"
                confidence = 0.5
                price_change_prediction = 0.0
            
            return {
                "direction": direction,
                "confidence": confidence,
                "price_change_prediction": price_change_prediction,
                "oversold_score": oversold_score,
                "overbought_score": overbought_score,
                "model_type": "mean_reversion"
            }
            
        except Exception as e:
            logger.error(f"í‰ê·  íšŒê·€ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_feature_importance(self) -> Dict[str, float]:
        return self.reversion_weights.copy()

class VolatilityBreakoutModel(BaseRegimeModel):
    """ë³€ë™ì„± ëŒíŒŒ ëª¨ë¸ (ê³ ë³€ë™ì„±/ì €ë³€ë™ì„± íŠ¹í™”)"""
    
    def __init__(self, model_id: str = "volatility_breakout"):
        super().__init__(model_id, "HIGH_VOLATILITY_SHOCK")
        self.volatility_weights = {
            'volatility_1d': 0.25,
            'volatility_7d': 0.20,
            'volume_volatility': 0.20,
            'futures_basis': 0.15,
            'funding_rate': 0.10,
            'whale_activity': 0.10
        }
    
    async def train(self, training_data: List[Dict]) -> Dict:
        """ë³€ë™ì„± ëª¨ë¸ í•™ìŠµ"""
        try:
            # ê³ ë³€ë™ì„±/ì €ë³€ë™ì„± ë°ì´í„° í•„í„°ë§
            vol_data = [d for d in training_data 
                       if d.get('regime') in ['HIGH_VOLATILITY_SHOCK', 'LOW_VOLATILITY_ACCUMULATION']]
            
            if len(vol_data) < 15:
                return {"error": "ë³€ë™ì„± í•™ìŠµ ë°ì´í„° ë¶€ì¡±"}
            
            features_array = []
            targets_array = []
            
            for data in vol_data:
                features = data.get('features', [])
                target = data.get('target')
                
                if len(features) >= 19 and target is not None:
                    vol_features = [
                        features[4],   # volatility_1d
                        features[5],   # volatility_7d
                        features[9],   # volume_volatility
                        features[17],  # futures_basis
                        features[18],  # funding_rate
                        features[14]   # whale_activity
                    ]
                    features_array.append(vol_features)
                    targets_array.append(target)
            
            if len(features_array) < 10:
                return {"error": "ìœ íš¨í•œ íŠ¹ì§• ë°ì´í„° ë¶€ì¡±"}
            
            features_array = np.array(features_array)
            targets_array = np.array(targets_array)
            
            # ë¹„ì„ í˜• ëª¨ë¸ (RandomForest) ì‚¬ìš©
            from sklearn.ensemble import RandomForestRegressor
            model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)
            model.fit(features_array, targets_array)
            
            # íŠ¹ì§• ì¤‘ìš”ë„ ì—…ë°ì´íŠ¸
            feature_names = list(self.volatility_weights.keys())
            importances = model.feature_importances_
            
            for i, feature in enumerate(feature_names):
                if i < len(importances):
                    self.volatility_weights[feature] = importances[i]
            
            self.is_trained = True
            self.last_training_date = datetime.now()
            
            predictions = model.predict(features_array)
            accuracy = np.mean(np.abs(predictions - targets_array) < 0.04)
            
            return {
                "training_completed": True,
                "samples": len(features_array),
                "accuracy": accuracy,
                "optimal_weights": self.volatility_weights
            }
            
        except Exception as e:
            logger.error(f"ë³€ë™ì„± ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def predict(self, features: np.ndarray) -> Dict:
        """ë³€ë™ì„± ëŒíŒŒ ì˜ˆì¸¡"""
        try:
            if not self.is_trained or len(features) < 19:
                return {"error": "ëª¨ë¸ ë¯¸í•™ìŠµ ë˜ëŠ” íŠ¹ì§• ë¶€ì¡±"}
            
            # ë³€ë™ì„± íŠ¹ì§• ì¶”ì¶œ
            vol_1d = features[4]
            vol_7d = features[5]
            vol_vol = features[9]
            futures_basis = features[17]
            funding_rate = features[18]
            whale_activity = features[14]
            
            # ë³€ë™ì„± ì²´ì œ ë¶„ì„
            vol_regime_score = vol_1d * 0.4 + vol_7d * 0.3 + vol_vol * 0.3
            
            # ëŒíŒŒ ì‹ í˜¸ ê°ì§€
            basis_signal = abs(futures_basis) > 0.02
            funding_signal = abs(funding_rate) > 0.01
            whale_signal = whale_activity > 0.7
            
            breakout_signals = sum([basis_signal, funding_signal, whale_signal])
            
            # ì˜ˆì¸¡ ìƒì„±
            if vol_regime_score > 0.06 and breakout_signals >= 2:
                direction = "HIGH_VOLATILITY_BREAKOUT"
                confidence = min(vol_regime_score * 15, 1.0)
                price_change_prediction = np.sign(futures_basis + funding_rate) * 0.05
            elif vol_regime_score < 0.015 and whale_signal:
                direction = "LOW_VOLATILITY_ACCUMULATION"
                confidence = 0.7
                price_change_prediction = 0.01  # ì‘ì€ ìƒìŠ¹ ê¸°ëŒ€
            else:
                direction = "NEUTRAL_VOLATILITY"
                confidence = 0.5
                price_change_prediction = 0.0
            
            return {
                "direction": direction,
                "confidence": confidence,
                "price_change_prediction": price_change_prediction,
                "volatility_regime_score": vol_regime_score,
                "breakout_signals": breakout_signals,
                "model_type": "volatility_breakout"
            }
            
        except Exception as e:
            logger.error(f"ë³€ë™ì„± ëŒíŒŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_feature_importance(self) -> Dict[str, float]:
        return self.volatility_weights.copy()

class AdaptiveRegimeModelSelector:
    """ì ì‘í˜• ì²´ì œë³„ ëª¨ë¸ ì„ íƒê¸°"""
    
    def __init__(self, base_path: str = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"):
        self.base_path = base_path
        self.db_path = os.path.join(base_path, "adaptive_regime_db.db")
        self.models_path = os.path.join(base_path, "adaptive_models")
        os.makedirs(self.models_path, exist_ok=True)
        
        # ì²´ì œë³„ ëª¨ë¸ ë“±ë¡
        self.regime_models = {
            "BULL_MARKET": [
                TrendFollowingModel(),
                VolatilityBreakoutModel("volatility_bull")
            ],
            "BEAR_MARKET": [
                MeanReversionModel(),
                TrendFollowingModel("trend_bear")
            ],
            "SIDEWAYS": [
                MeanReversionModel("mean_sideways"),
                VolatilityBreakoutModel("vol_sideways")
            ],
            "HIGH_VOLATILITY_SHOCK": [
                VolatilityBreakoutModel(),
                MeanReversionModel("mean_shock")
            ],
            "LOW_VOLATILITY_ACCUMULATION": [
                VolatilityBreakoutModel("vol_accumulation"),
                TrendFollowingModel("trend_accumulation")
            ]
        }
        
        # ì²´ì œë³„ ì„¤ì •
        self.regime_configs = {}
        self.init_regime_configs()
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_tracker = {}
        self.model_rankings = {}
        
        # ë™ì  ê°€ì¤‘ì¹˜
        self.dynamic_weights = defaultdict(lambda: defaultdict(float))
        
        # ì˜ˆì¸¡ íˆìŠ¤í† ë¦¬
        self.prediction_history = deque(maxlen=1000)
        
        self.init_database()
        self.load_configurations()
        
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ì ì‘í˜• ì˜ˆì¸¡ ê¸°ë¡
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS adaptive_predictions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    regime_type TEXT NOT NULL,
                    model_used TEXT NOT NULL,
                    prediction_data TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    contributing_models TEXT NOT NULL,
                    performance_score REAL,
                    actual_result REAL,
                    is_verified BOOLEAN DEFAULT FALSE
                )
            ''')
            
            # ëª¨ë¸ ì„±ëŠ¥ ì¶”ì 
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS model_performance_tracking (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    model_id TEXT NOT NULL,
                    regime_type TEXT NOT NULL,
                    performance_period TEXT NOT NULL,
                    accuracy REAL NOT NULL,
                    precision_val REAL NOT NULL,
                    recall_val REAL NOT NULL,
                    f1_score REAL NOT NULL,
                    directional_accuracy REAL NOT NULL,
                    profit_factor REAL NOT NULL,
                    sharpe_ratio REAL,
                    max_drawdown REAL,
                    sample_size INTEGER NOT NULL,
                    last_updated TEXT NOT NULL
                )
            ''')
            
            # ë™ì  ê°€ì¤‘ì¹˜ íˆìŠ¤í† ë¦¬
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS dynamic_weights_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    regime_type TEXT NOT NULL,
                    model_weights TEXT NOT NULL,
                    performance_trigger TEXT,
                    adjustment_reason TEXT NOT NULL
                )
            ''')
            
            # ì²´ì œë³„ ì„¤ì •
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS regime_configurations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    regime_type TEXT NOT NULL,
                    primary_model TEXT NOT NULL,
                    fallback_models TEXT NOT NULL,
                    ensemble_weights TEXT NOT NULL,
                    performance_threshold REAL NOT NULL,
                    retraining_interval INTEGER NOT NULL,
                    risk_adjustment_factor REAL NOT NULL,
                    last_updated TEXT NOT NULL,
                    is_active BOOLEAN DEFAULT TRUE
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("âœ… ì ì‘í˜• ëª¨ë¸ ì„ íƒê¸° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì ì‘í˜• ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def init_regime_configs(self):
        """ì²´ì œë³„ ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™”"""
        try:
            self.regime_configs = {
                "BULL_MARKET": RegimeModelConfig(
                    regime_type="BULL_MARKET",
                    primary_model="trend_following",
                    fallback_models=["volatility_bull"],
                    ensemble_weights={"trend_following": 0.7, "volatility_bull": 0.3},
                    performance_threshold=0.65,
                    retraining_interval_days=7,
                    feature_importance_weights={},
                    risk_adjustment_factor=0.8
                ),
                "BEAR_MARKET": RegimeModelConfig(
                    regime_type="BEAR_MARKET",
                    primary_model="mean_reversion",
                    fallback_models=["trend_bear"],
                    ensemble_weights={"mean_reversion": 0.8, "trend_bear": 0.2},
                    performance_threshold=0.60,
                    retraining_interval_days=5,
                    feature_importance_weights={},
                    risk_adjustment_factor=1.2
                ),
                "SIDEWAYS": RegimeModelConfig(
                    regime_type="SIDEWAYS",
                    primary_model="mean_sideways",
                    fallback_models=["vol_sideways"],
                    ensemble_weights={"mean_sideways": 0.6, "vol_sideways": 0.4},
                    performance_threshold=0.55,
                    retraining_interval_days=10,
                    feature_importance_weights={},
                    risk_adjustment_factor=1.0
                ),
                "HIGH_VOLATILITY_SHOCK": RegimeModelConfig(
                    regime_type="HIGH_VOLATILITY_SHOCK",
                    primary_model="volatility_breakout",
                    fallback_models=["mean_shock"],
                    ensemble_weights={"volatility_breakout": 0.9, "mean_shock": 0.1},
                    performance_threshold=0.50,
                    retraining_interval_days=3,
                    feature_importance_weights={},
                    risk_adjustment_factor=1.5
                ),
                "LOW_VOLATILITY_ACCUMULATION": RegimeModelConfig(
                    regime_type="LOW_VOLATILITY_ACCUMULATION",
                    primary_model="vol_accumulation",
                    fallback_models=["trend_accumulation"],
                    ensemble_weights={"vol_accumulation": 0.7, "trend_accumulation": 0.3},
                    performance_threshold=0.60,
                    retraining_interval_days=14,
                    feature_importance_weights={},
                    risk_adjustment_factor=0.9
                )
            }
            
            logger.info("âœ… ì²´ì œë³„ ê¸°ë³¸ ì„¤ì • ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì²´ì œë³„ ì„¤ì • ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def load_configurations(self):
        """ì €ì¥ëœ ì„¤ì • ë¡œë“œ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT regime_type, primary_model, fallback_models, ensemble_weights,
                       performance_threshold, retraining_interval, risk_adjustment_factor
                FROM regime_configurations 
                WHERE is_active = TRUE
            ''')
            
            configurations = cursor.fetchall()
            
            for config in configurations:
                regime_type = config[0]
                if regime_type in self.regime_configs:
                    self.regime_configs[regime_type].primary_model = config[1]
                    self.regime_configs[regime_type].fallback_models = json.loads(config[2])
                    self.regime_configs[regime_type].ensemble_weights = json.loads(config[3])
                    self.regime_configs[regime_type].performance_threshold = config[4]
                    self.regime_configs[regime_type].retraining_interval_days = config[5]
                    self.regime_configs[regime_type].risk_adjustment_factor = config[6]
            
            conn.close()
            logger.info("âœ… ì €ì¥ëœ ì„¤ì • ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def train_regime_models(self, training_data: List[Dict]) -> Dict:
        """ëª¨ë“  ì²´ì œë³„ ëª¨ë¸ í•™ìŠµ"""
        try:
            logger.info(f"ğŸ§  ì²´ì œë³„ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë°ì´í„°: {len(training_data)}ê°œ)")
            
            training_results = {}
            
            for regime_type, models in self.regime_models.items():
                logger.info(f"ğŸ“š {regime_type} ëª¨ë¸ë“¤ í•™ìŠµ ì¤‘...")
                
                regime_results = {}
                for model in models:
                    result = await model.train(training_data)
                    regime_results[model.model_id] = result
                
                training_results[regime_type] = regime_results
                
                # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
                await self.update_ensemble_weights(regime_type, regime_results)
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            await self.save_training_results(training_results)
            
            return {
                "training_completed": True,
                "regimes_trained": len(training_results),
                "total_models": sum(len(models) for models in self.regime_models.values()),
                "results": training_results
            }
            
        except Exception as e:
            logger.error(f"ì²´ì œë³„ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def update_ensemble_weights(self, regime_type: str, training_results: Dict):
        """ì„±ëŠ¥ ê¸°ë°˜ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        try:
            if regime_type not in self.regime_configs:
                return
            
            # ëª¨ë¸ë³„ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            performance_scores = {}
            for model_id, result in training_results.items():
                if isinstance(result, dict) and not result.get("error"):
                    accuracy = result.get("accuracy", 0)
                    samples = result.get("samples", 0)
                    
                    # ì„±ëŠ¥ ì ìˆ˜ (ì •í™•ë„ + ìƒ˜í”Œ ê°€ì¤‘ì¹˜)
                    score = accuracy * (1 + min(samples / 100, 0.5))
                    performance_scores[model_id] = score
            
            if not performance_scores:
                return
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_score = sum(performance_scores.values())
            if total_score > 0:
                new_weights = {
                    model_id: score / total_score 
                    for model_id, score in performance_scores.items()
                }
                
                self.regime_configs[regime_type].ensemble_weights = new_weights
                
                # ë™ì  ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
                self.dynamic_weights[regime_type] = new_weights
                
                logger.info(f"âœ… {regime_type} ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸: {new_weights}")
            
        except Exception as e:
            logger.error(f"ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def predict_with_adaptive_selection(self, regime_type: str, features: np.ndarray) -> PredictionResult:
        """ì ì‘í˜• ëª¨ë¸ ì„ íƒìœ¼ë¡œ ì˜ˆì¸¡"""
        try:
            if regime_type not in self.regime_models:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì²´ì œ ìœ í˜•: {regime_type}")
            
            models = self.regime_models[regime_type]
            config = self.regime_configs[regime_type]
            
            # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
            model_predictions = {}
            model_confidences = {}
            
            for model in models:
                try:
                    prediction = await model.predict(features)
                    if not prediction.get("error"):
                        model_predictions[model.model_id] = prediction
                        model_confidences[model.model_id] = prediction.get("confidence", 0.5)
                except Exception as model_error:
                    logger.warning(f"ëª¨ë¸ {model.model_id} ì˜ˆì¸¡ ì‹¤íŒ¨: {model_error}")
                    continue
            
            if not model_predictions:
                raise ValueError("ëª¨ë“  ëª¨ë¸ ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            
            # ì„±ëŠ¥ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
            best_model_id = self.select_best_performing_model(regime_type, model_confidences)
            primary_prediction = model_predictions.get(best_model_id)
            
            if not primary_prediction:
                # Fallback: ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ëª¨ë¸ ì‚¬ìš©
                best_model_id = max(model_confidences.items(), key=lambda x: x[1])[0]
                primary_prediction = model_predictions[best_model_id]
            
            # ì•™ìƒë¸” ì˜ˆì¸¡ (ê°€ì¤‘ í‰ê· )
            ensemble_prediction = self.create_ensemble_prediction(
                model_predictions, config.ensemble_weights, regime_type
            )
            
            # ìµœì¢… ì˜ˆì¸¡ ê²°ì •
            if ensemble_prediction.get("confidence", 0) > primary_prediction.get("confidence", 0):
                final_prediction = ensemble_prediction
                model_used = "ensemble"
            else:
                final_prediction = primary_prediction  
                model_used = best_model_id
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            performance_score = self.calculate_prediction_performance_score(
                final_prediction, model_predictions, regime_type
            )
            
            # ê¸°ì—¬ ëª¨ë¸ ê°€ì¤‘ì¹˜
            contributing_models = config.ensemble_weights.copy()
            
            result = PredictionResult(
                regime_type=regime_type,
                prediction=final_prediction,
                model_used=model_used,
                confidence=final_prediction.get("confidence", 0.5),
                contributing_models=contributing_models,
                performance_score=performance_score,
                timestamp=datetime.now()
            )
            
            # ì˜ˆì¸¡ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            self.prediction_history.append(result)
            
            # ê²°ê³¼ ì €ì¥
            await self.save_prediction_result(result)
            
            return result
            
        except Exception as e:
            logger.error(f"ì ì‘í˜• ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì˜ˆì¸¡ ë°˜í™˜
            return PredictionResult(
                regime_type=regime_type,
                prediction={"direction": "NEUTRAL", "confidence": 0.5, "error": str(e)},
                model_used="fallback",
                confidence=0.5,
                contributing_models={},
                performance_score=0.5,
                timestamp=datetime.now()
            )
    
    def select_best_performing_model(self, regime_type: str, model_confidences: Dict[str, float]) -> str:
        """ì„±ëŠ¥ ê¸°ë°˜ ìµœê³  ëª¨ë¸ ì„ íƒ"""
        try:
            # ìµœê·¼ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ í™•ì¸
            recent_performance = self.get_recent_model_performance(regime_type)
            
            if recent_performance:
                # ì„±ëŠ¥ ì ìˆ˜ì™€ ì‹ ë¢°ë„ ì¡°í•©
                combined_scores = {}
                for model_id, confidence in model_confidences.items():
                    performance = recent_performance.get(model_id, 0.5)
                    combined_score = 0.6 * performance + 0.4 * confidence
                    combined_scores[model_id] = combined_score
                
                return max(combined_scores.items(), key=lambda x: x[1])[0]
            else:
                # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ì‹ ë¢°ë„ ê¸°ì¤€
                return max(model_confidences.items(), key=lambda x: x[1])[0]
                
        except Exception as e:
            logger.error(f"ìµœê³  ëª¨ë¸ ì„ íƒ ì‹¤íŒ¨: {e}")
            return list(model_confidences.keys())[0] if model_confidences else "default"
    
    def get_recent_model_performance(self, regime_type: str, days: int = 7) -> Dict[str, float]:
        """ìµœê·¼ ëª¨ë¸ ì„±ëŠ¥ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
            
            cursor.execute('''
                SELECT model_id, AVG(accuracy) as avg_accuracy
                FROM model_performance_tracking 
                WHERE regime_type = ? AND last_updated > ?
                GROUP BY model_id
            ''', (regime_type, cutoff_date))
            
            results = cursor.fetchall()
            conn.close()
            
            return {model_id: accuracy for model_id, accuracy in results}
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì„±ëŠ¥ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def create_ensemble_prediction(self, model_predictions: Dict, weights: Dict, regime_type: str) -> Dict:
        """ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±"""
        try:
            if not model_predictions or not weights:
                return {"error": "ì˜ˆì¸¡ ë˜ëŠ” ê°€ì¤‘ì¹˜ ë°ì´í„° ì—†ìŒ"}
            
            # ë°©í–¥ì„± íˆ¬í‘œ
            direction_votes = {}
            confidence_weighted = 0
            price_change_weighted = 0
            total_weight = 0
            
            for model_id, prediction in model_predictions.items():
                weight = weights.get(model_id, 0)
                if weight <= 0:
                    continue
                
                direction = prediction.get("direction", "NEUTRAL")
                confidence = prediction.get("confidence", 0.5)
                price_change = prediction.get("price_change_prediction", 0)
                
                # ë°©í–¥ íˆ¬í‘œ ì§‘ê³„
                direction_votes[direction] = direction_votes.get(direction, 0) + weight
                
                # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                confidence_weighted += confidence * weight
                price_change_weighted += price_change * weight
                total_weight += weight
            
            if total_weight == 0:
                return {"error": "ìœ íš¨í•œ ê°€ì¤‘ì¹˜ ì—†ìŒ"}
            
            # ìµœì¢… ê²°ê³¼
            final_direction = max(direction_votes.items(), key=lambda x: x[1])[0] if direction_votes else "NEUTRAL"
            final_confidence = confidence_weighted / total_weight
            final_price_change = price_change_weighted / total_weight
            
            # ì•™ìƒë¸” ë³´ì •
            ensemble_confidence = min(final_confidence * 1.1, 1.0)  # ì•™ìƒë¸” ë³´ë„ˆìŠ¤
            
            return {
                "direction": final_direction,
                "confidence": ensemble_confidence,
                "price_change_prediction": final_price_change,
                "direction_votes": direction_votes,
                "total_weight": total_weight,
                "model_type": "ensemble"
            }
            
        except Exception as e:
            logger.error(f"ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def calculate_prediction_performance_score(self, prediction: Dict, 
                                             model_predictions: Dict, regime_type: str) -> float:
        """ì˜ˆì¸¡ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        try:
            base_confidence = prediction.get("confidence", 0.5)
            
            # ëª¨ë¸ í•©ì˜ë„ (ì—¬ëŸ¬ ëª¨ë¸ì´ ê°™ì€ ë°©í–¥ ì˜ˆì¸¡ì‹œ ê°€ì‚°ì )
            directions = [p.get("direction", "NEUTRAL") for p in model_predictions.values()]
            consensus = directions.count(prediction.get("direction", "NEUTRAL")) / len(directions)
            
            # ì²´ì œ ì í•©ì„± (ê° ì²´ì œë³„ ê¸°ëŒ€ ì„±ëŠ¥)
            regime_multiplier = {
                "BULL_MARKET": 1.1,
                "BEAR_MARKET": 1.0,
                "SIDEWAYS": 0.9,
                "HIGH_VOLATILITY_SHOCK": 0.8,
                "LOW_VOLATILITY_ACCUMULATION": 1.0
            }.get(regime_type, 1.0)
            
            # ìµœì¢… ì„±ëŠ¥ ì ìˆ˜
            performance_score = base_confidence * consensus * regime_multiplier
            
            return min(performance_score, 1.0)
            
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def save_prediction_result(self, result: PredictionResult):
        """ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO adaptive_predictions
                (timestamp, regime_type, model_used, prediction_data, confidence,
                 contributing_models, performance_score)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                result.timestamp.isoformat(),
                result.regime_type,
                result.model_used,
                json.dumps(result.prediction),
                result.confidence,
                json.dumps(result.contributing_models),
                result.performance_score
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def save_training_results(self, training_results: Dict):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for regime_type, results in training_results.items():
                for model_id, result in results.items():
                    if isinstance(result, dict) and not result.get("error"):
                        cursor.execute('''
                            INSERT INTO model_performance_tracking
                            (model_id, regime_type, performance_period, accuracy,
                             precision_val, recall_val, f1_score, directional_accuracy,
                             profit_factor, sample_size, last_updated)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            model_id,
                            regime_type,
                            "training",
                            result.get("accuracy", 0),
                            result.get("accuracy", 0),  # ë‹¨ìˆœí™”
                            result.get("accuracy", 0),
                            result.get("accuracy", 0),
                            result.get("accuracy", 0),
                            1.0,  # ê¸°ë³¸ê°’
                            result.get("samples", 0),
                            datetime.now().isoformat()
                        ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def get_adaptive_diagnostics(self) -> Dict:
        """ì ì‘í˜• ì‹œìŠ¤í…œ ì§„ë‹¨"""
        try:
            diagnostics = {
                "system_status": "active",
                "total_regimes": len(self.regime_models),
                "total_models": sum(len(models) for models in self.regime_models.values()),
                "prediction_history_length": len(self.prediction_history)
            }
            
            # ì²´ì œë³„ ëª¨ë¸ ìƒíƒœ
            regime_status = {}
            for regime_type, models in self.regime_models.items():
                trained_models = sum(1 for model in models if model.is_trained)
                regime_status[regime_type] = {
                    "total_models": len(models),
                    "trained_models": trained_models,
                    "primary_model": self.regime_configs[regime_type].primary_model,
                    "ensemble_weights": self.regime_configs[regime_type].ensemble_weights,
                    "performance_threshold": self.regime_configs[regime_type].performance_threshold
                }
            
            diagnostics["regime_status"] = regime_status
            
            # ìµœê·¼ ì˜ˆì¸¡ ì„±ëŠ¥
            if self.prediction_history:
                recent_predictions = list(self.prediction_history)[-10:]
                avg_confidence = statistics.mean([p.confidence for p in recent_predictions])
                avg_performance = statistics.mean([p.performance_score for p in recent_predictions])
                
                diagnostics["recent_performance"] = {
                    "avg_confidence": avg_confidence,
                    "avg_performance_score": avg_performance,
                    "prediction_count": len(recent_predictions)
                }
            
            return diagnostics
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_adaptive_regime_selector():
    """ì ì‘í˜• ì²´ì œ ëª¨ë¸ ì„ íƒê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸ”„ ì ì‘í˜• ì²´ì œ ëª¨ë¸ ì„ íƒê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    selector = AdaptiveRegimeModelSelector()
    
    # ì‹œìŠ¤í…œ ì§„ë‹¨
    diagnostics = await selector.get_adaptive_diagnostics()
    print(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {diagnostics.get('system_status')}")
    print(f"ğŸ¯ ì´ ì²´ì œ: {diagnostics.get('total_regimes')}ê°œ")
    print(f"ğŸ¤– ì´ ëª¨ë¸: {diagnostics.get('total_models')}ê°œ")
    
    # ì²´ì œë³„ ìƒíƒœ
    regime_status = diagnostics.get("regime_status", {})
    print(f"\nğŸ“ˆ ì²´ì œë³„ ëª¨ë¸ ìƒíƒœ:")
    for regime, status in regime_status.items():
        trained = status["trained_models"]
        total = status["total_models"] 
        primary = status["primary_model"]
        print(f"   â€¢ {regime}: {trained}/{total} í•™ìŠµë¨, ì£¼ëª¨ë¸: {primary}")
    
    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    test_features = np.random.random(24)  # 24ê°œ íŠ¹ì§•
    
    print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìˆ˜í–‰:")
    for regime_type in ["BULL_MARKET", "BEAR_MARKET", "SIDEWAYS"]:
        try:
            result = await selector.predict_with_adaptive_selection(regime_type, test_features)
            
            print(f"\nğŸ¯ {regime_type}:")
            print(f"   â€¢ ì‚¬ìš© ëª¨ë¸: {result.model_used}")
            print(f"   â€¢ ì˜ˆì¸¡: {result.prediction.get('direction', 'N/A')}")
            print(f"   â€¢ ì‹ ë¢°ë„: {result.confidence:.1%}")
            print(f"   â€¢ ì„±ëŠ¥ ì ìˆ˜: {result.performance_score:.3f}")
            
            if result.contributing_models:
                print(f"   â€¢ ê¸°ì—¬ ëª¨ë¸ ê°€ì¤‘ì¹˜:")
                for model, weight in result.contributing_models.items():
                    print(f"     - {model}: {weight:.1%}")
                    
        except Exception as e:
            print(f"   âŒ {regime_type} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ì ì‘í˜• ì²´ì œ ëª¨ë¸ ì„ íƒê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(test_adaptive_regime_selector())