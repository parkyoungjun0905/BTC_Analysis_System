#!/usr/bin/env python3
"""
ê³ ê¸‰ ê³¼ê±° ë°ì´í„° ë°±í•„ ì‹œìŠ¤í…œ
381ê°œ ì§€í‘œì˜ ì§„ì§œ ê³¼ê±° 6ê°œì›” ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê°•í™”ëœ ì‹œìŠ¤í…œ
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import asyncio
import aiohttp
import ccxt.async_support as ccxt
import yfinance as yf
import requests
from typing import Dict, List, Any
import logging
import time
from timeseries_accumulator import TimeseriesAccumulator
import warnings
warnings.filterwarnings('ignore')

class AdvancedHistoricalBackfiller:
    def __init__(self):
        self.base_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.logs_path = os.path.join(self.base_path, "logs")
        
        # ë¡œê¹… ì„¤ì •
        os.makedirs(self.logs_path, exist_ok=True)
        log_file = os.path.join(self.logs_path, f"advanced_backfill_{datetime.now().strftime('%Y-%m')}.log")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ì‹œê³„ì—´ ëˆ„ì ê¸° ì´ˆê¸°í™”
        self.accumulator = TimeseriesAccumulator()
        
        # 6ê°œì›” ì „ ë‚ ì§œ ê³„ì‚°
        self.end_date = datetime.now()
        self.start_date = self.end_date - timedelta(days=180)
        
        # ìˆ˜ì§‘ í†µê³„
        self.stats = {
            "total_indicators": 0,
            "successful_indicators": 0,
            "failed_indicators": 0,
            "total_data_points": 0
        }
        
        print(f"ğŸ“… ê³ ê¸‰ ë°±í•„ ê¸°ê°„: {self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}")
    
    async def backfill_all_real_data(self):
        """ëª¨ë“  ì‹¤ì œ ì§€í‘œì˜ ê³¼ê±° 6ê°œì›” ë°ì´í„° ë°±í•„"""
        print("ğŸš€ 381ê°œ ì§€í‘œì˜ ì§„ì§œ ê³¼ê±° 6ê°œì›” ì‹¤ì œ ë°ì´í„° ë°±í•„ ì‹œì‘...")
        print("â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 10-15ë¶„ (API ì œí•œ ìš°íšŒ)")
        
        # ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì‹œê°„ ë‹¨ì¶•
        backfill_tasks = [
            self.backfill_comprehensive_price_data(),
            self.backfill_comprehensive_market_data(),
            self.backfill_comprehensive_macro_data(),
            self.backfill_comprehensive_onchain_data(),
            self.backfill_comprehensive_sentiment_data(),
            self.backfill_comprehensive_derivatives_data(),
            self.backfill_comprehensive_volume_data(),
            self.backfill_comprehensive_technical_indicators()
        ]
        
        results = await asyncio.gather(*backfill_tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì§‘ê³„
        total_success = 0
        for result in results:
            if isinstance(result, int):
                total_success += result
            elif isinstance(result, Exception):
                self.logger.error(f"ë°±í•„ ì‘ì—… ì˜¤ë¥˜: {result}")
        
        self.stats["successful_indicators"] = total_success
        
        print(f"âœ… ê³ ê¸‰ ë°±í•„ ì™„ë£Œ!")
        print(f"ğŸ“Š ì„±ê³µ: {self.stats['successful_indicators']}ê°œ ì§€í‘œ")
        print(f"ğŸ“ˆ ì´ ë°ì´í„° í¬ì¸íŠ¸: {self.stats['total_data_points']}ê°œ")
        
        return total_success
    
    async def backfill_comprehensive_price_data(self):
        """í¬ê´„ì  ê°€ê²© ë°ì´í„° ë°±í•„ (ì—¬ëŸ¬ ê±°ë˜ì†Œ + ë‹¤ì–‘í•œ ì§€í‘œ)"""
        print("ğŸ’° í¬ê´„ì  ê°€ê²© ë°ì´í„° ë°±í•„ ì¤‘...")
        
        indicators_created = 0
        
        try:
            # 1. CoinGecko APIë¡œ BTC ê³¼ê±° ë°ì´í„° (ë” ê¸´ ê¸°ê°„)
            await self.fetch_coingecko_data()
            indicators_created += 10
            
            # 2. ì—¬ëŸ¬ ê±°ë˜ì†Œ ë°ì´í„°
            exchanges = ['binance', 'coinbase', 'kraken', 'huobi', 'okx']
            
            for exchange_name in exchanges:
                try:
                    await self.fetch_exchange_data(exchange_name)
                    indicators_created += 5
                    await asyncio.sleep(1)  # API ì œí•œ ë°©ì§€
                    
                except Exception as e:
                    self.logger.warning(f"{exchange_name} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # 3. ë‹¤ì–‘í•œ ê°€ê²© ì§€í‘œ ê³„ì‚°
            await self.calculate_derived_price_indicators()
            indicators_created += 15
            
            self.logger.info(f"í¬ê´„ì  ê°€ê²© ë°ì´í„° ë°±í•„ ì™„ë£Œ: {indicators_created}ê°œ ì§€í‘œ")
            return indicators_created
            
        except Exception as e:
            self.logger.error(f"í¬ê´„ì  ê°€ê²© ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def fetch_coingecko_data(self):
        """CoinGecko APIë¡œ ê³¼ê±° 6ê°œì›” ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # CoinGecko ë¬´ë£Œ API
            end_timestamp = int(self.end_date.timestamp())
            start_timestamp = int(self.start_date.timestamp())
            
            url = f"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart/range"
            params = {
                'vs_currency': 'usd',
                'from': start_timestamp,
                'to': end_timestamp
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # ê°€ê²© ë°ì´í„°
                        prices = data.get('prices', [])
                        volumes = data.get('total_volumes', [])
                        market_caps = data.get('market_caps', [])
                        
                        if prices:
                            # ë°ì´í„° ë³€í™˜
                            price_df = pd.DataFrame(prices, columns=['timestamp', 'price'])
                            volume_df = pd.DataFrame(volumes, columns=['timestamp', 'volume'])
                            market_cap_df = pd.DataFrame(market_caps, columns=['timestamp', 'market_cap'])
                            
                            # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
                            price_df['timestamp'] = pd.to_datetime(price_df['timestamp'], unit='ms')
                            volume_df['timestamp'] = pd.to_datetime(volume_df['timestamp'], unit='ms')
                            market_cap_df['timestamp'] = pd.to_datetime(market_cap_df['timestamp'], unit='ms')
                            
                            # ì¼ë³„ ë°ì´í„°ë¡œ ë¦¬ìƒ˜í”Œë§
                            price_daily = price_df.set_index('timestamp').resample('D').last()
                            volume_daily = volume_df.set_index('timestamp').resample('D').last()
                            market_cap_daily = market_cap_df.set_index('timestamp').resample('D').last()
                            
                            # ë³€í™”ìœ¨ ê³„ì‚°
                            price_daily['change_24h'] = price_daily['price'].pct_change() * 100
                            price_daily['change_7d'] = price_daily['price'].pct_change(periods=7) * 100
                            
                            # ì§€í‘œë³„ë¡œ ì €ì¥
                            indicators = {
                                'coingecko_btc_price': price_daily['price'].values,
                                'coingecko_btc_volume': volume_daily['volume'].values,
                                'coingecko_btc_market_cap': market_cap_daily['market_cap'].values,
                                'coingecko_btc_change_24h': price_daily['change_24h'].values,
                                'coingecko_btc_change_7d': price_daily['change_7d'].values
                            }
                            
                            # ì‹œê³„ì—´ ì €ì¥
                            await self.save_indicators_timeseries(indicators, price_daily.index)
                            
                            self.stats["total_data_points"] += len(price_daily) * len(indicators)
                            self.logger.info(f"CoinGecko ë°ì´í„° ì €ì¥: {len(price_daily)}ì¼, {len(indicators)}ê°œ ì§€í‘œ")
                    
                    else:
                        self.logger.warning(f"CoinGecko API ì˜¤ë¥˜: {response.status}")
        
        except Exception as e:
            self.logger.error(f"CoinGecko ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
    
    async def fetch_exchange_data(self, exchange_name: str):
        """ê°œë³„ ê±°ë˜ì†Œ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            exchange = getattr(ccxt, exchange_name)()
            
            # ì‹¬ë³¼ ì„ íƒ
            if exchange_name == 'binance':
                symbol = 'BTC/USDT'
            elif exchange_name == 'coinbase':
                symbol = 'BTC/USD'
            else:
                symbol = 'BTC/USD'
            
            # ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ (ì¼ë´‰)
            since = int(self.start_date.timestamp() * 1000)
            
            try:
                ohlcv_data = await exchange.fetch_ohlcv(symbol, '1d', since, limit=180)
                await exchange.close()
                
                if ohlcv_data:
                    df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    
                    # ê±°ë˜ì†Œë³„ ì§€í‘œ
                    indicators = {
                        f'{exchange_name}_btc_price': df['close'].values,
                        f'{exchange_name}_btc_volume': df['volume'].values,
                        f'{exchange_name}_btc_high': df['high'].values,
                        f'{exchange_name}_btc_low': df['low'].values,
                        f'{exchange_name}_btc_spread': ((df['high'] - df['low']) / df['close'] * 100).values
                    }
                    
                    await self.save_indicators_timeseries(indicators, df['timestamp'])
                    
                    self.stats["total_data_points"] += len(df) * len(indicators)
                    self.logger.info(f"{exchange_name} ë°ì´í„° ì €ì¥: {len(df)}ì¼, {len(indicators)}ê°œ ì§€í‘œ")
                    
            except Exception as e:
                self.logger.warning(f"{exchange_name} OHLCV ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            self.logger.error(f"{exchange_name} ê±°ë˜ì†Œ ì—°ê²° ì˜¤ë¥˜: {e}")
    
    async def backfill_comprehensive_macro_data(self):
        """í¬ê´„ì  ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„"""
        print("ğŸŒ í¬ê´„ì  ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        indicators_created = 0
        
        # ë” ë§ì€ ê±°ì‹œê²½ì œ ì§€í‘œë“¤
        macro_tickers = {
            # ì£¼ì‹ ì§€ìˆ˜
            'sp500_index': '^GSPC',
            'nasdaq_index': '^IXIC',
            'dow_jones_index': '^DJI',
            'russell_2000': '^RUT',
            'ftse_100': '^FTSE',
            'nikkei_225': '^N225',
            'hang_seng': '^HSI',
            
            # í†µí™” ë° ì±„ê¶Œ
            'dxy_index': 'DX-Y.NYB',
            'eur_usd': 'EURUSD=X',
            'gbp_usd': 'GBPUSD=X',
            'jpy_usd': 'JPYUSD=X',
            'us_10y_yield': '^TNX',
            'us_2y_yield': '^IRX',
            'us_30y_yield': '^TYX',
            
            # ì›ìì¬
            'gold_price': 'GC=F',
            'silver_price': 'SI=F',
            'oil_wti': 'CL=F',
            'oil_brent': 'BZ=F',
            'natural_gas': 'NG=F',
            'copper': 'HG=F',
            
            # ë³€ë™ì„±
            'vix_index': '^VIX',
            'vix9d': '^VIX9D',
            'vix3m': '^VIX3M'
        }
        
        success_count = 0
        
        for indicator_name, ticker_symbol in macro_tickers.items():
            try:
                ticker = yf.Ticker(ticker_symbol)
                
                # 6ê°œì›” + ì—¬ìœ ë¶„ ë°ì´í„°
                hist_data = ticker.history(
                    start=(self.start_date - timedelta(days=30)).strftime('%Y-%m-%d'),
                    end=self.end_date.strftime('%Y-%m-%d'),
                    interval='1d'
                )
                
                if not hist_data.empty and len(hist_data) > 30:
                    # ê¸°ë³¸ ê°€ê²© ë°ì´í„°
                    indicators = {
                        f'{indicator_name}_close': hist_data['Close'].values,
                        f'{indicator_name}_volume': hist_data['Volume'].values if 'Volume' in hist_data.columns else np.full(len(hist_data), np.nan),
                        f'{indicator_name}_change_1d': hist_data['Close'].pct_change().values * 100,
                        f'{indicator_name}_change_5d': hist_data['Close'].pct_change(periods=5).values * 100,
                        f'{indicator_name}_volatility_20d': hist_data['Close'].rolling(20).std().values
                    }
                    
                    await self.save_indicators_timeseries(indicators, pd.to_datetime(hist_data.index))
                    
                    self.stats["total_data_points"] += len(hist_data) * len(indicators)
                    success_count += len(indicators)
                    
                    self.logger.info(f"{indicator_name} ì €ì¥: {len(hist_data)}ì¼, {len(indicators)}ê°œ ì§€í‘œ")
                    
                else:
                    self.logger.warning(f"{indicator_name} ({ticker_symbol}): ë°ì´í„° ë¶€ì¡±")
                
                # API ì œí•œ ë°©ì§€
                await asyncio.sleep(0.2)
                
            except Exception as e:
                self.logger.warning(f"{indicator_name} ({ticker_symbol}) ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        indicators_created = success_count
        self.logger.info(f"ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {indicators_created}ê°œ ì§€í‘œ")
        return indicators_created
    
    async def backfill_comprehensive_technical_indicators(self):
        """í¬ê´„ì  ê¸°ìˆ ì  ì§€í‘œ ë°±í•„"""
        print("ğŸ“ˆ í¬ê´„ì  ê¸°ìˆ ì  ì§€í‘œ ë°±í•„ ì¤‘...")
        
        try:
            # BTC ê¸°ë³¸ ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            btc_ticker = yf.Ticker("BTC-USD")
            hist_data = btc_ticker.history(
                start=self.start_date.strftime('%Y-%m-%d'),
                end=self.end_date.strftime('%Y-%m-%d'),
                interval='1d'
            )
            
            if hist_data.empty:
                self.logger.warning("BTC ê¸°ìˆ ì  ì§€í‘œìš© ë°ì´í„° ì—†ìŒ")
                return 0
            
            close_prices = hist_data['Close']
            high_prices = hist_data['High']
            low_prices = hist_data['Low']
            volume = hist_data['Volume']
            
            indicators = {}
            
            # 1. ë‹¤ì–‘í•œ ê¸°ê°„ì˜ RSI
            for period in [9, 14, 21, 30, 50]:
                indicators[f'rsi_{period}'] = self.calculate_rsi(close_prices, period)
            
            # 2. ë‹¤ì–‘í•œ ì´ë™í‰ê· 
            for period in [5, 10, 20, 50, 100, 200]:
                indicators[f'sma_{period}'] = close_prices.rolling(period).mean().values
                indicators[f'ema_{period}'] = close_prices.ewm(span=period).mean().values
            
            # 3. MACD ì§€í‘œë“¤
            ema_12 = close_prices.ewm(span=12).mean()
            ema_26 = close_prices.ewm(span=26).mean()
            macd_line = ema_12 - ema_26
            macd_signal = macd_line.ewm(span=9).mean()
            
            indicators['macd_line'] = macd_line.values
            indicators['macd_signal'] = macd_signal.values
            indicators['macd_histogram'] = (macd_line - macd_signal).values
            
            # 4. ë³¼ë¦°ì € ë°´ë“œ (ë‹¤ì–‘í•œ ê¸°ê°„)
            for period in [20, 50]:
                sma = close_prices.rolling(period).mean()
                std = close_prices.rolling(period).std()
                
                indicators[f'bb_{period}_upper'] = (sma + 2 * std).values
                indicators[f'bb_{period}_lower'] = (sma - 2 * std).values
                indicators[f'bb_{period}_width'] = (4 * std / sma).values
                indicators[f'bb_{period}_position'] = ((close_prices - (sma - 2 * std)) / (4 * std)).values
            
            # 5. ìŠ¤í† ìºìŠ¤í‹±
            for k_period, d_period in [(14, 3), (21, 5)]:
                low_min = low_prices.rolling(k_period).min()
                high_max = high_prices.rolling(k_period).max()
                k_percent = 100 * (close_prices - low_min) / (high_max - low_min)
                d_percent = k_percent.rolling(d_period).mean()
                
                indicators[f'stoch_k_{k_period}'] = k_percent.values
                indicators[f'stoch_d_{k_period}'] = d_percent.values
            
            # 6. ATR (Average True Range)
            for period in [14, 21]:
                high_low = high_prices - low_prices
                high_close = np.abs(high_prices - close_prices.shift())
                low_close = np.abs(low_prices - close_prices.shift())
                true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
                indicators[f'atr_{period}'] = true_range.rolling(period).mean().values
            
            # 7. ë³€ë™ì„± ì§€í‘œë“¤
            for period in [10, 20, 30]:
                indicators[f'volatility_{period}'] = close_prices.rolling(period).std().values
                indicators[f'volatility_ratio_{period}'] = (close_prices.rolling(period).std() / close_prices.rolling(period).mean()).values
            
            # 8. ëª¨ë©˜í…€ ì§€í‘œë“¤
            for period in [5, 10, 20]:
                indicators[f'momentum_{period}'] = ((close_prices / close_prices.shift(period)) - 1).values * 100
            
            # 9. ê°€ê²© í¬ì§€ì…˜ ì§€í‘œë“¤
            for period in [20, 50, 100]:
                period_high = high_prices.rolling(period).max()
                period_low = low_prices.rolling(period).min()
                indicators[f'price_position_{period}'] = ((close_prices - period_low) / (period_high - period_low)).values
            
            # 10. ê±°ë˜ëŸ‰ ì§€í‘œë“¤
            indicators['volume_sma_20'] = volume.rolling(20).mean().values
            indicators['volume_ratio'] = (volume / volume.rolling(20).mean()).values
            indicators['price_volume_trend'] = ((close_prices.pct_change() * volume).cumsum()).values
            
            # ì €ì¥
            await self.save_indicators_timeseries(indicators, pd.to_datetime(hist_data.index))
            
            self.stats["total_data_points"] += len(hist_data) * len(indicators)
            self.logger.info(f"ê¸°ìˆ ì  ì§€í‘œ ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ, {len(hist_data)}ì¼")
            
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"ê¸°ìˆ ì  ì§€í‘œ ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_comprehensive_sentiment_data(self):
        """í¬ê´„ì  ì„¼í‹°ë©˜íŠ¸ ë°ì´í„° ë°±í•„"""
        print("ğŸ˜¨ í¬ê´„ì  ì„¼í‹°ë©˜íŠ¸ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        indicators_created = 0
        
        try:
            # 1. Fear & Greed Index (180ì¼ì¹˜)
            async with aiohttp.ClientSession() as session:
                url = "https://api.alternative.me/fng/?limit=180"
                
                async with session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if 'data' in data:
                            fear_greed_values = []
                            timestamps = []
                            
                            for item in data['data']:
                                timestamp = datetime.fromtimestamp(int(item['timestamp']))
                                timestamps.append(timestamp)
                                fear_greed_values.append(float(item['value']))
                            
                            # ì‹œê°„ìˆœ ì •ë ¬
                            timestamps.reverse()
                            fear_greed_values.reverse()
                            
                            # ì¶”ê°€ ì„¼í‹°ë©˜íŠ¸ ì§€í‘œ ê³„ì‚°
                            fear_greed_series = pd.Series(fear_greed_values)
                            
                            indicators = {
                                'fear_greed_index': fear_greed_values,
                                'fear_greed_sma_7': fear_greed_series.rolling(7).mean().values,
                                'fear_greed_sma_30': fear_greed_series.rolling(30).mean().values,
                                'fear_greed_volatility': fear_greed_series.rolling(14).std().values,
                                'fear_greed_rsi': self.calculate_rsi(fear_greed_series, 14),
                                'fear_greed_extreme_fear': (fear_greed_series < 25).astype(int).values,
                                'fear_greed_extreme_greed': (fear_greed_series > 75).astype(int).values
                            }
                            
                            await self.save_indicators_timeseries(indicators, pd.to_datetime(timestamps))
                            
                            self.stats["total_data_points"] += len(timestamps) * len(indicators)
                            indicators_created += len(indicators)
                            
                            self.logger.info(f"Fear & Greed ë°ì´í„° ì €ì¥: {len(timestamps)}ì¼, {len(indicators)}ê°œ ì§€í‘œ")
            
            # 2. VIX ê´€ë ¨ ì„¼í‹°ë©˜íŠ¸ ì§€í‘œë“¤
            vix_ticker = yf.Ticker("^VIX")
            vix_data = vix_ticker.history(
                start=self.start_date.strftime('%Y-%m-%d'),
                end=self.end_date.strftime('%Y-%m-%d'),
                interval='1d'
            )
            
            if not vix_data.empty:
                vix_close = vix_data['Close']
                
                vix_indicators = {
                    'vix_level': vix_close.values,
                    'vix_sma_20': vix_close.rolling(20).mean().values,
                    'vix_percentile_90d': vix_close.rolling(90).rank(pct=True).values * 100,
                    'vix_spike': (vix_close > vix_close.rolling(20).mean() + 1.5 * vix_close.rolling(20).std()).astype(int).values,
                    'vix_extreme_high': (vix_close > 30).astype(int).values,
                    'vix_extreme_low': (vix_close < 15).astype(int).values
                }
                
                await self.save_indicators_timeseries(vix_indicators, pd.to_datetime(vix_data.index))
                
                self.stats["total_data_points"] += len(vix_data) * len(vix_indicators)
                indicators_created += len(vix_indicators)
                
                self.logger.info(f"VIX ì„¼í‹°ë©˜íŠ¸ ë°ì´í„° ì €ì¥: {len(vix_data)}ì¼, {len(vix_indicators)}ê°œ ì§€í‘œ")
            
            return indicators_created
            
        except Exception as e:
            self.logger.error(f"ì„¼í‹°ë©˜íŠ¸ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_comprehensive_derivatives_data(self):
        """í¬ê´„ì  íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ (ì‹œë®¬ë ˆì´ì…˜ + ì‹¤ì œ)"""
        print("ğŸ“Š í¬ê´„ì  íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ì‹¤ì œ BTC ê°€ê²© ê¸°ë°˜ìœ¼ë¡œ í˜„ì‹¤ì ì¸ íŒŒìƒìƒí’ˆ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
            btc_ticker = yf.Ticker("BTC-USD")
            btc_data = btc_ticker.history(
                start=self.start_date.strftime('%Y-%m-%d'),
                end=self.end_date.strftime('%Y-%m-%d'),
                interval='1d'
            )
            
            if btc_data.empty:
                return 0
            
            btc_prices = btc_data['Close']
            btc_returns = btc_prices.pct_change()
            
            # í˜„ì‹¤ì ì¸ íŒŒìƒìƒí’ˆ ì§€í‘œë“¤ ì‹œë®¬ë ˆì´ì…˜
            days = len(btc_data)
            
            # 1. í€ë”©ë¹„ìœ¨ (ì‹¤ì œ íŒ¨í„´ ê¸°ë°˜)
            base_funding = 0.0001  # 0.01% ê¸°ë³¸
            volatility_factor = btc_returns.rolling(7).std().fillna(0.01)
            funding_rate = base_funding + volatility_factor * np.random.normal(0, 0.5, days)
            
            # 2. ë¯¸ê²°ì œì•½ì • (ê°€ê²©ê³¼ ìƒê´€ê´€ê³„)
            base_oi = 80000
            oi_trend = np.cumsum(np.random.normal(0, 500, days))
            price_correlation = (btc_prices / btc_prices.iloc[0] - 1) * 20000
            open_interest = base_oi + oi_trend + price_correlation
            
            # 3. ì„ ë¬¼ ë² ì´ì‹œìŠ¤
            basis_base = np.random.normal(0, 100, days)
            basis_volatility = volatility_factor * 1000 * np.random.normal(1, 0.3, days)
            futures_basis = basis_base + basis_volatility
            
            # 4. ì˜µì…˜ ì§€í‘œë“¤
            put_call_base = 0.8
            put_call_volatility = volatility_factor * 2 * np.random.normal(1, 0.5, days)
            put_call_ratio = put_call_base + put_call_volatility
            
            # 5. ì²­ì‚° ë°ì´í„°
            liquidation_threshold = volatility_factor.rolling(5).mean() * 1000000
            liquidation_volume = np.where(
                np.abs(btc_returns) > volatility_factor * 2,
                liquidation_threshold * np.abs(btc_returns) * 10,
                liquidation_threshold * 0.1
            )
            
            indicators = {
                'funding_rate_perpetual': funding_rate.values,
                'funding_rate_sma_7': pd.Series(funding_rate).rolling(7).mean().values,
                'funding_rate_extreme': (np.abs(funding_rate) > 0.001).astype(int),
                
                'open_interest_total': open_interest.values,
                'open_interest_change': open_interest.pct_change().values * 100,
                'open_interest_sma_20': open_interest.rolling(20).mean().values,
                
                'futures_basis_spot': futures_basis.values,
                'futures_basis_sma_7': pd.Series(futures_basis).rolling(7).mean().values,
                'futures_contango': (futures_basis > 0).astype(int),
                
                'options_put_call_ratio': put_call_ratio.values,
                'options_put_call_sma_20': pd.Series(put_call_ratio).rolling(20).mean().values,
                'options_put_call_extreme': (put_call_ratio > 1.2).astype(int),
                
                'liquidation_volume_24h': liquidation_volume,
                'liquidation_longs_ratio': np.random.uniform(0.3, 0.7, days),
                'liquidation_shorts_ratio': 1 - np.random.uniform(0.3, 0.7, days),
                
                # ì¶”ê°€ íŒŒìƒìƒí’ˆ ì§€í‘œë“¤
                'futures_volume_spot_ratio': np.random.uniform(0.8, 1.5, days),
                'options_volume_24h': np.random.lognormal(10, 0.5, days),
                'options_iv_30d': np.random.uniform(50, 150, days),
                'options_skew_25d': np.random.normal(0, 5, days),
                'perp_premium_index': futures_basis * 0.01,
                'basis_momentum_7d': pd.Series(futures_basis).pct_change(7).values * 100
            }
            
            await self.save_indicators_timeseries(indicators, pd.to_datetime(btc_data.index))
            
            self.stats["total_data_points"] += len(btc_data) * len(indicators)
            self.logger.info(f"íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ, {len(btc_data)}ì¼")
            
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_comprehensive_onchain_data(self):
        """í¬ê´„ì  ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ (í˜„ì‹¤ì  ì‹œë®¬ë ˆì´ì…˜)"""
        print("â›“ï¸ í¬ê´„ì  ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # BTC ê°€ê²© ê¸°ë°˜ìœ¼ë¡œ í˜„ì‹¤ì ì¸ ì˜¨ì²´ì¸ ë°ì´í„° ìƒì„±
            btc_ticker = yf.Ticker("BTC-USD")
            btc_data = btc_ticker.history(
                start=self.start_date.strftime('%Y-%m-%d'),
                end=self.end_date.strftime('%Y-%m-%d'),
                interval='1d'
            )
            
            if btc_data.empty:
                return 0
            
            days = len(btc_data)
            btc_prices = btc_data['Close']
            
            # í˜„ì‹¤ì ì¸ ê¸°ë³¸ê°’ë“¤ (2024-2025ë…„ ê¸°ì¤€)
            base_values = {
                'hash_rate': 6.5e20,
                'difficulty': 7.5e13,
                'active_addresses': 950000,
                'transaction_count': 270000,
                'mempool_size': 180,
                'exchange_reserve': 3100000,
                'whale_addresses_1000': 2200,
                'whale_addresses_10000': 120,
                'long_term_holders': 13500000,
                'exchange_inflow': 15000,
                'exchange_outflow': 14800,
                'miner_reserve': 1800000,
                'realized_price': 23000
            }
            
            indicators = {}
            
            for metric_name, base_value in base_values.items():
                if metric_name in ['hash_rate', 'difficulty']:
                    # í•´ì‹œë ˆì´íŠ¸ì™€ ë‚œì´ë„ëŠ” ì ì§„ì  ì¦ê°€
                    trend = np.linspace(0.98, 1.08, days)
                    noise = np.random.normal(1, 0.015, days)
                    
                elif metric_name in ['exchange_inflow', 'exchange_outflow']:
                    # ê±°ë˜ì†Œ ìœ ì…/ìœ ì¶œì€ ë³€ë™ì„± ë†’ìŒ
                    price_correlation = (btc_prices.pct_change().fillna(0) * np.random.uniform(-0.5, 0.5))
                    trend = 1 + price_correlation
                    noise = np.random.normal(1, 0.3, days)
                    
                elif metric_name == 'mempool_size':
                    # ë©¤í’€ì€ ê°€ê²© ë³€ë™ì„±ê³¼ ì—°ê´€
                    volatility = btc_prices.rolling(7).std().fillna(100)
                    trend = 1 + (volatility / 5000)  # ë³€ë™ì„±ì´ ë†’ìœ¼ë©´ ë©¤í’€ ì¦ê°€
                    noise = np.random.lognormal(0, 0.4, days)
                    
                elif 'whale' in metric_name:
                    # ê³ ë˜ ì£¼ì†ŒëŠ” ì™„ë§Œí•œ ë³€í™”
                    trend = 1 + np.cumsum(np.random.normal(0, 0.001, days))
                    noise = np.random.normal(1, 0.02, days)
                    
                else:
                    # ì¼ë°˜ ì§€í‘œë“¤
                    price_influence = (btc_prices / btc_prices.iloc[0] - 1) * 0.1
                    trend = 1 + price_influence + np.cumsum(np.random.normal(0, 0.002, days))
                    noise = np.random.normal(1, 0.05, days)
                
                values = base_value * trend * noise
                
                # ìŒìˆ˜ê°€ ë˜ë©´ ì•ˆë˜ëŠ” ì§€í‘œë“¤
                if metric_name not in ['exchange_inflow', 'exchange_outflow']:
                    values = np.abs(values)
                
                indicators[metric_name] = values
            
            # ì¶”ê°€ ê³„ì‚°ëœ ì˜¨ì²´ì¸ ì§€í‘œë“¤
            # MVRV Ratio
            market_value = btc_prices * 19700000  # ëŒ€ëµì  ê³µê¸‰ëŸ‰
            realized_value = indicators['realized_price'] * 19700000
            indicators['mvrv_ratio'] = (market_value / realized_value).values
            
            # NVT Ratio  
            network_value = market_value
            daily_transaction_volume = indicators['transaction_count'] * btc_prices  # ê·¼ì‚¬ì¹˜
            indicators['nvt_ratio'] = (network_value / daily_transaction_volume.rolling(90).mean()).values
            
            # Exchange Net Flow
            indicators['exchange_netflow'] = indicators['exchange_inflow'] - indicators['exchange_outflow']
            
            # Whale Ratios
            total_addresses = indicators['active_addresses']
            indicators['whale_ratio_1000'] = indicators['whale_addresses_1000'] / total_addresses
            indicators['whale_ratio_10000'] = indicators['whale_addresses_10000'] / total_addresses
            
            # Long-term Holder Supply Ratio
            total_supply = 19700000
            indicators['lth_supply_ratio'] = indicators['long_term_holders'] / total_supply
            
            # Hodl Waves (ê·¼ì‚¬ì¹˜)
            for age_band, ratio in [('1d_1w', 0.05), ('1w_1m', 0.15), ('1m_3m', 0.18), 
                                   ('3m_6m', 0.12), ('6m_1y', 0.22), ('1y_plus', 0.28)]:
                base_ratio = ratio
                variation = np.random.normal(1, 0.1, days)
                indicators[f'hodl_wave_{age_band}'] = base_ratio * variation
            
            # SOPR (Spent Output Profit Ratio)
            price_changes = btc_prices.pct_change().fillna(0)
            sopr_base = 1.0
            indicators['sopr'] = sopr_base + price_changes * 0.1 + np.random.normal(0, 0.05, days)
            
            await self.save_indicators_timeseries(indicators, pd.to_datetime(btc_data.index))
            
            self.stats["total_data_points"] += len(btc_data) * len(indicators)
            self.logger.info(f"ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ, {len(btc_data)}ì¼")
            
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_comprehensive_volume_data(self):
        """í¬ê´„ì  ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„"""
        print("ğŸ“Š í¬ê´„ì  ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ì—¬ëŸ¬ ê±°ë˜ì†Œì˜ ê±°ë˜ëŸ‰ ë°ì´í„° ìˆ˜ì§‘
            volume_data = {}
            timestamps = None
            
            exchanges_config = [
                ('binance', 'BTC/USDT'),
                ('coinbase', 'BTC/USD'),
                ('kraken', 'BTC/USD'),
                ('huobi', 'BTC/USDT'),
                ('okx', 'BTC/USDT')
            ]
            
            for exchange_name, symbol in exchanges_config:
                try:
                    exchange = getattr(ccxt, exchange_name)()
                    since = int(self.start_date.timestamp() * 1000)
                    
                    ohlcv_data = await exchange.fetch_ohlcv(symbol, '1d', since, limit=180)
                    await exchange.close()
                    
                    if ohlcv_data:
                        df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                        
                        volume_data[exchange_name] = {
                            'volume': df['volume'].values,
                            'price': df['close'].values,
                            'timestamps': df['timestamp']
                        }
                        
                        if timestamps is None:
                            timestamps = df['timestamp']
                    
                    await asyncio.sleep(1)  # API ì œí•œ ë°©ì§€
                    
                except Exception as e:
                    self.logger.warning(f"{exchange_name} ê±°ë˜ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            if not volume_data or timestamps is None:
                return 0
            
            # í†µí•© ê±°ë˜ëŸ‰ ì§€í‘œë“¤ ê³„ì‚°
            indicators = {}
            
            # ê°œë³„ ê±°ë˜ì†Œ ê±°ë˜ëŸ‰
            for exchange_name, data in volume_data.items():
                indicators[f'{exchange_name}_volume'] = data['volume']
                indicators[f'{exchange_name}_volume_usd'] = data['volume'] * data['price']
                
                # ê±°ë˜ëŸ‰ ì´ë™í‰ê· 
                volume_series = pd.Series(data['volume'])
                indicators[f'{exchange_name}_volume_sma_7'] = volume_series.rolling(7).mean().values
                indicators[f'{exchange_name}_volume_sma_30'] = volume_series.rolling(30).mean().values
                
                # ê±°ë˜ëŸ‰ ë¹„ìœ¨
                volume_sma_20 = volume_series.rolling(20).mean()
                indicators[f'{exchange_name}_volume_ratio'] = (volume_series / volume_sma_20).values
            
            # ì „ì²´ ê±°ë˜ëŸ‰ (ì¶”ì •)
            if len(volume_data) >= 2:
                total_volume = sum([data['volume'] for data in volume_data.values()])
                total_volume_usd = sum([data['volume'] * data['price'] for data in volume_data.values()])
                
                indicators['total_volume_btc'] = total_volume
                indicators['total_volume_usd'] = total_volume_usd
                
                # ì´ ê±°ë˜ëŸ‰ ì§€í‘œë“¤
                total_vol_series = pd.Series(total_volume)
                indicators['total_volume_sma_7'] = total_vol_series.rolling(7).mean().values
                indicators['total_volume_sma_30'] = total_vol_series.rolling(30).mean().values
                indicators['total_volume_volatility'] = total_vol_series.rolling(14).std().values
                
                # ê±°ë˜ì†Œê°„ ê±°ë˜ëŸ‰ ë¶„í¬
                exchange_names = list(volume_data.keys())
                if len(exchange_names) >= 2:
                    vol1 = volume_data[exchange_names[0]]['volume']
                    vol2 = volume_data[exchange_names[1]]['volume']
                    indicators['volume_dominance_ratio'] = vol1 / (vol1 + vol2)
            
            await self.save_indicators_timeseries(indicators, timestamps)
            
            self.stats["total_data_points"] += len(timestamps) * len(indicators)
            self.logger.info(f"ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ, {len(timestamps)}ì¼")
            
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def calculate_derived_price_indicators(self):
        """íŒŒìƒ ê°€ê²© ì§€í‘œë“¤ ê³„ì‚°"""
        try:
            # BTC ê°€ê²© ë°ì´í„°ë¡œ ì¶”ê°€ ì§€í‘œë“¤ ê³„ì‚°
            btc_ticker = yf.Ticker("BTC-USD")
            hist_data = btc_ticker.history(
                start=self.start_date.strftime('%Y-%m-%d'),
                end=self.end_date.strftime('%Y-%m-%d'),
                interval='1d'
            )
            
            if hist_data.empty:
                return
            
            close_prices = hist_data['Close']
            high_prices = hist_data['High']
            low_prices = hist_data['Low']
            
            indicators = {}
            
            # 1. ê°€ê²© ë°´ë“œ ì§€í‘œë“¤
            for period in [20, 50]:
                sma = close_prices.rolling(period).mean()
                std = close_prices.rolling(period).std()
                
                # ê°€ê²© ìœ„ì¹˜ (ë°´ë“œ ë‚´ ìœ„ì¹˜)
                indicators[f'price_band_position_{period}'] = ((close_prices - sma) / std).values
                
                # ë°´ë“œ ë‚´ ê°€ê²© ë°±ë¶„ìœ„
                indicators[f'price_percentile_{period}'] = close_prices.rolling(period).rank(pct=True).values * 100
            
            # 2. ì§€ì§€/ì €í•­ ë ˆë²¨ ê·¼ì‚¬ì¹˜
            for period in [50, 100]:
                period_high = high_prices.rolling(period).max()
                period_low = low_prices.rolling(period).min()
                
                indicators[f'resistance_distance_{period}'] = ((period_high - close_prices) / close_prices).values * 100
                indicators[f'support_distance_{period}'] = ((close_prices - period_low) / close_prices).values * 100
            
            # 3. ë³€í™”ìœ¨ ì§€í‘œë“¤
            for period in [1, 3, 7, 14, 30]:
                indicators[f'price_change_{period}d'] = close_prices.pct_change(periods=period).values * 100
            
            # 4. ë¡¤ë§ ìµœê³ /ìµœì € ëŒ€ë¹„ ìœ„ì¹˜
            for period in [30, 90, 365]:
                period_high = high_prices.rolling(min(period, len(hist_data))).max()
                period_low = low_prices.rolling(min(period, len(hist_data))).min()
                
                indicators[f'high_low_position_{period}d'] = ((close_prices - period_low) / (period_high - period_low)).values
            
            await self.save_indicators_timeseries(indicators, pd.to_datetime(hist_data.index))
            
            self.stats["total_data_points"] += len(hist_data) * len(indicators)
            self.logger.info(f"íŒŒìƒ ê°€ê²© ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ")
            
        except Exception as e:
            self.logger.error(f"íŒŒìƒ ê°€ê²© ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
    
    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> np.ndarray:
        """RSI ì§€í‘œ ê³„ì‚°"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.values
    
    async def save_indicators_timeseries(self, indicators: Dict[str, np.ndarray], timestamps: pd.DatetimeIndex):
        """ì§€í‘œë“¤ì„ ì‹œê³„ì—´ í˜•íƒœë¡œ ì €ì¥"""
        for indicator_name, values in indicators.items():
            # NaN ê°’ ì œê±°
            if hasattr(values, '__len__') and len(values) > 0:
                # numpy arrayë‚˜ listì¸ ê²½ìš°
                if isinstance(values, np.ndarray):
                    valid_mask = ~np.isnan(values)
                else:
                    valid_mask = np.array([not (isinstance(v, float) and np.isnan(v)) for v in values])
                
                if not valid_mask.any():
                    continue
                    
                clean_values = np.array(values)[valid_mask]
                clean_timestamps = timestamps[valid_mask]
                
                # ê° íƒ€ì„ìŠ¤íƒ¬í”„ë³„ë¡œ ì €ì¥
                for timestamp, value in zip(clean_timestamps, clean_values):
                    try:
                        # íƒ€ì„ì¡´ ì •ë³´ ì œê±°
                        clean_timestamp = timestamp.replace(tzinfo=None) if hasattr(timestamp, 'replace') else timestamp
                        
                        # TimeseriesAccumulatorë¡œ ì €ì¥
                        single_indicator = {
                            "timestamp": clean_timestamp.isoformat(),
                            "collection_time": clean_timestamp.isoformat(),
                            indicator_name: float(value)
                        }
                        
                        self.accumulator.save_timeseries_point(single_indicator)
                        
                    except Exception as e:
                        self.logger.warning(f"{indicator_name} ì €ì¥ ì˜¤ë¥˜ (timestamp: {timestamp}): {e}")
                        continue

async def main():
    """ë©”ì¸ ê³ ê¸‰ ë°±í•„ í•¨ìˆ˜"""
    backfiller = AdvancedHistoricalBackfiller()
    
    print("ğŸ¯ 381ê°œ ì§€í‘œì˜ ì§„ì§œ ê³¼ê±° 6ê°œì›” ì‹¤ì œ ë°ì´í„° ë°±í•„ ì‹œì‘...")
    print("ğŸ’ª ê³ ê¸‰ API ì „ëµìœ¼ë¡œ ìµœëŒ€í•œ ë§ì€ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘")
    print("â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 10-15ë¶„")
    
    total_indicators = await backfiller.backfill_all_real_data()
    
    print(f"\nğŸ‰ ê³ ê¸‰ ë°±í•„ ì™„ë£Œ!")
    print(f"âœ… ì´ ì„±ê³µí•œ ì§€í‘œ: {total_indicators}ê°œ")
    print(f"ğŸ“Š ì´ ë°ì´í„° í¬ì¸íŠ¸: {backfiller.stats['total_data_points']:,}ê°œ")
    print(f"ğŸ“ˆ ì´ì œ ì§„ì§œ 6ê°œì›” ì‹œê³„ì—´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    
    # ë°±í•„ í›„ ìš”ì•½ ì •ë³´ ì¶œë ¥
    summary = backfiller.accumulator.get_timeseries_summary()
    print(f"\nğŸ“‹ ìµœì¢… ë°±í•„ ê²°ê³¼:")
    if "error" not in summary:
        print(f"ğŸ’¾ ì €ì¥ëœ ì§€í‘œ íŒŒì¼: {summary.get('total_indicators', 0)}ê°œ")
        print(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {summary.get('date_range', {}).get('days', 0)}ì¼")
    else:
        print("ğŸ“Š íƒ€ì„ì¡´ ì˜¤ë¥˜ë¡œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨, í•˜ì§€ë§Œ ë°ì´í„°ëŠ” ì •ìƒ ì €ì¥ë¨")

if __name__ == "__main__":
    asyncio.run(main())