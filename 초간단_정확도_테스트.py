#!/usr/bin/env python3
"""
âš¡ ì´ˆê°„ë‹¨ ì •í™•ë„ í…ŒìŠ¤íŠ¸
- í˜„ì¬ ëª¨ë¸ ì„±ëŠ¥ ë¹ ë¥´ê²Œ í™•ì¸
- ì£¼ìš” ê°œì„  ì•„ì´ë””ì–´ë§Œ í…ŒìŠ¤íŠ¸
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

def quick_test():
    print("âš¡ ì´ˆê°„ë‹¨ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ ë°ì´í„° ë¡œë”©...")
    df = pd.read_csv("ai_optimized_3month_data/ai_matrix_complete.csv")
    
    # BTC ê°€ê²© ì»¬ëŸ¼
    btc_col = 'onchain_blockchain_info_network_stats_market_price_usd'
    if btc_col not in df.columns:
        btc_col = df.columns[0]
    
    print(f"ğŸ¯ íƒ€ê²Ÿ: {btc_col}")
    print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape}")
    
    # ê¸°ë³¸ ì „ì²˜ë¦¬
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df_clean = df[numeric_cols].fillna(0).replace([np.inf, -np.inf], 0)
    
    # X, y ë¶„ë¦¬
    X = df_clean.drop(columns=[btc_col]).values
    y = df_clean[btc_col].shift(-1).dropna().values
    X = X[:-1]
    
    print(f"ğŸ“ˆ X shape: {X.shape}, y shape: {y.shape}")
    
    # ê°„ë‹¨í•œ train/test ë¶„í•  (ìµœê·¼ 20% í…ŒìŠ¤íŠ¸)
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"ğŸ”„ Train: {len(X_train)}, Test: {len(X_test)}")
    
    # 1. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
    print("\n1ï¸âƒ£ ë² ì´ìŠ¤ë¼ì¸ í…ŒìŠ¤íŠ¸...")
    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    rf = RandomForestRegressor(n_estimators=30, random_state=42)
    rf.fit(X_train_scaled, y_train)
    pred_baseline = rf.predict(X_test_scaled)
    
    r2_baseline = r2_score(y_test, pred_baseline)
    acc_baseline = max(0, r2_baseline * 100)
    print(f"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ì •í™•ë„: {acc_baseline:.2f}%")
    
    # 2. í”¼ì²˜ ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ
    print("\n2ï¸âƒ£ ìƒìœ„ í”¼ì²˜ë§Œ ì‚¬ìš©...")
    feature_importance = rf.feature_importances_
    top_indices = np.argsort(feature_importance)[-200:]  # ìƒìœ„ 200ê°œ
    
    X_train_top = X_train_scaled[:, top_indices]
    X_test_top = X_test_scaled[:, top_indices]
    
    rf_top = RandomForestRegressor(n_estimators=30, random_state=42)
    rf_top.fit(X_train_top, y_train)
    pred_top = rf_top.predict(X_test_top)
    
    r2_top = r2_score(y_test, pred_top)
    acc_top = max(0, r2_top * 100)
    print(f"ğŸ“Š ìƒìœ„ í”¼ì²˜ ì •í™•ë„: {acc_top:.2f}%")
    
    # 3. ì•™ìƒë¸” (2ê°œ ëª¨ë¸)
    print("\n3ï¸âƒ£ ê°„ë‹¨ ì•™ìƒë¸”...")
    from sklearn.ensemble import GradientBoostingRegressor
    
    gbm = GradientBoostingRegressor(n_estimators=30, random_state=42)
    gbm.fit(X_train_scaled, y_train)
    pred_gbm = gbm.predict(X_test_scaled)
    
    # ì•™ìƒë¸” (50:50)
    pred_ensemble = (pred_baseline + pred_gbm) / 2
    
    r2_ensemble = r2_score(y_test, pred_ensemble)
    acc_ensemble = max(0, r2_ensemble * 100)
    print(f"ğŸ“Š ì•™ìƒë¸” ì •í™•ë„: {acc_ensemble:.2f}%")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 50)
    print("ğŸ† ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    print(f"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸:     {acc_baseline:.2f}%")
    print(f"ğŸ” ìƒìœ„ í”¼ì²˜:     {acc_top:.2f}%")  
    print(f"âš–ï¸ ì•™ìƒë¸”:         {acc_ensemble:.2f}%")
    print("-" * 50)
    
    best_acc = max(acc_baseline, acc_top, acc_ensemble)
    print(f"ğŸ¯ ìµœê³  ì •í™•ë„:   {best_acc:.2f}%")
    
    if best_acc >= 85:
        print("ğŸ‰ ëª©í‘œ ë‹¬ì„±! (85% ì´ìƒ)")
    else:
        need_improvement = 85 - best_acc
        print(f"âš ï¸ ëª©í‘œ ë¯¸ë‹¬ (ì¶”ê°€ {need_improvement:.1f}% í•„ìš”)")
    
    print("=" * 50)
    
    return {
        'baseline': acc_baseline,
        'top_features': acc_top, 
        'ensemble': acc_ensemble,
        'best': best_acc
    }

if __name__ == "__main__":
    results = quick_test()