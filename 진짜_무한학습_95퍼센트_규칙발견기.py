#!/usr/bin/env python3
"""
ğŸ”¥ ì§„ì§œ ë¬´í•œí•™ìŠµ 95% ê·œì¹™ ë°œê²¬ê¸°
- ë‹¤ë°©ë©´ ì˜ˆì¸¡ ì‹œë„ â†’ ì‹¤íŒ¨ ë¶„ì„ â†’ í•™ìŠµ â†’ ë¬´í•œ ë°˜ë³µ
- ê³µí†µ ê·œì¹™/íŒ¨í„´ ìë™ ë°œê²¬ ë° ì•ˆë‚´
- 95% ì„±ê³µë¥  ë‹¬ì„±ê¹Œì§€ ì§„í™”í•˜ëŠ” AI í•™ìŠµ ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import warnings
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, ElasticNet, Lasso, BayesianRidge
from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.model_selection import cross_val_score
import itertools
import random
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')

class InfiniteLearningRuleDiscoverer:
    """ì§„ì§œ ë¬´í•œí•™ìŠµ ê·œì¹™ ë°œê²¬ê¸°"""
    
    def __init__(self):
        self.data_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.historical_data = None
        
        # í•™ìŠµ ê¸°ë¡ ì €ì¥ì†Œ
        self.all_predictions = []  # ëª¨ë“  ì˜ˆì¸¡ ì‹œë„ ê¸°ë¡
        self.success_patterns = []  # ì„±ê³µí•œ íŒ¨í„´ë“¤
        self.failure_patterns = []  # ì‹¤íŒ¨í•œ íŒ¨í„´ë“¤
        self.discovered_rules = []  # ë°œê²¬ëœ ê³µí†µ ê·œì¹™ë“¤
        
        # ì„±ëŠ¥ ì¶”ì 
        self.total_attempts = 0
        self.success_count = 0
        self.current_success_rate = 0.0
        self.target_success_rate = 95.0
        
        # ë™ì  í•™ìŠµ íŒŒë¼ë¯¸í„°
        self.learning_weights = defaultdict(float)  # ì§€í‘œë³„ í•™ìŠµëœ ê°€ì¤‘ì¹˜
        self.pattern_memory = defaultdict(list)    # íŒ¨í„´ë³„ ì„±ê³µ/ì‹¤íŒ¨ ê¸°ë¡
        self.market_regime_rules = {}              # ì‹œì¥ ìƒí™©ë³„ ê·œì¹™
        
        # ë‹¤ë°©ë©´ ì˜ˆì¸¡ ì „ëµë“¤
        self.prediction_strategies = {
            'technical_focus': {'weight': 1.0, 'success': 0, 'attempts': 0},
            'onchain_focus': {'weight': 1.0, 'success': 0, 'attempts': 0},
            'macro_focus': {'weight': 1.0, 'success': 0, 'attempts': 0},
            'sentiment_focus': {'weight': 1.0, 'success': 0, 'attempts': 0},
            'hybrid_ensemble': {'weight': 1.0, 'success': 0, 'attempts': 0},
            'momentum_based': {'weight': 1.0, 'success': 0, 'attempts': 0},
            'mean_reversion': {'weight': 1.0, 'success': 0, 'attempts': 0}
        }
        
        print("ğŸ”¥ ì§„ì§œ ë¬´í•œí•™ìŠµ 95% ê·œì¹™ ë°œê²¬ê¸° ì´ˆê¸°í™”")
        print(f"ğŸ¯ ëª©í‘œ: {self.target_success_rate}% ì„±ê³µë¥  ë‹¬ì„±")
        
    def load_data(self) -> bool:
        """3ê°œì›” í†µí•© ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“‚ 3ê°œì›” í†µí•© ë°ì´í„° ë¡œë”©...")
        
        try:
            csv_path = os.path.join(self.data_path, "ai_optimized_3month_data", "ai_matrix_complete.csv")
            df = pd.read_csv(csv_path)
            
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.sort_values('timestamp').reset_index(drop=True)
            
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            self.historical_data = df[['timestamp'] + list(numeric_cols) if 'timestamp' in df.columns else list(numeric_cols)].copy()
            self.historical_data = self.historical_data.fillna(method='ffill').fillna(method='bfill').fillna(0)
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.historical_data.shape}")
            print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥ ì§€í‘œ: {len(numeric_cols)}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def categorize_all_indicators(self) -> Dict[str, List[str]]:
        """1,369ê°œ ì§€í‘œë¥¼ ì¹´í…Œê³ ë¦¬ë³„ ì™„ì „ ë¶„ë¥˜"""
        all_cols = [col for col in self.historical_data.columns if col != 'timestamp']
        
        categories = {
            'price_basic': [],
            'volume': [], 
            'technical': [],
            'onchain_whale': [],
            'onchain_hodl': [],
            'onchain_network': [],
            'derivatives': [],
            'macro': [],
            'sentiment': [],
            'correlation': [],
            'volatility': [],
            'pattern': [],
            'support_resistance': [],
            'market_structure': [],
            'liquidity': [],
            'others': []
        }
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        keywords = {
            'price_basic': ['price', 'open', 'high', 'low', 'close'],
            'volume': ['volume', 'trade_volume', 'transaction_volume'],
            'technical': ['rsi', 'macd', 'bollinger', 'sma', 'ema', 'stoch', 'williams'],
            'onchain_whale': ['whale', 'large_tx', 'top100'],
            'onchain_hodl': ['hodl', 'lth', 'sth', 'age'],
            'onchain_network': ['hash', 'difficulty', 'miner', 'blockchain_info'],
            'derivatives': ['funding', 'basis', 'futures', 'options', 'perpetual'],
            'macro': ['dxy', 'gold', 'nasdaq', 'spx', 'vix', 'crude', 'bonds'],
            'sentiment': ['fear_greed', 'social', 'sentiment'],
            'correlation': ['correlation', 'corr'],
            'volatility': ['volatility', 'vol', 'atr'],
            'pattern': ['pattern', 'flag', 'triangle', 'head_shoulders'],
            'support_resistance': ['support', 'resistance', 'level'],
            'market_structure': ['market_structure', 'cross', 'lead_lag'],
            'liquidity': ['liquidity', 'depth', 'spread', 'slippage']
        }
        
        # ë¶„ë¥˜ ì‹¤í–‰
        for col in all_cols:
            categorized = False
            for category, words in keywords.items():
                if any(word.lower() in col.lower() for word in words):
                    categories[category].append(col)
                    categorized = True
                    break
            
            if not categorized:
                categories['others'].append(col)
        
        # ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ì§€í‘œ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜:")
        for category, indicators in categories.items():
            if indicators:
                print(f"  {category:20s}: {len(indicators):4d}ê°œ")
        
        return categories
    
    def generate_diverse_prediction_strategy(self) -> Dict:
        """ë‹¤ë°©ë©´ ì˜ˆì¸¡ ì „ëµ ìƒì„±"""
        categories = self.categorize_all_indicators()
        
        strategy_types = [
            'technical_focus', 'onchain_focus', 'macro_focus', 'sentiment_focus',
            'hybrid_ensemble', 'momentum_based', 'mean_reversion'
        ]
        
        selected_strategy = random.choice(strategy_types)
        
        # ì „ëµë³„ ì§€í‘œ ì„ íƒ
        if selected_strategy == 'technical_focus':
            selected_indicators = (
                categories['technical'][:10] + 
                categories['price_basic'][:5] + 
                categories['volume'][:3]
            )
            model_type = 'rf'
            
        elif selected_strategy == 'onchain_focus':
            selected_indicators = (
                categories['onchain_whale'][:8] + 
                categories['onchain_hodl'][:8] + 
                categories['onchain_network'][:4]
            )
            model_type = 'gb'
            
        elif selected_strategy == 'macro_focus':
            selected_indicators = (
                categories['macro'][:8] + 
                categories['correlation'][:8] + 
                categories['price_basic'][:4]
            )
            model_type = 'ridge'
            
        elif selected_strategy == 'sentiment_focus':
            selected_indicators = (
                categories['sentiment'][:5] + 
                categories['volume'][:5] + 
                categories['social'] if 'social' in categories else categories['others'][:5]
            )
            model_type = 'elastic'
            
        elif selected_strategy == 'hybrid_ensemble':
            # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ê· í˜•ìˆê²Œ
            selected_indicators = []
            for cat_name, indicators in categories.items():
                if indicators and cat_name != 'others':
                    selected_indicators.extend(indicators[:3])
            model_type = 'ensemble'
            
        elif selected_strategy == 'momentum_based':
            selected_indicators = (
                categories['technical'][:6] + 
                categories['volatility'][:6] + 
                categories['pattern'][:4] + 
                categories['price_basic'][:4]
            )
            model_type = 'gb'
            
        else:  # mean_reversion
            selected_indicators = (
                categories['support_resistance'][:8] + 
                categories['technical'][:6] + 
                categories['onchain_hodl'][:6]
            )
            model_type = 'ridge'
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì§€í‘œë§Œ í•„í„°ë§
        available_indicators = [ind for ind in selected_indicators if ind in self.historical_data.columns]
        
        if not available_indicators:
            available_indicators = random.sample(
                [col for col in self.historical_data.columns if col != 'timestamp'], 
                min(15, len(self.historical_data.columns)-1)
            )
        
        return {
            'strategy_type': selected_strategy,
            'indicators': available_indicators[:20],  # ìµœëŒ€ 20ê°œ
            'model_type': model_type,
            'prediction_hours': random.choice([1, 6, 12, 24, 48, 72]),
            'market_regime': self.detect_market_regime(),
            'preprocessing': random.choice(['robust', 'standard', 'minmax'])
        }
    
    def detect_market_regime(self) -> str:
        """í˜„ì¬ ì‹œì¥ ìƒí™© ê°ì§€"""
        # ê°„ë‹¨í•œ ì‹œì¥ ìƒí™© ë¶„ë¥˜
        regimes = ['bull_trend', 'bear_trend', 'sideways', 'high_volatility', 'low_volatility']
        return random.choice(regimes)  # ì„ì‹œë¡œ ëœë¤ (ì‹¤ì œë¡œëŠ” ê°€ê²© ë¶„ì„ ê¸°ë°˜)
    
    def execute_prediction_attempt(self, start_idx: int, strategy: Dict) -> Dict:
        """ë‹¨ì¼ ì˜ˆì¸¡ ì‹œë„ ì‹¤í–‰"""
        try:
            # íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸°
            price_candidates = [
                'onchain_blockchain_info_network_stats_market_price_usd',
                'price', 'close', 'open'
            ]
            target_col = None
            for candidate in price_candidates:
                if candidate in self.historical_data.columns:
                    target_col = candidate
                    break
            
            if not target_col:
                numeric_cols = self.historical_data.select_dtypes(include=[np.number]).columns
                target_col = numeric_cols[0]
            
            # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            train_data = self.historical_data.iloc[:start_idx]
            if len(train_data) < 100:
                return {'success': False, 'error': 'í•™ìŠµ ë°ì´í„° ë¶€ì¡±'}
            
            # í”¼ì²˜ ì¤€ë¹„
            X_train = train_data[strategy['indicators']]
            prediction_hours = strategy['prediction_hours']
            y_train = train_data[target_col].shift(-prediction_hours).dropna()
            X_train = X_train.iloc[:-prediction_hours]
            
            if len(X_train) < 50:
                return {'success': False, 'error': 'íƒ€ê²Ÿ ë°ì´í„° ë¶€ì¡±'}
            
            # ì „ì²˜ë¦¬
            if strategy['preprocessing'] == 'robust':
                scaler = RobustScaler()
            elif strategy['preprocessing'] == 'standard':
                scaler = StandardScaler()
            else:
                scaler = MinMaxScaler()
            
            X_train_scaled = scaler.fit_transform(X_train)
            
            # ëª¨ë¸ í•™ìŠµ
            if strategy['model_type'] == 'rf':
                model = RandomForestRegressor(n_estimators=50, random_state=42)
            elif strategy['model_type'] == 'gb':
                model = GradientBoostingRegressor(n_estimators=50, random_state=42)
            elif strategy['model_type'] == 'ridge':
                model = Ridge(alpha=1.0)
            elif strategy['model_type'] == 'elastic':
                model = ElasticNet(alpha=1.0)
            elif strategy['model_type'] == 'ensemble':
                # ê°„ë‹¨í•œ ì•™ìƒë¸”
                models = [
                    RandomForestRegressor(n_estimators=30, random_state=42),
                    GradientBoostingRegressor(n_estimators=30, random_state=42)
                ]
                predictions = []
                for m in models:
                    m.fit(X_train_scaled, y_train)
                    current_features = self.historical_data.iloc[start_idx:start_idx+1][strategy['indicators']]
                    current_scaled = scaler.transform(current_features)
                    pred = m.predict(current_scaled)[0]
                    predictions.append(pred)
                
                final_prediction = np.mean(predictions)
                
                # ì‹¤ì œê°’ê³¼ ë¹„êµ
                target_idx = start_idx + prediction_hours
                if target_idx >= len(self.historical_data):
                    return {'success': False, 'error': 'ì˜ˆì¸¡ ì‹œì  ì´ˆê³¼'}
                
                actual_value = self.historical_data.iloc[target_idx][target_col]
                error_pct = abs(actual_value - final_prediction) / actual_value * 100
                accuracy = max(0, 100 - error_pct)
                
                return {
                    'success': True,
                    'accuracy': accuracy,
                    'predicted': final_prediction,
                    'actual': actual_value,
                    'error_pct': error_pct,
                    'strategy': strategy
                }
            
            # ë‹¨ì¼ ëª¨ë¸ì˜ ê²½ìš°
            model.fit(X_train_scaled, y_train)
            
            # ì˜ˆì¸¡
            current_features = self.historical_data.iloc[start_idx:start_idx+1][strategy['indicators']]
            current_scaled = scaler.transform(current_features)
            prediction = model.predict(current_scaled)[0]
            
            # ê²€ì¦
            target_idx = start_idx + prediction_hours
            if target_idx >= len(self.historical_data):
                return {'success': False, 'error': 'ì˜ˆì¸¡ ì‹œì  ì´ˆê³¼'}
            
            actual_value = self.historical_data.iloc[target_idx][target_col]
            error_pct = abs(actual_value - prediction) / actual_value * 100
            accuracy = max(0, 100 - error_pct)
            
            return {
                'success': True,
                'accuracy': accuracy,
                'predicted': prediction,
                'actual': actual_value,
                'error_pct': error_pct,
                'strategy': strategy
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def analyze_prediction_result(self, result: Dict, attempt_num: int):
        """ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ë° í•™ìŠµ"""
        self.total_attempts += 1
        
        if result['success']:
            accuracy = result['accuracy']
            strategy = result['strategy']
            
            # ì„±ê³µ/ì‹¤íŒ¨ ê¸°ì¤€ (80% ì´ìƒì„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼)
            is_success = accuracy >= 80.0
            
            if is_success:
                self.success_count += 1
                self.success_patterns.append(result)
                
                # ì„±ê³µí•œ ì „ëµì˜ ê°€ì¤‘ì¹˜ ì¦ê°€
                strategy_type = strategy['strategy_type']
                self.prediction_strategies[strategy_type]['success'] += 1
                
                # ì„±ê³µí•œ ì§€í‘œë“¤ì˜ ê°€ì¤‘ì¹˜ ì¦ê°€
                for indicator in strategy['indicators']:
                    self.learning_weights[indicator] += 0.1
                
                print(f"âœ… ì‹œë„ {attempt_num}: ì„±ê³µ! ì •í™•ë„ {accuracy:.1f}% (ì „ëµ: {strategy_type})")
                
            else:
                self.failure_patterns.append(result)
                
                # ì‹¤íŒ¨í•œ ì§€í‘œë“¤ì˜ ê°€ì¤‘ì¹˜ ê°ì†Œ
                for indicator in strategy['indicators']:
                    self.learning_weights[indicator] -= 0.05
                
                if attempt_num % 100 == 0:
                    print(f"âŒ ì‹œë„ {attempt_num}: ì‹¤íŒ¨ ì •í™•ë„ {accuracy:.1f}% (ì „ëµ: {strategy['strategy_type']})")
            
            # ì „ëµë³„ ì‹œë„ íšŸìˆ˜ ì¦ê°€
            self.prediction_strategies[strategy['strategy_type']]['attempts'] += 1
            
        else:
            if attempt_num % 100 == 0:
                print(f"âš ï¸ ì‹œë„ {attempt_num}: ì˜¤ë¥˜ - {result.get('error', 'Unknown')}")
        
        # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        if self.total_attempts > 0:
            self.current_success_rate = (self.success_count / self.total_attempts) * 100
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ê·œì¹™ ë°œê²¬ ì‹œë„
        if attempt_num % 500 == 0:
            self.discover_common_rules()
            self.print_progress_report(attempt_num)
    
    def discover_common_rules(self):
        """ê³µí†µ ê·œì¹™ ë°œê²¬"""
        if len(self.success_patterns) < 10:
            return
        
        print(f"\nğŸ” ê³µí†µ ê·œì¹™ ë¶„ì„ ì¤‘... (ì„±ê³µ ì‚¬ë¡€ {len(self.success_patterns)}ê°œ ê¸°ë°˜)")
        
        # ê·œì¹™ 1: ê°€ì¥ íš¨ê³¼ì ì¸ ì§€í‘œë“¤
        indicator_success_count = defaultdict(int)
        for pattern in self.success_patterns:
            for indicator in pattern['strategy']['indicators']:
                indicator_success_count[indicator] += 1
        
        top_indicators = sorted(indicator_success_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        # ê·œì¹™ 2: ê°€ì¥ íš¨ê³¼ì ì¸ ì „ëµ íƒ€ì…
        strategy_success_rate = {}
        for strategy_type, stats in self.prediction_strategies.items():
            if stats['attempts'] > 0:
                success_rate = (stats['success'] / stats['attempts']) * 100
                strategy_success_rate[strategy_type] = success_rate
        
        best_strategies = sorted(strategy_success_rate.items(), key=lambda x: x[1], reverse=True)
        
        # ê·œì¹™ 3: ìµœì  ì˜ˆì¸¡ ì‹œê°„
        prediction_hours_success = defaultdict(list)
        for pattern in self.success_patterns:
            hours = pattern['strategy']['prediction_hours']
            accuracy = pattern['accuracy']
            prediction_hours_success[hours].append(accuracy)
        
        optimal_hours = {}
        for hours, accuracies in prediction_hours_success.items():
            optimal_hours[hours] = np.mean(accuracies)
        
        best_hours = sorted(optimal_hours.items(), key=lambda x: x[1], reverse=True)
        
        # ë°œê²¬ëœ ê·œì¹™ ì €ì¥
        new_rule = {
            'discovery_time': datetime.now(),
            'success_cases': len(self.success_patterns),
            'total_attempts': self.total_attempts,
            'top_indicators': top_indicators,
            'best_strategies': best_strategies,
            'optimal_prediction_hours': best_hours,
            'current_success_rate': self.current_success_rate
        }
        
        self.discovered_rules.append(new_rule)
        
        # ì‚¬ìš©ìì—ê²Œ ê·œì¹™ ì•ˆë‚´
        self.report_discovered_rules(new_rule)
    
    def report_discovered_rules(self, rule: Dict):
        """ë°œê²¬ëœ ê·œì¹™ì„ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´"""
        print(f"\nğŸ¯ ë°œê²¬ëœ ê³µí†µ ê·œì¹™ (ì„±ê³µë¥  {rule['current_success_rate']:.1f}%)")
        print("="*60)
        
        print(f"ğŸ“Š ìµœê³  ì„±ê³¼ ì§€í‘œ TOP 5:")
        for i, (indicator, count) in enumerate(rule['top_indicators'][:5]):
            print(f"  {i+1}. {indicator[:50]}... (ì„±ê³µ {count}íšŒ)")
        
        print(f"\nğŸ¯ ìµœê³  ì„±ê³¼ ì „ëµ TOP 3:")
        for i, (strategy, rate) in enumerate(rule['best_strategies'][:3]):
            print(f"  {i+1}. {strategy:20s} ì„±ê³µë¥  {rate:.1f}%")
        
        print(f"\nâ° ìµœì  ì˜ˆì¸¡ ì‹œê°„ TOP 3:")
        for i, (hours, avg_acc) in enumerate(rule['optimal_prediction_hours'][:3]):
            print(f"  {i+1}. {hours:2d}ì‹œê°„ í›„ ì˜ˆì¸¡: í‰ê·  ì •í™•ë„ {avg_acc:.1f}%")
        
        print("="*60)
    
    def print_progress_report(self, attempt_num: int):
        """ì§„í–‰ ìƒí™© ë³´ê³ """
        print(f"\nğŸ“ˆ ì§„í–‰ ìƒí™© ë³´ê³  (ì‹œë„ {attempt_num}íšŒ)")
        print(f"ğŸ¯ í˜„ì¬ ì„±ê³µë¥ : {self.current_success_rate:.2f}% (ëª©í‘œ: {self.target_success_rate}%)")
        print(f"âœ… ì„±ê³µ: {self.success_count}íšŒ, âŒ ì‹¤íŒ¨: {self.total_attempts - self.success_count}íšŒ")
        
        if self.current_success_rate >= self.target_success_rate:
            print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! {self.target_success_rate}% ì„±ê³µë¥  ë‹¬ì„±!")
            return True
        else:
            remaining = self.target_success_rate - self.current_success_rate
            print(f"âš ï¸ ëª©í‘œê¹Œì§€ +{remaining:.2f}% ë” í•„ìš”")
            return False
    
    def run_infinite_learning(self, max_attempts: int = 10000):
        """ë¬´í•œ í•™ìŠµ ì‹¤í–‰"""
        print(f"\nğŸš€ ë¬´í•œ í•™ìŠµ ì‹œì‘ (ìµœëŒ€ {max_attempts}íšŒ)")
        print(f"ğŸ¯ ëª©í‘œ: {self.target_success_rate}% ì„±ê³µë¥  ë‹¬ì„±")
        print("="*70)
        
        data_length = len(self.historical_data)
        min_start = 200
        max_start = data_length - 100
        
        for attempt in range(1, max_attempts + 1):
            # ëœë¤ ì‹œì  ì„ íƒ
            start_idx = random.randint(min_start, max_start)
            
            # ë‹¤ë°©ë©´ ì˜ˆì¸¡ ì „ëµ ìƒì„±
            strategy = self.generate_diverse_prediction_strategy()
            
            # ì˜ˆì¸¡ ì‹œë„
            result = self.execute_prediction_attempt(start_idx, strategy)
            
            # ê²°ê³¼ ë¶„ì„ ë° í•™ìŠµ
            self.analyze_prediction_result(result, attempt)
            
            # ëª©í‘œ ë‹¬ì„± ì²´í¬
            if attempt % 1000 == 0:
                if self.print_progress_report(attempt):
                    break
        
        # ìµœì¢… ê²°ê³¼
        self.print_final_results()
        self.save_learning_results()
    
    def print_final_results(self):
        """ìµœì¢… ê²°ê³¼ ì¶œë ¥"""
        print(f"\n" + "="*70)
        print("ğŸ† ë¬´í•œ í•™ìŠµ ìµœì¢… ê²°ê³¼")
        print("="*70)
        print(f"ğŸ”„ ì´ ì‹œë„ íšŸìˆ˜:     {self.total_attempts:,}")
        print(f"âœ… ì„±ê³µ íšŸìˆ˜:       {self.success_count:,}")
        print(f"ğŸ¯ ìµœì¢… ì„±ê³µë¥ :     {self.current_success_rate:.2f}%")
        print(f"ğŸ“Š ë°œê²¬ëœ ê·œì¹™ ìˆ˜:   {len(self.discovered_rules)}")
        
        if self.current_success_rate >= self.target_success_rate:
            print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! ({self.target_success_rate}% ì´ìƒ)")
        else:
            print(f"âš ï¸ ëª©í‘œ ë¯¸ë‹¬ì„± (ëª©í‘œ: {self.target_success_rate}%)")
        
        # ìµœì¢… ë°œê²¬ëœ ê·œì¹™ë“¤ ìš”ì•½
        if self.discovered_rules:
            final_rule = self.discovered_rules[-1]
            print(f"\nğŸ¯ ìµœì¢… ë°œê²¬ ê·œì¹™:")
            print(f"ğŸ“ˆ ìµœê³  ì§€í‘œ: {final_rule['top_indicators'][0][0] if final_rule['top_indicators'] else 'N/A'}")
            print(f"ğŸ† ìµœê³  ì „ëµ: {final_rule['best_strategies'][0][0] if final_rule['best_strategies'] else 'N/A'}")
            print(f"â° ìµœì  ì‹œê°„: {final_rule['optimal_prediction_hours'][0][0] if final_rule['optimal_prediction_hours'] else 'N/A'}ì‹œê°„")
        
        print("="*70)
    
    def save_learning_results(self):
        """í•™ìŠµ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        results = {
            'timestamp': timestamp,
            'total_attempts': self.total_attempts,
            'success_count': self.success_count,
            'final_success_rate': self.current_success_rate,
            'target_achieved': self.current_success_rate >= self.target_success_rate,
            'discovered_rules': self.discovered_rules,
            'learning_weights': dict(self.learning_weights),
            'strategy_performance': self.prediction_strategies,
            'success_patterns_count': len(self.success_patterns),
            'failure_patterns_count': len(self.failure_patterns)
        }
        
        filename = f"infinite_learning_rules_{timestamp}.json"
        filepath = os.path.join(self.data_path, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ í•™ìŠµ ê²°ê³¼ ì €ì¥: {filename}")
        return filepath
    
    def run_complete_system(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        print("ğŸ”¥ ì§„ì§œ ë¬´í•œí•™ìŠµ 95% ê·œì¹™ ë°œê²¬ê¸° ì‹œì‘")
        print("="*70)
        
        if not self.load_data():
            return None
        
        # ë¬´í•œ í•™ìŠµ ì‹¤í–‰
        self.run_infinite_learning(max_attempts=5000)  # 5000íšŒ ì‹œë„
        
        return {
            'success_rate': self.current_success_rate,
            'total_attempts': self.total_attempts,
            'rules_discovered': len(self.discovered_rules),
            'target_achieved': self.current_success_rate >= self.target_success_rate
        }

def main():
    learner = InfiniteLearningRuleDiscoverer()
    return learner.run_complete_system()

if __name__ == "__main__":
    results = main()