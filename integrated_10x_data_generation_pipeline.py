#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© 10ë°° ë¹„íŠ¸ì½”ì¸ í›ˆë ¨ ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸
- ëª¨ë“  ë°ì´í„° ì¦ê°• ê¸°ë²• í†µí•©
- ì‹œì¥ íŠ¹ì„± ë³´ì¡´ ë³´ì¥
- í’ˆì§ˆ ê´€ë¦¬ ë° ê²€ì¦
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

import os
import sys
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
import logging
import pickle
import time
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

# ë¡œì»¬ ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from bitcoin_data_augmentation_system import BitcoinDataAugmentationSystem
    from synthetic_data_generation_system import SyntheticBitcoinDataGenerator
    from advanced_cross_validation_system import AdvancedCrossValidationSystem
    from data_quality_enhancement_pipeline import DataQualityEnhancementPipeline
except ImportError as e:
    print(f"âš ï¸ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    print("í•„ìš”í•œ ëª¨ë“ˆë“¤ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

# ê³¼í•™ ê³„ì‚°
from scipy import stats
from scipy.signal import savgol_filter
from scipy.optimize import minimize

# ë¨¸ì‹ ëŸ¬ë‹
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

# í†µê³„ ë° ì‹œê°í™”
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class DataGenerationConfig:
    """ë°ì´í„° ìƒì„± ì„¤ì •"""
    target_multiplier: int = 10          # ëª©í‘œ ë°°ìˆ˜
    quality_threshold: float = 0.7       # í’ˆì§ˆ ì„ê³„ê°’
    max_workers: int = 4                 # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
    
    # ì¦ê°• ê¸°ë²•ë³„ ë¹„ì¤‘
    augmentation_ratios: Dict[str, float] = None
    
    # í’ˆì§ˆ ê´€ë¦¬
    enable_quality_control: bool = True
    enable_validation: bool = True
    enable_monitoring: bool = True
    
    # ì¶œë ¥ ì„¤ì •
    output_formats: List[str] = None
    compression: bool = True
    split_by_timeframe: bool = True
    
    def __post_init__(self):
        if self.augmentation_ratios is None:
            self.augmentation_ratios = {
                'financial_ts': 0.3,      # ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°•
                'synthetic': 0.25,        # í•©ì„± ë°ì´í„°
                'regime_aware': 0.2,      # ì²´ì œë³„ ì¦ê°•  
                'monte_carlo': 0.15,      # ëª¬í…Œì¹´ë¥¼ë¡œ
                'bootstrap': 0.1          # ë¶€íŠ¸ìŠ¤íŠ¸ë©
            }
        
        if self.output_formats is None:
            self.output_formats = ['csv', 'parquet', 'hdf5']

@dataclass
class GenerationMetrics:
    """ìƒì„± ë©”íŠ¸ë¦­"""
    original_samples: int
    generated_samples: int
    multiplication_factor: float
    quality_score: float
    generation_time: float
    memory_usage: float
    success_rate: float
    
    # ê¸°ë²•ë³„ ê¸°ì—¬ë„
    method_contributions: Dict[str, int] = None
    
    # í’ˆì§ˆ ì„¸ë¶€ì‚¬í•­
    quality_details: Dict[str, float] = None

class Integrated10xDataGenerationPipeline:
    """
    ğŸš€ í†µí•© 10ë°° ë¹„íŠ¸ì½”ì¸ í›ˆë ¨ ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. ëª¨ë“  ì¦ê°• ê¸°ë²• í†µí•© ë° ì¡°ìœ¨
    2. í’ˆì§ˆ ë³´ì¥ ë° ê²€ì¦
    3. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    4. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì§„í–‰ë¥  ì¶”ì 
    5. ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ ì§€ì›
    """
    
    def __init__(self, config: DataGenerationConfig = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config: ë°ì´í„° ìƒì„± ì„¤ì •
        """
        self.config = config or DataGenerationConfig()
        self.logger = logging.getLogger(__name__)
        
        # í•˜ìœ„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.augmentation_system = BitcoinDataAugmentationSystem()
        self.synthetic_generator = SyntheticBitcoinDataGenerator()
        self.validation_system = AdvancedCrossValidationSystem()
        self.quality_pipeline = DataQualityEnhancementPipeline()
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.original_data = {}
        self.generated_data = {}
        self.quality_reports = {}
        self.generation_history = []
        
        # ëª¨ë‹ˆí„°ë§
        self.start_time = None
        self.progress_callback = None
        
        self.logger.info("ğŸš€ í†µí•© 10ë°° ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_source_data(self, data_path: str = "three_month_timeseries_data") -> Dict[str, pd.DataFrame]:
        """
        ì›ë³¸ ë°ì´í„° ë¡œë“œ
        
        Args:
            data_path: ë°ì´í„° ê²½ë¡œ
            
        Returns:
            ë¡œë“œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info(f"ğŸ“Š ì›ë³¸ ë°ì´í„° ë¡œë“œ: {data_path}")
        
        # ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)
        try:
            self.original_data = self.augmentation_system.load_bitcoin_data()
            
            if not self.original_data:
                # ì˜ˆì œ ë°ì´í„° ìƒì„±
                self.logger.info("ì˜ˆì œ ë°ì´í„° ìƒì„± ì¤‘...")
                self.original_data = self._generate_example_data()
            
            total_samples = sum(len(df) for df in self.original_data.values())
            self.logger.info(f"âœ… ì´ {len(self.original_data)}ê°œ ë°ì´í„°ì…‹, {total_samples:,}ê°œ ìƒ˜í”Œ ë¡œë“œ")
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.original_data = self._generate_example_data()
        
        return self.original_data
    
    def _generate_example_data(self) -> Dict[str, pd.DataFrame]:
        """ì˜ˆì œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ)"""
        self.logger.info("ğŸ“Š ì˜ˆì œ ë°ì´í„° ìƒì„±...")
        
        np.random.seed(42)
        n_samples = 2000
        
        # ì‹œê°„ ì¸ë±ìŠ¤
        dates = pd.date_range('2024-01-01', periods=n_samples, freq='H')
        
        # ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‹œê³„ì—´ ë°ì´í„°
        example_data = {}
        
        # 1. ê°€ê²© ë°ì´í„°
        price_trend = np.linspace(50000, 65000, n_samples)
        price_seasonal = 2000 * np.sin(2 * np.pi * np.arange(n_samples) / 168)  # ì£¼ê°„ ì£¼ê¸°
        price_noise = np.random.normal(0, 500, n_samples)
        price = price_trend + price_seasonal + price_noise
        
        example_data['btc_price'] = pd.DataFrame({
            'price': price,
            'volume': np.random.lognormal(15, 1, n_samples),
            'market_cap': price * 19_000_000
        }, index=dates)
        
        # 2. ì˜¨ì²´ì¸ ë°ì´í„°
        example_data['onchain_metrics'] = pd.DataFrame({
            'active_addresses': np.random.poisson(800000, n_samples),
            'transaction_count': np.random.poisson(250000, n_samples),
            'hash_rate': np.random.gamma(2, 50000000, n_samples),
            'difficulty': np.random.gamma(3, 10000000000000, n_samples)
        }, index=dates)
        
        # 3. ì‹¬ë¦¬ ì§€í‘œ
        fear_greed = 50 + 30 * np.sin(2 * np.pi * np.arange(n_samples) / 720) + np.random.normal(0, 10, n_samples)
        fear_greed = np.clip(fear_greed, 0, 100)
        
        example_data['sentiment'] = pd.DataFrame({
            'fear_greed_index': fear_greed,
            'social_volume': np.random.gamma(2, 100000, n_samples),
            'news_sentiment': np.random.uniform(-1, 1, n_samples)
        }, index=dates)
        
        return example_data
    
    def calculate_generation_targets(self) -> Dict[str, int]:
        """
        ìƒì„± ëª©í‘œëŸ‰ ê³„ì‚°
        
        Returns:
            ê¸°ë²•ë³„ ìƒì„± ëª©í‘œëŸ‰
        """
        total_original = sum(len(df) for df in self.original_data.values())
        target_total = total_original * self.config.target_multiplier
        additional_needed = target_total - total_original
        
        targets = {}
        for method, ratio in self.config.augmentation_ratios.items():
            targets[method] = int(additional_needed * ratio)
        
        self.logger.info(f"ğŸ¯ ìƒì„± ëª©í‘œ: ì´ {additional_needed:,}ê°œ ì¶”ê°€ ìƒ˜í”Œ")
        for method, count in targets.items():
            self.logger.info(f"  - {method}: {count:,}ê°œ")
        
        return targets
    
    def generate_financial_timeseries_data(self, target_count: int) -> Dict[str, List[pd.DataFrame]]:
        """
        ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°• ë°ì´í„° ìƒì„±
        
        Args:
            target_count: ëª©í‘œ ìƒì„± ìˆ˜
            
        Returns:
            ì¦ê°•ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info(f"ğŸ“ˆ ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°• ë°ì´í„° {target_count:,}ê°œ ìƒì„±...")
        
        results = {}
        
        try:
            # ê¸°ë³¸ ì¦ê°• ì‹¤í–‰
            augmented_results = self.augmentation_system.execute_comprehensive_augmentation()
            
            # ê²°ê³¼ ì •ë¦¬ ë° ìƒ˜í”Œë§
            for data_name, variants in augmented_results.items():
                results[data_name] = []
                variant_list = list(variants.values())
                
                # ëª©í‘œ ìˆ˜ëŸ‰ì— ë§ê²Œ ìƒ˜í”Œë§
                samples_per_dataset = target_count // len(self.original_data)
                
                if variant_list and samples_per_dataset > 0:
                    # í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
                    if self.config.enable_quality_control:
                        filtered_variants = []
                        for variant in variant_list:
                            quality = self.quality_pipeline.assess_data_quality(variant)
                            if quality.overall_score >= self.config.quality_threshold:
                                filtered_variants.append(variant)
                        variant_list = filtered_variants or variant_list[:10]  # ìµœì†Œ ë³´ì¥
                    
                    # í•„ìš”í•œë§Œí¼ ì„ íƒ
                    selected_count = min(samples_per_dataset, len(variant_list))
                    results[data_name] = variant_list[:selected_count]
        
        except Exception as e:
            self.logger.error(f"ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°• ì˜¤ë¥˜: {e}")
            results = {}
        
        generated_count = sum(len(variants) for variants in results.values())
        self.logger.info(f"âœ… ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°• ì™„ë£Œ: {generated_count:,}ê°œ ìƒì„±")
        
        return results
    
    def generate_synthetic_data(self, target_count: int) -> Dict[str, List[pd.DataFrame]]:
        """
        í•©ì„± ë°ì´í„° ìƒì„±
        
        Args:
            target_count: ëª©í‘œ ìƒì„± ìˆ˜
            
        Returns:
            í•©ì„± ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info(f"ğŸ”® í•©ì„± ë°ì´í„° {target_count:,}ê°œ ìƒì„±...")
        
        results = {}
        
        try:
            # ëŒ€í‘œ ë°ì´í„°ì…‹ ì„ íƒ (ê°€ì¥ í° ê²ƒ)
            main_dataset_name = max(self.original_data.keys(), 
                                  key=lambda k: len(self.original_data[k]))
            main_data = self.original_data[main_dataset_name]
            
            # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
            training_data = self.synthetic_generator.prepare_training_data(main_data)
            
            if len(training_data) > 10:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
                # GAN/VAE í›ˆë ¨ (ê°„ë‹¨í•œ ì˜ˆì œìš©)
                try:
                    # í›ˆë ¨ (ì§§ê²Œ)
                    if hasattr(self.synthetic_generator, 'train_gan'):
                        self.synthetic_generator.train_gan(training_data, epochs=10)
                        gan_samples = self.synthetic_generator.generate_gan_samples(target_count // 2)
                        results['gan_synthetic'] = [pd.DataFrame(sample) for sample in gan_samples[:10]]
                
                    if hasattr(self.synthetic_generator, 'train_vae'):
                        self.synthetic_generator.train_vae(training_data, epochs=10) 
                        vae_samples = self.synthetic_generator.generate_vae_samples(target_count // 2)
                        results['vae_synthetic'] = [pd.DataFrame(sample) for sample in vae_samples[:10]]
                
                except Exception as e:
                    self.logger.warning(f"ë”¥ëŸ¬ë‹ í•©ì„± ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
                
                # ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ (í•­ìƒ ê°€ëŠ¥)
                if 'price' in main_data.columns or len(main_data.columns) > 0:
                    price_col = 'price' if 'price' in main_data.columns else main_data.columns[0]
                    returns = main_data[price_col].pct_change().dropna()
                    
                    mc_samples = []
                    n_simulations = min(target_count, 100)
                    
                    for _ in range(n_simulations):
                        initial_price = main_data[price_col].iloc[-1]
                        sim_path = self.synthetic_generator.monte_carlo_price_simulation(
                            initial_price, returns, n_simulations=1, time_horizon=168
                        )
                        
                        sim_df = pd.DataFrame({price_col: sim_path[0]})
                        mc_samples.append(sim_df)
                    
                    results['monte_carlo'] = mc_samples
                
        except Exception as e:
            self.logger.error(f"í•©ì„± ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
            results = {}
        
        generated_count = sum(len(variants) for variants in results.values())
        self.logger.info(f"âœ… í•©ì„± ë°ì´í„° ìƒì„± ì™„ë£Œ: {generated_count:,}ê°œ ìƒì„±")
        
        return results
    
    def generate_regime_aware_data(self, target_count: int) -> Dict[str, List[pd.DataFrame]]:
        """
        ì‹œì¥ ì²´ì œë³„ íŠ¹í™” ë°ì´í„° ìƒì„±
        
        Args:
            target_count: ëª©í‘œ ìƒì„± ìˆ˜
            
        Returns:
            ì²´ì œë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬  
        """
        self.logger.info(f"ğŸ“Š ì‹œì¥ ì²´ì œë³„ ë°ì´í„° {target_count:,}ê°œ ìƒì„±...")
        
        results = {}
        
        try:
            # ì²´ì œë³„ ì¦ê°• ì‹¤í–‰
            for data_name, data in self.original_data.items():
                regime_variants = self.augmentation_system.regime_aware_augmentation(data_name)
                
                if regime_variants:
                    # ìƒ˜í”Œ ì œí•œ
                    samples_per_dataset = target_count // len(self.original_data)
                    variant_list = list(regime_variants.values())
                    selected = variant_list[:samples_per_dataset]
                    results[data_name] = selected
        
        except Exception as e:
            self.logger.error(f"ì²´ì œë³„ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
            results = {}
        
        generated_count = sum(len(variants) for variants in results.values())
        self.logger.info(f"âœ… ì²´ì œë³„ ë°ì´í„° ìƒì„± ì™„ë£Œ: {generated_count:,}ê°œ ìƒì„±")
        
        return results
    
    def generate_bootstrap_data(self, target_count: int) -> Dict[str, List[pd.DataFrame]]:
        """
        ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°ì´í„° ìƒì„±
        
        Args:
            target_count: ëª©í‘œ ìƒì„± ìˆ˜
            
        Returns:
            ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info(f"ğŸ”„ ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°ì´í„° {target_count:,}ê°œ ìƒì„±...")
        
        results = {}
        
        try:
            for data_name, data in self.original_data.items():
                n_bootstrap_samples = target_count // len(self.original_data)
                bootstrap_samples = self.synthetic_generator.bootstrap_resample(
                    data, n_bootstrap_samples
                )
                results[data_name] = bootstrap_samples
        
        except Exception as e:
            self.logger.error(f"ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
            results = {}
        
        generated_count = sum(len(variants) for variants in results.values())
        self.logger.info(f"âœ… ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°ì´í„° ìƒì„± ì™„ë£Œ: {generated_count:,}ê°œ ìƒì„±")
        
        return results
    
    def parallel_data_generation(self, targets: Dict[str, int]) -> Dict[str, Dict]:
        """
        ë³‘ë ¬ ë°ì´í„° ìƒì„± ì‹¤í–‰
        
        Args:
            targets: ê¸°ë²•ë³„ ëª©í‘œëŸ‰
            
        Returns:
            ìƒì„±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info("âš¡ ë³‘ë ¬ ë°ì´í„° ìƒì„± ì‹œì‘...")
        
        generation_tasks = []
        
        # ìƒì„± ì‘ì—… ì •ì˜
        if 'financial_ts' in targets:
            generation_tasks.append(('financial_ts', self.generate_financial_timeseries_data, targets['financial_ts']))
        
        if 'synthetic' in targets:
            generation_tasks.append(('synthetic', self.generate_synthetic_data, targets['synthetic']))
        
        if 'regime_aware' in targets:
            generation_tasks.append(('regime_aware', self.generate_regime_aware_data, targets['regime_aware']))
        
        if 'bootstrap' in targets:
            generation_tasks.append(('bootstrap', self.generate_bootstrap_data, targets['bootstrap']))
        
        # ë³‘ë ¬ ì‹¤í–‰
        all_results = {}
        
        with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # ì‘ì—… ì œì¶œ
            future_to_method = {}
            for method_name, method_func, target_count in generation_tasks:
                future = executor.submit(method_func, target_count)
                future_to_method[future] = method_name
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in future_to_method:
                method_name = future_to_method[future]
                try:
                    result = future.result(timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                    all_results[method_name] = result
                except Exception as e:
                    self.logger.error(f"{method_name} ìƒì„± ì‹¤íŒ¨: {e}")
                    all_results[method_name] = {}
        
        self.logger.info("âœ… ë³‘ë ¬ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        return all_results
    
    def apply_quality_enhancement(self, generated_data: Dict) -> Dict:
        """
        ìƒì„±ëœ ë°ì´í„°ì— í’ˆì§ˆ í–¥ìƒ ì ìš©
        
        Args:
            generated_data: ìƒì„±ëœ ë°ì´í„°
            
        Returns:
            í’ˆì§ˆ í–¥ìƒëœ ë°ì´í„°
        """
        if not self.config.enable_quality_control:
            return generated_data
        
        self.logger.info("ğŸ”§ ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ì ìš©...")
        
        enhanced_data = {}
        
        for method_name, method_data in generated_data.items():
            enhanced_data[method_name] = {}
            
            for dataset_name, dataset_variants in method_data.items():
                enhanced_variants = []
                
                for variant in dataset_variants:
                    try:
                        if isinstance(variant, pd.DataFrame) and len(variant) > 10:
                            # í’ˆì§ˆ í–¥ìƒ ì ìš©
                            enhanced_variant, _ = self.quality_pipeline.enhance_data_quality(
                                variant, {
                                    'detect_outliers': True,
                                    'handle_outliers': True,
                                    'impute_missing': True,
                                    'reduce_noise': True,
                                    'extract_signals': False,
                                    'enhance_snr': False
                                }
                            )
                            
                            # í’ˆì§ˆ ê²€ì‚¬
                            quality = self.quality_pipeline.assess_data_quality(enhanced_variant)
                            
                            if quality.overall_score >= self.config.quality_threshold:
                                enhanced_variants.append(enhanced_variant)
                            else:
                                self.logger.warning(f"í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ ë°ì´í„° ì œì™¸: {quality.overall_score:.3f}")
                        
                    except Exception as e:
                        self.logger.warning(f"í’ˆì§ˆ í–¥ìƒ ì˜¤ë¥˜: {e}")
                        continue
                
                if enhanced_variants:
                    enhanced_data[method_name][dataset_name] = enhanced_variants
        
        self.logger.info("âœ… ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ì™„ë£Œ")
        return enhanced_data
    
    def validate_generated_data(self, generated_data: Dict) -> Dict[str, float]:
        """
        ìƒì„±ëœ ë°ì´í„° ê²€ì¦
        
        Args:
            generated_data: ìƒì„±ëœ ë°ì´í„°
            
        Returns:
            ê²€ì¦ ê²°ê³¼
        """
        if not self.config.enable_validation:
            return {'validation_score': 1.0}
        
        self.logger.info("ğŸ” ìƒì„±ëœ ë°ì´í„° ê²€ì¦...")
        
        validation_results = {}
        
        try:
            # ìƒ˜í”Œ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ ê²€ì¦
            for method_name, method_data in generated_data.items():
                method_scores = []
                
                for dataset_name, variants in method_data.items():
                    if variants and dataset_name in self.original_data:
                        original = self.original_data[dataset_name]
                        
                        for variant in variants[:5]:  # ìƒ˜í”Œë§Œ ê²€ì¦
                            try:
                                if isinstance(variant, pd.DataFrame):
                                    # ê¸°ë³¸ í†µê³„ ë¹„êµ
                                    score = self._compare_statistical_properties(original, variant)
                                    method_scores.append(score)
                            except:
                                continue
                
                if method_scores:
                    validation_results[method_name] = np.mean(method_scores)
        
        except Exception as e:
            self.logger.warning(f"ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜: {e}")
            validation_results = {'overall': 0.7}
        
        overall_score = np.mean(list(validation_results.values())) if validation_results else 0.7
        validation_results['overall'] = overall_score
        
        self.logger.info(f"âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {overall_score:.3f}")
        return validation_results
    
    def _compare_statistical_properties(self, original: pd.DataFrame, generated: pd.DataFrame) -> float:
        """í†µê³„ì  ì†ì„± ë¹„êµ"""
        similarities = []
        
        # ê³µí†µ ìˆ«ìí˜• ì»¬ëŸ¼
        orig_numeric = original.select_dtypes(include=[np.number])
        gen_numeric = generated.select_dtypes(include=[np.number])
        
        common_cols = set(orig_numeric.columns) & set(gen_numeric.columns)
        
        for col in list(common_cols)[:3]:  # ìµœëŒ€ 3ê°œ ì»¬ëŸ¼ë§Œ
            try:
                orig_values = orig_numeric[col].dropna()
                gen_values = gen_numeric[col].dropna()
                
                if len(orig_values) > 5 and len(gen_values) > 5:
                    # í‰ê·  ìœ ì‚¬ì„±
                    mean_similarity = 1 - abs(orig_values.mean() - gen_values.mean()) / (abs(orig_values.mean()) + 1e-8)
                    mean_similarity = max(0, mean_similarity)
                    
                    # í‘œì¤€í¸ì°¨ ìœ ì‚¬ì„±  
                    std_similarity = 1 - abs(orig_values.std() - gen_values.std()) / (orig_values.std() + 1e-8)
                    std_similarity = max(0, std_similarity)
                    
                    similarities.append((mean_similarity + std_similarity) / 2)
            except:
                continue
        
        return np.mean(similarities) if similarities else 0.5
    
    def save_generated_data(self, generated_data: Dict, output_dir: str = "generated_10x_btc_data") -> None:
        """
        ìƒì„±ëœ ë°ì´í„° ì €ì¥
        
        Args:
            generated_data: ìƒì„±ëœ ë°ì´í„°
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        self.logger.info(f"ğŸ’¾ ìƒì„±ëœ ë°ì´í„° ì €ì¥: {output_dir}")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'generation_time': datetime.now().isoformat(),
            'config': asdict(self.config),
            'original_data_info': {
                name: {'shape': df.shape, 'columns': list(df.columns)}
                for name, df in self.original_data.items()
            },
            'generated_data_info': {
                method: {
                    dataset: len(variants)
                    for dataset, variants in method_data.items()
                }
                for method, method_data in generated_data.items()
            }
        }
        
        with open(os.path.join(output_dir, 'metadata.json'), 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
        
        # ë°ì´í„° ì €ì¥
        for method_name, method_data in generated_data.items():
            method_dir = os.path.join(output_dir, method_name)
            os.makedirs(method_dir, exist_ok=True)
            
            for dataset_name, variants in method_data.items():
                dataset_dir = os.path.join(method_dir, dataset_name)
                os.makedirs(dataset_dir, exist_ok=True)
                
                for i, variant in enumerate(variants):
                    if isinstance(variant, pd.DataFrame):
                        # CSV ì €ì¥
                        if 'csv' in self.config.output_formats:
                            variant.to_csv(os.path.join(dataset_dir, f'variant_{i:03d}.csv'), index=True)
                        
                        # Parquet ì €ì¥ (ì••ì¶•)
                        if 'parquet' in self.config.output_formats and self.config.compression:
                            try:
                                variant.to_parquet(os.path.join(dataset_dir, f'variant_{i:03d}.parquet'))
                            except:
                                pass
        
        self.logger.info("âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ")
    
    def generate_comprehensive_report(self, 
                                    generated_data: Dict,
                                    generation_metrics: GenerationMetrics,
                                    validation_results: Dict) -> str:
        """
        ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        
        Args:
            generated_data: ìƒì„±ëœ ë°ì´í„°
            generation_metrics: ìƒì„± ë©”íŠ¸ë¦­
            validation_results: ê²€ì¦ ê²°ê³¼
            
        Returns:
            HTML ë³´ê³ ì„œ
        """
        # í†µê³„ ê³„ì‚°
        total_original = generation_metrics.original_samples
        total_generated = generation_metrics.generated_samples
        
        # ê¸°ë²•ë³„ ê¸°ì—¬ë„ ê³„ì‚°
        method_contributions = {}
        for method_name, method_data in generated_data.items():
            count = sum(len(variants) for variants in method_data.values())
            method_contributions[method_name] = count
        
        html_report = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>10ë°° ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ìƒì„± ë³´ê³ ì„œ</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 5px; }}
                .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
                .metric {{ display: inline-block; margin: 10px; padding: 10px; background: #f8f9fa; border-radius: 3px; }}
                .success {{ background: #d4edda; color: #155724; }}
                .warning {{ background: #fff3cd; color: #856404; }}
                .danger {{ background: #f8d7da; color: #721c24; }}
                table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background: #f2f2f2; }}
                .progress-bar {{ width: 100%; background: #f0f0f0; border-radius: 10px; }}
                .progress {{ height: 20px; background: #007bff; border-radius: 10px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸš€ 10ë°° ë¹„íŠ¸ì½”ì¸ í›ˆë ¨ ë°ì´í„° ìƒì„± ë³´ê³ ì„œ</h1>
                <p>ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p>ëª©í‘œ ë‹¬ì„±ë¥ : {(generation_metrics.multiplication_factor / self.config.target_multiplier) * 100:.1f}%</p>
            </div>
            
            <div class="section">
                <h2>ğŸ“Š ìƒì„± í†µê³„ ìš”ì•½</h2>
                <div class="metric {'success' if generation_metrics.multiplication_factor >= self.config.target_multiplier else 'warning'}">
                    ì´ ì¦ê°€ìœ¨: {generation_metrics.multiplication_factor:.1f}ë°°
                </div>
                <div class="metric">ì›ë³¸ ìƒ˜í”Œ: {total_original:,}ê°œ</div>
                <div class="metric">ìƒì„± ìƒ˜í”Œ: {total_generated:,}ê°œ</div>
                <div class="metric">ì²˜ë¦¬ ì‹œê°„: {generation_metrics.generation_time:.1f}ì´ˆ</div>
                <div class="metric {'success' if generation_metrics.quality_score >= self.config.quality_threshold else 'warning'}">
                    í’ˆì§ˆ ì ìˆ˜: {generation_metrics.quality_score:.3f}
                </div>
            </div>
            
            <div class="section">
                <h2>ğŸ¯ ê¸°ë²•ë³„ ê¸°ì—¬ë„</h2>
                <table>
                    <tr><th>ì¦ê°• ê¸°ë²•</th><th>ìƒì„±ëœ ìƒ˜í”Œ ìˆ˜</th><th>ë¹„ìœ¨</th><th>í’ˆì§ˆ</th></tr>
        """
        
        for method_name, count in method_contributions.items():
            ratio = (count / total_generated) * 100 if total_generated > 0 else 0
            quality = validation_results.get(method_name, 0.5)
            quality_class = 'success' if quality >= 0.7 else 'warning' if quality >= 0.5 else 'danger'
            
            html_report += f"""
                    <tr>
                        <td>{method_name}</td>
                        <td>{count:,}</td>
                        <td>{ratio:.1f}%</td>
                        <td><span class="{quality_class}">{quality:.3f}</span></td>
                    </tr>
            """
        
        html_report += f"""
                </table>
            </div>
            
            <div class="section">
                <h2>ğŸ” í’ˆì§ˆ ê²€ì¦ ê²°ê³¼</h2>
                <p><strong>ì „ì²´ ê²€ì¦ ì ìˆ˜:</strong> {validation_results.get('overall', 0):.3f}</p>
                <div class="progress-bar">
                    <div class="progress" style="width: {validation_results.get('overall', 0) * 100:.1f}%"></div>
                </div>
            </div>
            
            <div class="section">
                <h2>âš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­</h2>
                <div class="metric">ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {generation_metrics.memory_usage:.1f} MB</div>
                <div class="metric">ì„±ê³µë¥ : {generation_metrics.success_rate:.1f}%</div>
                <div class="metric">ì²˜ë¦¬ ì†ë„: {total_generated / generation_metrics.generation_time:.0f} ìƒ˜í”Œ/ì´ˆ</div>
            </div>
            
            <div class="section">
                <h2>âœ… ê¶Œì¥ì‚¬í•­</h2>
                <ul>
        """
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if generation_metrics.multiplication_factor >= self.config.target_multiplier:
            html_report += "<li>âœ… ëª©í‘œ ë‹¬ì„±! ìƒì„±ëœ ë°ì´í„°ë¥¼ ëª¨ë¸ í›ˆë ¨ì— í™œìš©í•˜ì„¸ìš”.</li>"
        else:
            html_report += "<li>âš ï¸ ëª©í‘œ ë¯¸ë‹¬ì„±. ì¶”ê°€ ë°ì´í„° ìƒì„±ì„ ê³ ë ¤í•˜ì„¸ìš”.</li>"
        
        if generation_metrics.quality_score >= self.config.quality_threshold:
            html_report += "<li>âœ… í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±. ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤.</li>"
        else:
            html_report += "<li>âš ï¸ í’ˆì§ˆ ê°œì„  í•„ìš”. í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸ì„ ì¬ê²€í† í•˜ì„¸ìš”.</li>"
        
        html_report += """
                    <li>ğŸ”„ ì •ê¸°ì ì¸ ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ìˆ˜í–‰</li>
                    <li>ğŸ“Š ìƒì„±ëœ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ A/B í…ŒìŠ¤íŠ¸ ì‹¤ì‹œ</li>
                    <li>ğŸ¯ ë†’ì€ í’ˆì§ˆì˜ ê¸°ë²•ì— ë” ë§ì€ ë¦¬ì†ŒìŠ¤ í• ë‹¹</li>
                </ul>
            </div>
        </body>
        </html>
        """
        
        return html_report
    
    def run_integrated_pipeline(self, data_path: str = None) -> GenerationMetrics:
        """
        í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            data_path: ë°ì´í„° ê²½ë¡œ
            
        Returns:
            ìƒì„± ë©”íŠ¸ë¦­
        """
        self.start_time = time.time()
        self.logger.info("ğŸš€ í†µí•© 10ë°° ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
        
        try:
            # 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ
            self.load_source_data(data_path)
            original_samples = sum(len(df) for df in self.original_data.values())
            
            # 2. ìƒì„± ëª©í‘œ ê³„ì‚°
            targets = self.calculate_generation_targets()
            
            # 3. ë³‘ë ¬ ë°ì´í„° ìƒì„±
            generated_data = self.parallel_data_generation(targets)
            
            # 4. í’ˆì§ˆ í–¥ìƒ ì ìš©
            enhanced_data = self.apply_quality_enhancement(generated_data)
            
            # 5. ë°ì´í„° ê²€ì¦
            validation_results = self.validate_generated_data(enhanced_data)
            
            # 6. ë°ì´í„° ì €ì¥
            self.save_generated_data(enhanced_data)
            
            # 7. ë©”íŠ¸ë¦­ ê³„ì‚°
            generated_samples = sum(
                len(variants) 
                for method_data in enhanced_data.values()
                for variants in method_data.values()
            )
            
            generation_time = time.time() - self.start_time
            
            metrics = GenerationMetrics(
                original_samples=original_samples,
                generated_samples=generated_samples,
                multiplication_factor=(original_samples + generated_samples) / original_samples if original_samples > 0 else 0,
                quality_score=validation_results.get('overall', 0),
                generation_time=generation_time,
                memory_usage=0,  # ì‹¤ì œ êµ¬í˜„ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
                success_rate=100.0 if generated_samples > 0 else 0
            )
            
            # 8. ë³´ê³ ì„œ ìƒì„±
            report = self.generate_comprehensive_report(enhanced_data, metrics, validation_results)
            
            with open("10x_data_generation_report.html", "w", encoding="utf-8") as f:
                f.write(report)
            
            self.logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! {metrics.multiplication_factor:.1f}ë°° ì¦ê°€ ë‹¬ì„±")
            self.logger.info(f"ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: 10x_data_generation_report.html")
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í†µí•© 10ë°° ë¹„íŠ¸ì½”ì¸ í›ˆë ¨ ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸")
    
    # ì„¤ì •
    config = DataGenerationConfig(
        target_multiplier=10,
        quality_threshold=0.6,
        max_workers=2,  # í…ŒìŠ¤íŠ¸ìš© ë‚®ì€ ê°’
        enable_quality_control=True,
        enable_validation=True
    )
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = Integrated10xDataGenerationPipeline(config)
    
    # ì‹¤í–‰
    try:
        metrics = pipeline.run_integrated_pipeline()
        
        print(f"\nğŸ‰ ì„±ê³µì  ì™„ë£Œ!")
        print(f"ğŸ“Š ì›ë³¸: {metrics.original_samples:,} â†’ ìµœì¢…: {metrics.generated_samples + metrics.original_samples:,}")
        print(f"ğŸ“ˆ ì¦ê°€ìœ¨: {metrics.multiplication_factor:.1f}ë°°")
        print(f"ğŸ” í’ˆì§ˆ: {metrics.quality_score:.3f}")
        print(f"â±ï¸ ì‹œê°„: {metrics.generation_time:.1f}ì´ˆ")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()