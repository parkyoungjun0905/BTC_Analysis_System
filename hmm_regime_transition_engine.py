#!/usr/bin/env python3
"""
Hidden Markov Model ê¸°ë°˜ ì²´ì œ ì „í™˜ ê°ì§€ ì—”ì§„
Bitcoin ì‹œì¥ì˜ ìˆ¨ê²¨ì§„ ìƒíƒœ(ì²´ì œ) ì „í™˜ì„ í†µê³„ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê³  ì˜ˆì¸¡

í•µì‹¬ ê¸°ëŠ¥:
1. ì‹œì¥ ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ ì²´ì œ ìƒíƒœ ì¶”ë¡ 
2. ì²´ì œ ì „í™˜ í™•ë¥  ë° íƒ€ì´ë° ì˜ˆì¸¡  
3. ì²´ì œë³„ ê´€ì¸¡ê°’ ë¶„í¬ í•™ìŠµ
4. ì‹¤ì‹œê°„ ì²´ì œ ì „í™˜ ì‹ í˜¸ ê°ì§€
"""

import os
import json
import sqlite3
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
import logging
from dataclasses import dataclass, asdict
import asyncio
import pickle
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import warnings
warnings.filterwarnings("ignore")

# HMM ë¼ì´ë¸ŒëŸ¬ë¦¬ ëŒ€ì‹  ìˆ˜ì¹˜ì  êµ¬í˜„
from scipy.stats import multivariate_normal
from scipy.special import logsumexp

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class HMMRegimeState:
    """HMM ì²´ì œ ìƒíƒœ ì •ì˜"""
    state_id: int
    state_name: str
    mean_features: np.ndarray
    covariance_matrix: np.ndarray
    steady_state_probability: float
    avg_duration_days: float
    
@dataclass 
class RegimeTransition:
    """ì²´ì œ ì „í™˜ ì •ë³´"""
    from_state: str
    to_state: str
    transition_probability: float
    predicted_timing: datetime
    confidence: float
    leading_indicators: List[str]
    market_catalysts: List[str]

class HMMRegimeTransitionEngine:
    """Hidden Markov Model ê¸°ë°˜ ì²´ì œ ì „í™˜ ì—”ì§„"""
    
    def __init__(self, base_path: str = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"):
        self.base_path = base_path
        self.db_path = os.path.join(base_path, "hmm_regime_db.db")
        self.models_path = os.path.join(base_path, "hmm_models")
        os.makedirs(self.models_path, exist_ok=True)
        
        # HMM íŒŒë¼ë¯¸í„°
        self.n_states = 5  # 5ê°œ ì²´ì œ
        self.n_features = 8  # ê´€ì¸¡ íŠ¹ì§• ìˆ˜
        
        # ìƒíƒœ ì •ì˜ (0ë¶€í„° ì‹œì‘)
        self.state_names = {
            0: "LOW_VOLATILITY_ACCUMULATION",
            1: "BULL_MARKET", 
            2: "SIDEWAYS",
            3: "BEAR_MARKET",
            4: "HIGH_VOLATILITY_SHOCK"
        }
        
        # HMM ëª¨ë¸ íŒŒë¼ë¯¸í„°ë“¤
        self.transition_matrix = None  # A[i,j] = P(state_j | state_i)
        self.emission_means = None     # ê° ìƒíƒœë³„ ê´€ì¸¡ê°’ í‰ê· 
        self.emission_covariances = None # ê° ìƒíƒœë³„ ê´€ì¸¡ê°’ ê³µë¶„ì‚°
        self.initial_probs = None      # ì´ˆê¸° ìƒíƒœ í™•ë¥ 
        
        # í•™ìŠµëœ ëª¨ë¸ ìƒíƒœ
        self.is_trained = False
        self.scaler = StandardScaler()
        
        # í˜„ì¬ ì¶”ì • ìƒíƒœ
        self.current_state_probs = np.ones(self.n_states) / self.n_states
        self.state_history = []
        
        # ì²´ì œ ì „í™˜ ê°ì§€ íŒŒë¼ë¯¸í„°
        self.transition_threshold = 0.3  # ì „í™˜ ê°ì§€ ì„ê³„ê°’
        self.confidence_threshold = 0.7   # ì‹ ë¢°ë„ ì„ê³„ê°’
        self.lookback_window = 20        # ê´€ì¸¡ ìœˆë„ìš° (ì¼)
        
        self.init_database()
        self.load_hmm_model()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # HMM ìƒíƒœ ê¸°ë¡
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS hmm_states (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    predicted_state INTEGER NOT NULL,
                    state_name TEXT NOT NULL,
                    state_probabilities TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    observation_features TEXT NOT NULL,
                    forward_probability REAL,
                    backward_probability REAL
                )
            ''')
            
            # ì²´ì œ ì „í™˜ ì˜ˆì¸¡
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS regime_transitions_hmm (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    from_state INTEGER NOT NULL,
                    to_state INTEGER NOT NULL,
                    from_state_name TEXT NOT NULL,
                    to_state_name TEXT NOT NULL,
                    transition_probability REAL NOT NULL,
                    predicted_timing TEXT,
                    confidence REAL NOT NULL,
                    leading_indicators TEXT NOT NULL,
                    actual_transition BOOLEAN,
                    verification_timestamp TEXT
                )
            ''')
            
            # HMM ëª¨ë¸ íŒŒë¼ë¯¸í„°
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS hmm_model_params (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    model_version TEXT NOT NULL,
                    transition_matrix TEXT NOT NULL,
                    emission_means TEXT NOT NULL,
                    emission_covariances TEXT NOT NULL,
                    initial_probabilities TEXT NOT NULL,
                    training_date TEXT NOT NULL,
                    training_samples INTEGER NOT NULL,
                    log_likelihood REAL,
                    is_active BOOLEAN DEFAULT TRUE
                )
            ''')
            
            # í•™ìŠµ ë°ì´í„°
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS hmm_training_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    features TEXT NOT NULL,
                    true_state INTEGER,
                    true_state_name TEXT,
                    is_validated BOOLEAN DEFAULT FALSE
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("âœ… HMM ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"HMM ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def load_hmm_model(self):
        """í•™ìŠµëœ HMM ëª¨ë¸ ë¡œë“œ"""
        try:
            model_file = os.path.join(self.models_path, "hmm_regime_model.pkl")
            if os.path.exists(model_file):
                with open(model_file, 'rb') as f:
                    model_data = pickle.load(f)
                    
                    self.transition_matrix = model_data.get('transition_matrix')
                    self.emission_means = model_data.get('emission_means')
                    self.emission_covariances = model_data.get('emission_covariances') 
                    self.initial_probs = model_data.get('initial_probs')
                    self.scaler = model_data.get('scaler', StandardScaler())
                    
                    if all(x is not None for x in [self.transition_matrix, self.emission_means, 
                                                  self.emission_covariances, self.initial_probs]):
                        self.is_trained = True
                        logger.info("âœ… HMM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    else:
                        logger.warning("âš ï¸ HMM ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¶ˆì™„ì „")
            else:
                logger.info("HMM ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.")
                self.initialize_default_parameters()
                
        except Exception as e:
            logger.error(f"HMM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.initialize_default_parameters()
    
    def initialize_default_parameters(self):
        """ê¸°ë³¸ HMM íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”"""
        try:
            # ì „í™˜ í™•ë¥  í–‰ë ¬ (ê²½í—˜ì  ì¶”ì •ê°’)
            self.transition_matrix = np.array([
                # LOW_VOL, BULL, SIDEWAYS, BEAR, HIGH_VOL
                [0.7,     0.2,  0.05,     0.03,  0.02],   # LOW_VOLATILITY_ACCUMULATION
                [0.05,    0.75, 0.15,     0.04,  0.01],   # BULL_MARKET
                [0.1,     0.25, 0.5,      0.1,   0.05],   # SIDEWAYS
                [0.02,    0.03, 0.15,     0.75,  0.05],   # BEAR_MARKET
                [0.15,    0.2,  0.3,      0.25,  0.1]     # HIGH_VOLATILITY_SHOCK
            ])
            
            # ê´€ì¸¡ê°’ í‰ê·  (ê° ìƒíƒœë³„)
            self.emission_means = np.array([
                [0.01,  0.02,  0.3,   45,   0.5,  0.0,   60,   0.1],   # LOW_VOL
                [0.05,  0.03,  0.8,   65,   0.7,  0.05,  75,   0.6],   # BULL
                [0.0,   0.025, 0.5,   50,   0.5,  0.0,   50,   0.3],   # SIDEWAYS
                [-0.05, 0.04,  0.2,   35,   0.3, -0.05,  25,   0.2],   # BEAR
                [0.0,   0.08,  0.4,   50,   0.5,  0.0,   40,   0.4]    # HIGH_VOL
            ])
            
            # ê³µë¶„ì‚° í–‰ë ¬ (ë‹¨ìˆœí™”ëœ ëŒ€ê° í–‰ë ¬)
            self.emission_covariances = np.array([
                np.diag([0.01, 0.005, 0.2, 100, 0.1, 0.02, 200, 0.1]) for _ in range(self.n_states)
            ])
            
            # ì´ˆê¸° ìƒíƒœ í™•ë¥ 
            self.initial_probs = np.array([0.2, 0.2, 0.4, 0.1, 0.1])
            
            logger.info("âœ… ê¸°ë³¸ HMM íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def train_hmm_model(self, training_data: List[Dict], max_iterations: int = 100) -> Dict:
        """Baum-Welch ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ HMM ëª¨ë¸ í•™ìŠµ"""
        try:
            if not training_data:
                return {"error": "í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            logger.info(f"ğŸ§  HMM ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë°ì´í„°: {len(training_data)}ê°œ)")
            
            # íŠ¹ì§•ê°’ ì¶”ì¶œ ë° ì „ì²˜ë¦¬
            observations = []
            true_states = []
            
            for data in training_data:
                features = data.get('features')
                true_state = data.get('true_state')
                
                if features and len(features) == self.n_features:
                    observations.append(features)
                    if true_state is not None:
                        true_states.append(true_state)
            
            if len(observations) < 10:
                return {"error": "ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            observations = np.array(observations)
            observations = self.scaler.fit_transform(observations)
            T = len(observations)
            
            # Baum-Welch ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
            log_likelihood_history = []
            
            for iteration in range(max_iterations):
                # Forward-Backward ì•Œê³ ë¦¬ì¦˜
                alpha, c = self.forward_algorithm(observations)
                beta = self.backward_algorithm(observations, c)
                
                # í˜„ì¬ log-likelihood ê³„ì‚°
                log_likelihood = -np.sum(np.log(c))
                log_likelihood_history.append(log_likelihood)
                
                if iteration > 0:
                    improvement = log_likelihood - log_likelihood_history[-2]
                    if abs(improvement) < 1e-6:
                        logger.info(f"ìˆ˜ë ´ ì™„ë£Œ (ë°˜ë³µ: {iteration})")
                        break
                
                # Expectation step
                gamma, xi = self.expectation_step(alpha, beta, observations)
                
                # Maximization step
                self.maximization_step(observations, gamma, xi)
                
                if iteration % 10 == 0:
                    logger.info(f"ë°˜ë³µ {iteration}: Log-likelihood = {log_likelihood:.2f}")
            
            # í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ ì €ì¥
            await self.save_hmm_model(log_likelihood_history[-1], len(training_data))
            
            self.is_trained = True
            
            return {
                "training_completed": True,
                "iterations": len(log_likelihood_history),
                "final_log_likelihood": log_likelihood_history[-1],
                "training_samples": len(observations),
                "convergence_improvement": log_likelihood_history[-1] - log_likelihood_history[0] if len(log_likelihood_history) > 1 else 0
            }
            
        except Exception as e:
            logger.error(f"HMM ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def forward_algorithm(self, observations: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Forward ì•Œê³ ë¦¬ì¦˜"""
        T = len(observations)
        alpha = np.zeros((T, self.n_states))
        c = np.zeros(T)  # scaling factor
        
        # ì´ˆê¸°í™” (t=0)
        for i in range(self.n_states):
            alpha[0, i] = self.initial_probs[i] * self.emission_probability(observations[0], i)
        
        c[0] = np.sum(alpha[0])
        if c[0] > 0:
            alpha[0] /= c[0]
        
        # ìˆœë°©í–¥ ê³„ì‚° (t=1 to T-1)
        for t in range(1, T):
            for j in range(self.n_states):
                alpha[t, j] = np.sum(alpha[t-1] * self.transition_matrix[:, j]) * \
                             self.emission_probability(observations[t], j)
            
            c[t] = np.sum(alpha[t])
            if c[t] > 0:
                alpha[t] /= c[t]
        
        return alpha, c
    
    def backward_algorithm(self, observations: np.ndarray, c: np.ndarray) -> np.ndarray:
        """Backward ì•Œê³ ë¦¬ì¦˜"""
        T = len(observations)
        beta = np.zeros((T, self.n_states))
        
        # ì´ˆê¸°í™” (t=T-1)
        beta[T-1] = 1.0
        
        # ì—­ë°©í–¥ ê³„ì‚° (t=T-2 to 0)
        for t in range(T-2, -1, -1):
            for i in range(self.n_states):
                beta[t, i] = np.sum(
                    self.transition_matrix[i] * 
                    np.array([self.emission_probability(observations[t+1], j) for j in range(self.n_states)]) * 
                    beta[t+1]
                )
            
            if c[t+1] > 0:
                beta[t] /= c[t+1]
        
        return beta
    
    def expectation_step(self, alpha: np.ndarray, beta: np.ndarray, 
                        observations: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Expectation step (gamma, xi ê³„ì‚°)"""
        T = len(observations)
        
        # gamma[t][i] = P(state=i at time t | observations)
        gamma = alpha * beta
        gamma_sum = np.sum(gamma, axis=1, keepdims=True)
        gamma = gamma / np.maximum(gamma_sum, 1e-10)
        
        # xi[t][i][j] = P(state=i at t, state=j at t+1 | observations)
        xi = np.zeros((T-1, self.n_states, self.n_states))
        
        for t in range(T-1):
            for i in range(self.n_states):
                for j in range(self.n_states):
                    xi[t, i, j] = (alpha[t, i] * self.transition_matrix[i, j] * 
                                  self.emission_probability(observations[t+1], j) * 
                                  beta[t+1, j])
            
            xi_sum = np.sum(xi[t])
            if xi_sum > 0:
                xi[t] /= xi_sum
        
        return gamma, xi
    
    def maximization_step(self, observations: np.ndarray, gamma: np.ndarray, xi: np.ndarray):
        """Maximization step (íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸)"""
        T = len(observations)
        
        # ì´ˆê¸° ìƒíƒœ í™•ë¥  ì—…ë°ì´íŠ¸
        self.initial_probs = gamma[0]
        
        # ì „í™˜ í™•ë¥  ì—…ë°ì´íŠ¸
        for i in range(self.n_states):
            for j in range(self.n_states):
                numerator = np.sum(xi[:, i, j])
                denominator = np.sum(gamma[:-1, i])
                self.transition_matrix[i, j] = numerator / max(denominator, 1e-10)
        
        # ê´€ì¸¡ í™•ë¥  íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ (ê°€ìš°ì‹œì•ˆ ê°€ì •)
        for i in range(self.n_states):
            gamma_sum = np.sum(gamma[:, i])
            
            if gamma_sum > 0:
                # í‰ê·  ì—…ë°ì´íŠ¸
                self.emission_means[i] = np.sum(observations * gamma[:, i:i+1], axis=0) / gamma_sum
                
                # ê³µë¶„ì‚° ì—…ë°ì´íŠ¸
                diff = observations - self.emission_means[i]
                self.emission_covariances[i] = np.sum(
                    gamma[:, i:i+1] * diff[:, :, np.newaxis] * diff[:, np.newaxis, :], axis=0
                ) / gamma_sum
                
                # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•œ ì •ê·œí™”
                self.emission_covariances[i] += np.eye(self.n_features) * 1e-6
    
    def emission_probability(self, observation: np.ndarray, state: int) -> float:
        """ê´€ì¸¡ê°’ì— ëŒ€í•œ ë°©ì¶œ í™•ë¥  (ë‹¤ë³€ëŸ‰ ê°€ìš°ì‹œì•ˆ)"""
        try:
            mean = self.emission_means[state]
            cov = self.emission_covariances[state]
            
            # ìˆ˜ì¹˜ì  ì•ˆì •ì„± ì²´í¬
            if np.any(np.isnan(observation)) or np.any(np.isnan(mean)):
                return 1e-10
            
            # ê³µë¶„ì‚° í–‰ë ¬ì˜ íŠ¹ì´ê°’ ì²˜ë¦¬
            try:
                prob = multivariate_normal.pdf(observation, mean, cov)
                return max(prob, 1e-10)  # ìµœì†Œê°’ ë³´ì¥
            except:
                return 1e-10
                
        except Exception as e:
            logger.error(f"ë°©ì¶œ í™•ë¥  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1e-10
    
    async def predict_regime_state(self, market_features: np.ndarray) -> Dict:
        """í˜„ì¬ ì‹œì¥ íŠ¹ì§•ìœ¼ë¡œë¶€í„° ì²´ì œ ìƒíƒœ ì˜ˆì¸¡"""
        try:
            if not self.is_trained:
                return {"error": "HMM ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
            
            # íŠ¹ì§•ê°’ ì „ì²˜ë¦¬
            features_scaled = self.scaler.transform(market_features.reshape(1, -1))[0]
            
            # ê° ìƒíƒœë³„ ê´€ì¸¡ í™•ë¥  ê³„ì‚°
            state_likelihoods = np.array([
                self.emission_probability(features_scaled, i) for i in range(self.n_states)
            ])
            
            # ì´ì „ ìƒíƒœ í™•ë¥ ê³¼ ì „í™˜ í™•ë¥  ê³ ë ¤
            prior_probs = self.current_state_probs @ self.transition_matrix
            
            # ë² ì´ì¦ˆ ì—…ë°ì´íŠ¸
            posterior_probs = prior_probs * state_likelihoods
            posterior_probs /= np.sum(posterior_probs)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.current_state_probs = posterior_probs
            
            # ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ìƒíƒœ
            predicted_state = np.argmax(posterior_probs)
            confidence = posterior_probs[predicted_state]
            
            # ìƒíƒœ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            self.state_history.append({
                "timestamp": datetime.now(),
                "predicted_state": predicted_state,
                "confidence": confidence,
                "all_probabilities": posterior_probs.tolist()
            })
            
            # ì²´ì œ ì „í™˜ ê°ì§€
            transition_info = self.detect_regime_transition()
            
            result = {
                "predicted_state": predicted_state,
                "state_name": self.state_names[predicted_state],
                "confidence": confidence,
                "state_probabilities": {
                    self.state_names[i]: prob for i, prob in enumerate(posterior_probs)
                },
                "transition_detected": transition_info.get("transition_detected", False),
                "transition_info": transition_info,
                "timestamp": datetime.now().isoformat()
            }
            
            # ê²°ê³¼ ì €ì¥
            await self.save_state_prediction(result, features_scaled)
            
            return result
            
        except Exception as e:
            logger.error(f"ì²´ì œ ìƒíƒœ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def detect_regime_transition(self) -> Dict:
        """ì²´ì œ ì „í™˜ ê°ì§€"""
        try:
            if len(self.state_history) < 2:
                return {"transition_detected": False}
            
            current_probs = self.state_history[-1]["all_probabilities"]
            previous_probs = self.state_history[-2]["all_probabilities"]
            
            # ìƒíƒœ í™•ë¥  ë³€í™”ëŸ‰ ê³„ì‚°
            prob_changes = np.array(current_probs) - np.array(previous_probs)
            max_increase = np.max(prob_changes)
            max_decrease = np.min(prob_changes)
            
            # ì „í™˜ ì¡°ê±´ í™•ì¸
            transition_detected = False
            from_state = None
            to_state = None
            
            if max_increase > self.transition_threshold and abs(max_decrease) > self.transition_threshold:
                from_state = int(np.argmin(prob_changes))
                to_state = int(np.argmax(prob_changes))
                
                # ì‹ ë¢°ë„ í™•ì¸
                if current_probs[to_state] > self.confidence_threshold:
                    transition_detected = True
            
            # ì „í™˜ íƒ€ì´ë° ì˜ˆì¸¡
            predicted_timing = None
            if transition_detected:
                predicted_timing = self.predict_transition_timing(from_state, to_state)
            
            return {
                "transition_detected": transition_detected,
                "from_state": from_state,
                "to_state": to_state,
                "from_state_name": self.state_names.get(from_state) if from_state is not None else None,
                "to_state_name": self.state_names.get(to_state) if to_state is not None else None,
                "probability_change": max_increase,
                "confidence": current_probs[to_state] if to_state is not None else 0,
                "predicted_timing": predicted_timing,
                "leading_indicators": self.identify_leading_indicators(from_state, to_state)
            }
            
        except Exception as e:
            logger.error(f"ì²´ì œ ì „í™˜ ê°ì§€ ì‹¤íŒ¨: {e}")
            return {"transition_detected": False, "error": str(e)}
    
    def predict_transition_timing(self, from_state: int, to_state: int) -> Optional[str]:
        """ì²´ì œ ì „í™˜ íƒ€ì´ë° ì˜ˆì¸¡"""
        try:
            # ì „í™˜ í™•ë¥  ê¸°ë°˜ ì˜ˆìƒ ëŒ€ê¸° ì‹œê°„ ê³„ì‚°
            transition_prob = self.transition_matrix[from_state, to_state]
            
            if transition_prob > 0:
                # ê¸°í•˜ ë¶„í¬ ê¸°ë°˜ ì˜ˆìƒ ëŒ€ê¸° ì‹œê°„ (ì¼)
                expected_days = 1 / transition_prob
                predicted_date = datetime.now() + timedelta(days=expected_days)
                return predicted_date.isoformat()
            
            return None
            
        except Exception as e:
            logger.error(f"ì „í™˜ íƒ€ì´ë° ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None
    
    def identify_leading_indicators(self, from_state: Optional[int], to_state: Optional[int]) -> List[str]:
        """ì²´ì œ ì „í™˜ ì„ í–‰ ì§€í‘œ ì‹ë³„"""
        indicators = []
        
        try:
            if from_state is None or to_state is None:
                return indicators
            
            # ìƒíƒœë³„ ì£¼ìš” íŠ¹ì§• ì¸ë±ìŠ¤
            feature_names = [
                "price_trend", "volatility", "volume_trend", "rsi", 
                "whale_activity", "funding_rate", "fear_greed", "correlation"
            ]
            
            # ë‘ ìƒíƒœê°„ íŠ¹ì§•ê°’ ì°¨ì´ ë¶„ì„
            from_mean = self.emission_means[from_state]
            to_mean = self.emission_means[to_state]
            
            differences = np.abs(to_mean - from_mean)
            significant_indices = np.where(differences > np.std(differences))[0]
            
            for idx in significant_indices:
                if idx < len(feature_names):
                    indicators.append(feature_names[idx])
            
            # ìƒíƒœë³„ íŠ¹í™” ì§€í‘œ ì¶”ê°€
            state_specific_indicators = {
                0: ["hodler_behavior", "whale_accumulation", "low_volume"],    # LOW_VOL
                1: ["momentum_indicators", "volume_surge", "positive_sentiment"], # BULL
                2: ["range_indicators", "consolidation_patterns"],              # SIDEWAYS
                3: ["fear_indicators", "selling_pressure", "exchange_inflows"], # BEAR
                4: ["volatility_spike", "liquidations", "news_events"]         # HIGH_VOL
            }
            
            if to_state in state_specific_indicators:
                indicators.extend(state_specific_indicators[to_state])
            
        except Exception as e:
            logger.error(f"ì„ í–‰ ì§€í‘œ ì‹ë³„ ì‹¤íŒ¨: {e}")
        
        return indicators[:5]  # ìƒìœ„ 5ê°œ ì§€í‘œë§Œ ë°˜í™˜
    
    async def save_hmm_model(self, log_likelihood: float, training_samples: int):
        """HMM ëª¨ë¸ ì €ì¥"""
        try:
            # íŒŒì¼ ì €ì¥
            model_data = {
                'transition_matrix': self.transition_matrix,
                'emission_means': self.emission_means,
                'emission_covariances': self.emission_covariances,
                'initial_probs': self.initial_probs,
                'scaler': self.scaler
            }
            
            model_file = os.path.join(self.models_path, "hmm_regime_model.pkl")
            with open(model_file, 'wb') as f:
                pickle.dump(model_data, f)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO hmm_model_params 
                (model_version, transition_matrix, emission_means, emission_covariances,
                 initial_probabilities, training_date, training_samples, log_likelihood, is_active)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                f"v{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                json.dumps(self.transition_matrix.tolist()),
                json.dumps(self.emission_means.tolist()),
                json.dumps([cov.tolist() for cov in self.emission_covariances]),
                json.dumps(self.initial_probs.tolist()),
                datetime.now().isoformat(),
                training_samples,
                log_likelihood,
                True
            ))
            
            # ì´ì „ ëª¨ë¸ë“¤ì„ ë¹„í™œì„±í™”
            cursor.execute('UPDATE hmm_model_params SET is_active = FALSE WHERE id != last_insert_rowid()')
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… HMM ëª¨ë¸ ì €ì¥ ì™„ë£Œ (Log-likelihood: {log_likelihood:.2f})")
            
        except Exception as e:
            logger.error(f"HMM ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def save_state_prediction(self, prediction: Dict, features: np.ndarray):
        """ìƒíƒœ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO hmm_states 
                (timestamp, predicted_state, state_name, state_probabilities, 
                 confidence, observation_features)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                prediction["timestamp"],
                prediction["predicted_state"],
                prediction["state_name"],
                json.dumps(prediction["state_probabilities"]),
                prediction["confidence"],
                json.dumps(features.tolist())
            ))
            
            # ì²´ì œ ì „í™˜ì´ ê°ì§€ë˜ë©´ ë³„ë„ ì €ì¥
            if prediction["transition_detected"]:
                transition_info = prediction["transition_info"]
                cursor.execute('''
                    INSERT INTO regime_transitions_hmm
                    (timestamp, from_state, to_state, from_state_name, to_state_name,
                     transition_probability, predicted_timing, confidence, leading_indicators)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    prediction["timestamp"],
                    transition_info.get("from_state"),
                    transition_info.get("to_state"),
                    transition_info.get("from_state_name"),
                    transition_info.get("to_state_name"),
                    transition_info.get("probability_change"),
                    transition_info.get("predicted_timing"),
                    transition_info.get("confidence"),
                    json.dumps(transition_info.get("leading_indicators", []))
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ìƒíƒœ ì˜ˆì¸¡ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def generate_transition_forecast(self, horizon_days: int = 7) -> Dict:
        """ì²´ì œ ì „í™˜ ì˜ˆì¸¡ (ì§€ì •ëœ ê¸°ê°„ ë‚´)"""
        try:
            if not self.is_trained:
                return {"error": "HMM ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
            
            forecasts = []
            current_probs = self.current_state_probs.copy()
            
            for day in range(1, horizon_days + 1):
                # ë‹¤ìŒ ë‚  ìƒíƒœ í™•ë¥  ê³„ì‚°
                next_probs = current_probs @ self.transition_matrix
                
                # ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ìƒíƒœ
                predicted_state = np.argmax(next_probs)
                confidence = next_probs[predicted_state]
                
                # ì „í™˜ í™•ë¥  (í˜„ì¬ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œ)
                current_state = np.argmax(current_probs)
                transition_probs = {}
                
                for i in range(self.n_states):
                    if i != current_state:
                        transition_probs[self.state_names[i]] = self.transition_matrix[current_state, i]
                
                forecasts.append({
                    "day": day,
                    "date": (datetime.now() + timedelta(days=day)).isoformat(),
                    "predicted_state": predicted_state,
                    "state_name": self.state_names[predicted_state],
                    "confidence": confidence,
                    "state_probabilities": {
                        self.state_names[i]: prob for i, prob in enumerate(next_probs)
                    },
                    "transition_probabilities": transition_probs
                })
                
                current_probs = next_probs
            
            # ì£¼ìš” ì „í™˜ ì‹œì  ì‹ë³„
            major_transitions = []
            for i, forecast in enumerate(forecasts[1:], 1):
                prev_state = forecasts[i-1]["predicted_state"]
                curr_state = forecast["predicted_state"]
                
                if prev_state != curr_state and forecast["confidence"] > 0.6:
                    major_transitions.append({
                        "day": forecast["day"],
                        "date": forecast["date"],
                        "from_state": self.state_names[prev_state],
                        "to_state": self.state_names[curr_state],
                        "confidence": forecast["confidence"]
                    })
            
            return {
                "forecast_horizon_days": horizon_days,
                "daily_forecasts": forecasts,
                "major_transitions": major_transitions,
                "current_state": self.state_names[np.argmax(self.current_state_probs)],
                "current_confidence": np.max(self.current_state_probs),
                "forecast_timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ì „í™˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def get_model_diagnostics(self) -> Dict:
        """HMM ëª¨ë¸ ì§„ë‹¨ ì •ë³´"""
        try:
            diagnostics = {
                "model_status": "trained" if self.is_trained else "untrained",
                "n_states": self.n_states,
                "n_features": self.n_features
            }
            
            if self.is_trained:
                # ì „í™˜ í–‰ë ¬ ë¶„ì„
                diagnostics["transition_matrix"] = {
                    "matrix": self.transition_matrix.tolist(),
                    "most_stable_state": self.state_names[np.argmax(np.diag(self.transition_matrix))],
                    "most_volatile_state": self.state_names[np.argmin(np.diag(self.transition_matrix))]
                }
                
                # ì •ìƒ ìƒíƒœ í™•ë¥  ê³„ì‚°
                eigenvals, eigenvecs = np.linalg.eig(self.transition_matrix.T)
                steady_state_idx = np.argmax(eigenvals.real)
                steady_state = np.abs(eigenvecs[:, steady_state_idx].real)
                steady_state /= np.sum(steady_state)
                
                diagnostics["steady_state_probabilities"] = {
                    self.state_names[i]: prob for i, prob in enumerate(steady_state)
                }
                
                # í˜„ì¬ ìƒíƒœ ì •ë³´
                diagnostics["current_state"] = {
                    "probabilities": {self.state_names[i]: prob for i, prob in enumerate(self.current_state_probs)},
                    "most_likely": self.state_names[np.argmax(self.current_state_probs)],
                    "confidence": np.max(self.current_state_probs)
                }
                
                # ìµœê·¼ ìƒíƒœ íˆìŠ¤í† ë¦¬
                if self.state_history:
                    recent_states = self.state_history[-10:]  # ìµœê·¼ 10ê°œ
                    diagnostics["recent_history"] = [
                        {
                            "timestamp": h["timestamp"].isoformat() if isinstance(h["timestamp"], datetime) else h["timestamp"],
                            "state": self.state_names[h["predicted_state"]], 
                            "confidence": h["confidence"]
                        } for h in recent_states
                    ]
            
            return diagnostics
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

# í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰ í•¨ìˆ˜
async def test_hmm_regime_engine():
    """HMM ì²´ì œ ì „í™˜ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¬ HMM ì²´ì œ ì „í™˜ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    engine = HMMRegimeTransitionEngine()
    
    # ëª¨ë¸ ì§„ë‹¨
    diagnostics = await engine.get_model_diagnostics()
    print(f"ğŸ“Š ëª¨ë¸ ìƒíƒœ: {diagnostics.get('model_status')}")
    
    if diagnostics.get('model_status') == 'trained':
        # í…ŒìŠ¤íŠ¸ íŠ¹ì§•ê°’
        test_features = np.array([
            0.02,   # price_trend  
            0.04,   # volatility
            0.5,    # volume_trend
            55,     # rsi
            0.6,    # whale_activity
            0.01,   # funding_rate
            45,     # fear_greed
            0.2     # correlation
        ])
        
        # ìƒíƒœ ì˜ˆì¸¡
        prediction = await engine.predict_regime_state(test_features)
        
        if not prediction.get("error"):
            print(f"ğŸ¯ ì˜ˆì¸¡ ìƒíƒœ: {prediction['state_name']}")
            print(f"ğŸ”¥ ì‹ ë¢°ë„: {prediction['confidence']:.1%}")
            print(f"ğŸ“ˆ ìƒíƒœ í™•ë¥ :")
            for state, prob in prediction['state_probabilities'].items():
                print(f"   â€¢ {state}: {prob:.1%}")
            
            if prediction.get('transition_detected'):
                trans = prediction['transition_info']
                print(f"âš¡ ì²´ì œ ì „í™˜ ê°ì§€!")
                print(f"   â€¢ {trans['from_state_name']} â†’ {trans['to_state_name']}")
                print(f"   â€¢ ì‹ ë¢°ë„: {trans['confidence']:.1%}")
                if trans.get('predicted_timing'):
                    print(f"   â€¢ ì˜ˆìƒ ì‹œì : {trans['predicted_timing']}")
        
        # ë¯¸ë˜ ì˜ˆì¸¡
        forecast = await engine.generate_transition_forecast(7)
        if not forecast.get("error"):
            print(f"\nğŸ“… 7ì¼ ì˜ˆì¸¡:")
            for transition in forecast.get('major_transitions', []):
                print(f"   â€¢ Day {transition['day']}: {transition['from_state']} â†’ {transition['to_state']} ({transition['confidence']:.1%})")
    else:
        print("âš ï¸ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ HMM ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(test_hmm_regime_engine())