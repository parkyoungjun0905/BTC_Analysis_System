#!/usr/bin/env python3
"""
ğŸ¯ ë¬´í•œ ë°±í…ŒìŠ¤íŠ¸ 95% ì •í™•ë„ ê³µì‹ ë°œê²¬ê¸°
- ê³¼ê±° ì„ì˜ ì‹œì ì—ì„œ ì˜ˆì¸¡ â†’ ì‹¤ì œê°’ ê²€ì¦ â†’ í•™ìŠµ â†’ ë¬´í•œ ë°˜ë³µ
- ìµœì ì˜ ì§€í‘œ ì¡°í•©ê³¼ ì ìš© ê³µì‹ ìë™ ë°œê²¬
- 95%+ ì •í™•ë„ ë‹¬ì„±ê¹Œì§€ ì§€ì†ì  ì§„í™”
"""

import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import warnings
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.preprocessing import RobustScaler, PolynomialFeatures
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.model_selection import cross_val_score
import itertools
import random

warnings.filterwarnings('ignore')

class InfiniteBacktestFormulaDiscoverer:
    """ë¬´í•œ ë°±í…ŒìŠ¤íŠ¸ 95% ê³µì‹ ë°œê²¬ê¸°"""
    
    def __init__(self):
        self.data_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.historical_data = None
        self.best_formulas = []  # ë°œê²¬ëœ ìµœê³  ê³µì‹ë“¤
        self.learning_iterations = 0
        self.current_best_accuracy = 0.0
        self.target_accuracy = 95.0
        
        # ì§€í‘œ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        self.indicator_categories = {
            'price': ['price', 'close', 'open', 'high', 'low'],
            'volume': ['volume', 'trade_volume'],
            'technical': ['rsi', 'macd', 'bollinger', 'sma', 'ema'],
            'onchain': ['whale_ratio', 'mvrv', 'sopr', 'nvt'],
            'derivatives': ['funding_rate', 'open_interest', 'basis'],
            'macro': ['dxy', 'gold', 'nasdaq', 'vix'],
            'sentiment': ['fear_greed', 'social']
        }
        
        # ì˜ˆì¸¡ ì‹œê°„ ì˜µì…˜ (ì‹œê°„ ë‹¨ìœ„)
        self.prediction_horizons = [1, 6, 12, 24, 48, 72, 168]  # 1ì‹œê°„~1ì£¼
        
        print("ğŸ¯ ë¬´í•œ ë°±í…ŒìŠ¤íŠ¸ 95% ê³µì‹ ë°œê²¬ê¸° ì´ˆê¸°í™”")
        
    def load_data(self) -> bool:
        """3ê°œì›” í†µí•© ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“‚ ë°ì´í„° ë¡œë”©...")
        
        try:
            csv_path = os.path.join(self.data_path, "ai_optimized_3month_data", "ai_matrix_complete.csv")
            df = pd.read_csv(csv_path)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.sort_values('timestamp').reset_index(drop=True)
            
            # ìˆ«ìí˜• ë°ì´í„°ë§Œ ì¶”ì¶œ
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            self.historical_data = df[['timestamp'] + list(numeric_cols) if 'timestamp' in df.columns else list(numeric_cols)].copy()
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            self.historical_data = self.historical_data.fillna(method='ffill').fillna(method='bfill').fillna(0)
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.historical_data.shape}")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def categorize_indicators(self) -> Dict[str, List[str]]:
        """ì§€í‘œë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        available_cols = self.historical_data.columns.tolist()
        if 'timestamp' in available_cols:
            available_cols.remove('timestamp')
            
        categorized = {}
        
        for category, keywords in self.indicator_categories.items():
            categorized[category] = []
            for col in available_cols:
                for keyword in keywords:
                    if keyword.lower() in col.lower():
                        categorized[category].append(col)
                        break
        
        # ë¯¸ë¶„ë¥˜ ì§€í‘œë“¤
        classified_cols = set()
        for cols in categorized.values():
            classified_cols.update(cols)
        
        categorized['others'] = [col for col in available_cols if col not in classified_cols]
        
        return categorized
    
    def generate_feature_combinations(self, max_features: int = 20) -> List[List[str]]:
        """ë‹¤ì–‘í•œ ì§€í‘œ ì¡°í•© ìƒì„±"""
        categorized = self.categorize_indicators()
        combinations = []
        
        # 1. ì¹´í…Œê³ ë¦¬ë³„ ëŒ€í‘œ ì§€í‘œ ì¡°í•©
        for r in range(2, min(len(categorized), 6)):  # 2~5ê°œ ì¹´í…Œê³ ë¦¬ ì¡°í•©
            for category_combo in itertools.combinations(categorized.keys(), r):
                features = []
                for category in category_combo:
                    if categorized[category]:
                        # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒìœ„ Nê°œì”©
                        features.extend(categorized[category][:min(5, len(categorized[category]))])
                
                if len(features) <= max_features:
                    combinations.append(features)
        
        # 2. ëœë¤ ì¡°í•© (ë‹¤ì–‘ì„± í™•ë³´)
        all_features = [col for cols in categorized.values() for col in cols]
        for _ in range(50):  # 50ê°œ ëœë¤ ì¡°í•©
            num_features = random.randint(5, min(max_features, len(all_features)))
            random_combo = random.sample(all_features, num_features)
            combinations.append(random_combo)
        
        return combinations
    
    def create_advanced_features(self, base_features: List[str], target_col: str) -> pd.DataFrame:
        """ê³ ê¸‰ íŒŒìƒ í”¼ì²˜ ìƒì„±"""
        df = self.historical_data.copy()
        
        # ê¸°ë³¸ í”¼ì²˜ë“¤ë§Œ ì„ íƒ
        available_features = [f for f in base_features if f in df.columns]
        if not available_features:
            return pd.DataFrame()
            
        feature_df = df[available_features + [target_col]].copy()
        
        # ê°€ê²© ê¸°ë°˜ ê³ ê¸‰ í”¼ì²˜ (target_colì´ ê°€ê²©ì¸ ê²½ìš°)
        price_data = df[target_col]
        
        # 1. ë‹¤ì¤‘ ê¸°ê°„ ì´ë™í‰ê· 
        for period in [12, 24, 168]:
            feature_df[f'{target_col}_sma_{period}'] = price_data.rolling(period).mean()
            feature_df[f'{target_col}_ema_{period}'] = price_data.ewm(period).mean()
        
        # 2. ë³€ë™ì„± ì§€í‘œ
        for period in [12, 24, 168]:
            feature_df[f'{target_col}_volatility_{period}'] = price_data.pct_change().rolling(period).std()
            feature_df[f'{target_col}_range_{period}'] = (price_data.rolling(period).max() - price_data.rolling(period).min()) / price_data.rolling(period).mean()
        
        # 3. ëª¨ë©˜í…€ ì§€í‘œ
        for period in [1, 6, 24, 168]:
            feature_df[f'{target_col}_momentum_{period}'] = price_data.pct_change(period)
            feature_df[f'{target_col}_roc_{period}'] = (price_data - price_data.shift(period)) / price_data.shift(period)
        
        # 4. ê¸°ìˆ ì  ì§€í‘œ
        # RSI
        delta = price_data.diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss
        feature_df[f'{target_col}_rsi'] = 100 - (100 / (1 + rs))
        
        # ë³¼ë¦°ì € ë°´ë“œ
        sma_20 = price_data.rolling(20).mean()
        std_20 = price_data.rolling(20).std()
        feature_df[f'{target_col}_bb_upper'] = sma_20 + (std_20 * 2)
        feature_df[f'{target_col}_bb_lower'] = sma_20 - (std_20 * 2)
        feature_df[f'{target_col}_bb_position'] = (price_data - feature_df[f'{target_col}_bb_lower']) / (feature_df[f'{target_col}_bb_upper'] - feature_df[f'{target_col}_bb_lower'])
        
        # 5. ì§€í‘œê°„ ìƒí˜¸ì‘ìš© (ìƒìœ„ 10ê°œ í”¼ì²˜ë§Œ)
        numeric_features = [f for f in available_features[:10] if f in feature_df.columns]
        for i, feat1 in enumerate(numeric_features):
            for feat2 in numeric_features[i+1:]:
                try:
                    # ë¹„ìœ¨
                    feature_df[f'{feat1}_ratio_{feat2}'] = feature_df[feat1] / (feature_df[feat2] + 1e-8)
                    # ì°¨ì´
                    feature_df[f'{feat1}_diff_{feat2}'] = feature_df[feat1] - feature_df[feat2]
                except:
                    continue
        
        # 6. ì‹œì°¨ í”¼ì²˜ (Lag features)
        for col in available_features[:10]:  # ìƒìœ„ 10ê°œë§Œ
            for lag in [1, 6, 24]:
                feature_df[f'{col}_lag_{lag}'] = feature_df[col].shift(lag)
        
        # NaN ì²˜ë¦¬
        feature_df = feature_df.fillna(method='bfill').fillna(0)
        feature_df = feature_df.replace([np.inf, -np.inf], 0)
        
        return feature_df
    
    def test_formula_at_timepoint(self, start_idx: int, features: List[str], 
                                 prediction_hours: int, model_type: str = 'ensemble') -> Dict:
        """íŠ¹ì • ì‹œì ì—ì„œ ê³µì‹ í…ŒìŠ¤íŠ¸"""
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸° (BTC ê°€ê²©)
        price_candidates = [
            'onchain_blockchain_info_network_stats_market_price_usd',
            'price', 'close', 'open'
        ]
        target_col = None
        for candidate in price_candidates:
            if candidate in self.historical_data.columns:
                target_col = candidate
                break
        
        if not target_col:
            numeric_cols = self.historical_data.select_dtypes(include=[np.number]).columns
            target_col = numeric_cols[0]
        
        try:
            # 1. ê³¼ê±° ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµ
            train_data = self.historical_data.iloc[:start_idx].copy()
            
            if len(train_data) < 200:  # ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„° í•„ìš”
                return {'success': False, 'error': 'í•™ìŠµ ë°ì´í„° ë¶€ì¡±'}
            
            # 2. ê³ ê¸‰ í”¼ì²˜ ìƒì„±
            enhanced_data = self.create_advanced_features(features, target_col)
            if enhanced_data.empty:
                return {'success': False, 'error': 'í”¼ì²˜ ìƒì„± ì‹¤íŒ¨'}
            
            train_enhanced = enhanced_data.iloc[:start_idx]
            
            # 3. X, y ì¤€ë¹„
            X_train = train_enhanced.drop(columns=[target_col])
            y_train = train_enhanced[target_col].shift(-prediction_hours).dropna()
            X_train = X_train.iloc[:-prediction_hours]
            
            if len(X_train) < 100:
                return {'success': False, 'error': 'íƒ€ê²Ÿ ë°ì´í„° ë¶€ì¡±'}
            
            # 4. ìŠ¤ì¼€ì¼ë§
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            
            # 5. ëª¨ë¸ í•™ìŠµ
            if model_type == 'ensemble':
                models = {
                    'rf': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42),
                    'gb': GradientBoostingRegressor(n_estimators=100, max_depth=8, random_state=42),
                    'ridge': Ridge(alpha=1.0)
                }
                
                predictions = {}
                for name, model in models.items():
                    model.fit(X_train_scaled, y_train)
                    
                    # í˜„ì¬ ì‹œì  ë°ì´í„°ë¡œ ì˜ˆì¸¡
                    current_features = enhanced_data.iloc[start_idx:start_idx+1].drop(columns=[target_col])
                    current_scaled = scaler.transform(current_features)
                    pred = model.predict(current_scaled)[0]
                    predictions[name] = pred
                
                # ê°€ì¤‘ ì•™ìƒë¸” (ê³¼ê±° ì„±ëŠ¥ ê¸°ë°˜)
                final_prediction = (predictions['rf'] * 0.4 + 
                                  predictions['gb'] * 0.4 + 
                                  predictions['ridge'] * 0.2)
                
            else:  # ë‹¨ì¼ ëª¨ë¸
                if model_type == 'rf':
                    model = RandomForestRegressor(n_estimators=100, random_state=42)
                elif model_type == 'gb':
                    model = GradientBoostingRegressor(n_estimators=100, random_state=42)
                else:
                    model = Ridge(alpha=1.0)
                
                model.fit(X_train_scaled, y_train)
                current_features = enhanced_data.iloc[start_idx:start_idx+1].drop(columns=[target_col])
                current_scaled = scaler.transform(current_features)
                final_prediction = model.predict(current_scaled)[0]
            
            # 6. ì‹¤ì œê°’ê³¼ ë¹„êµ
            target_idx = start_idx + prediction_hours
            if target_idx >= len(self.historical_data):
                return {'success': False, 'error': 'ì˜ˆì¸¡ ì‹œì  ì´ˆê³¼'}
            
            actual_value = self.historical_data.iloc[target_idx][target_col]
            current_value = self.historical_data.iloc[start_idx][target_col]
            
            # 7. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            absolute_error = abs(actual_value - final_prediction)
            percentage_error = (absolute_error / actual_value) * 100
            accuracy = max(0, 100 - percentage_error)
            
            return {
                'success': True,
                'start_idx': start_idx,
                'target_idx': target_idx,
                'current_value': current_value,
                'predicted_value': final_prediction,
                'actual_value': actual_value,
                'absolute_error': absolute_error,
                'percentage_error': percentage_error,
                'accuracy': accuracy,
                'features_used': features,
                'prediction_hours': prediction_hours,
                'model_type': model_type
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def infinite_formula_discovery(self, max_iterations: int = 1000) -> Dict:
        """ë¬´í•œ ê³µì‹ ë°œê²¬ í”„ë¡œì„¸ìŠ¤"""
        print(f"\nğŸš€ ë¬´í•œ ë°±í…ŒìŠ¤íŠ¸ ê³µì‹ ë°œê²¬ ì‹œì‘")
        print(f"   ğŸ¯ ëª©í‘œ ì •í™•ë„: {self.target_accuracy}%")
        print(f"   ğŸ”„ ìµœëŒ€ ë°˜ë³µ: {max_iterations}íšŒ")
        print("="*70)
        
        # ì§€í‘œ ì¡°í•© ìƒì„±
        feature_combinations = self.generate_feature_combinations()
        print(f"ğŸ“Š ìƒì„±ëœ ì§€í‘œ ì¡°í•©: {len(feature_combinations)}ê°œ")
        
        best_results = []
        iteration = 0
        
        data_length = len(self.historical_data)
        min_start_idx = 300  # ìµœì†Œ í•™ìŠµ ë°ì´í„°
        max_start_idx = data_length - 200  # ì˜ˆì¸¡ì„ ìœ„í•œ ì—¬ìœ 
        
        while iteration < max_iterations and self.current_best_accuracy < self.target_accuracy:
            iteration += 1
            
            # ëœë¤ ì„¤ì •
            start_idx = random.randint(min_start_idx, max_start_idx)
            features = random.choice(feature_combinations)
            prediction_hours = random.choice(self.prediction_horizons)
            model_type = random.choice(['ensemble', 'rf', 'gb', 'ridge'])
            
            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            result = self.test_formula_at_timepoint(start_idx, features, prediction_hours, model_type)
            
            if result['success']:
                accuracy = result['accuracy']
                
                # ì§„í–‰ìƒí™© ì¶œë ¥
                if iteration % 50 == 0 or accuracy > 90:
                    print(f"ğŸ” ë°˜ë³µ {iteration:4d}: ì •í™•ë„ {accuracy:5.2f}% "
                          f"(í”¼ì²˜ {len(features):2d}ê°œ, {prediction_hours:3d}ì‹œê°„ í›„ ì˜ˆì¸¡)")
                
                # ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
                if accuracy > self.current_best_accuracy:
                    self.current_best_accuracy = accuracy
                    
                    formula_info = {
                        'iteration': iteration,
                        'accuracy': accuracy,
                        'features': features,
                        'prediction_hours': prediction_hours,
                        'model_type': model_type,
                        'result_details': result
                    }
                    
                    best_results.append(formula_info)
                    
                    print(f"ğŸ† ì‹ ê¸°ë¡! ì •í™•ë„ {accuracy:.2f}% "
                          f"(í”¼ì²˜: {len(features)}ê°œ, ì˜ˆì¸¡: {prediction_hours}h, ëª¨ë¸: {model_type})")
                    
                    # ëª©í‘œ ë‹¬ì„± ì²´í¬
                    if accuracy >= self.target_accuracy:
                        print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! {self.target_accuracy}% ë‹¬ì„±!")
                        break
            
            else:
                if iteration % 100 == 0:
                    print(f"âš ï¸ ë°˜ë³µ {iteration}: ì‹¤íŒ¨ ({result.get('error', 'Unknown')})")
        
        # ìµœì¢… ê²°ê³¼
        print(f"\n" + "="*70)
        print("ğŸ† ë¬´í•œ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*70)
        print(f"ğŸ”„ ì´ ë°˜ë³µ íšŸìˆ˜:     {iteration}")
        print(f"ğŸ¯ ìµœê³  ì •í™•ë„:      {self.current_best_accuracy:.2f}%")
        print(f"ğŸ“Š ë°œê²¬ëœ ê³µì‹ ìˆ˜:   {len(best_results)}")
        
        if best_results:
            # ìµœê³  ê³µì‹ ë¶„ì„
            best_formula = best_results[-1]  # ë§ˆì§€ë§‰(ìµœê³ ) ê²°ê³¼
            
            print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ê³µì‹:")
            print(f"   ğŸ“ˆ ì •í™•ë„:        {best_formula['accuracy']:.2f}%")
            print(f"   ğŸ“Š ì‚¬ìš© ì§€í‘œ:     {len(best_formula['features'])}ê°œ")
            print(f"   â° ì˜ˆì¸¡ ê¸°ê°„:     {best_formula['prediction_hours']}ì‹œê°„")
            print(f"   ğŸ¤– ëª¨ë¸ íƒ€ì…:     {best_formula['model_type']}")
            
            # ìƒìœ„ ì§€í‘œë“¤ ì¶œë ¥
            print(f"\nğŸ” í•µì‹¬ ì§€í‘œ (ìƒìœ„ 10ê°œ):")
            for i, feature in enumerate(best_formula['features'][:10]):
                print(f"   {i+1:2d}. {feature}")
            
            self.best_formulas = best_results
        
        else:
            print("âŒ ìœ íš¨í•œ ê³µì‹ì„ ë°œê²¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        print("="*70)
        
        # ê²°ê³¼ ì €ì¥
        self.save_discovery_results(best_results, iteration)
        
        return {
            'total_iterations': iteration,
            'best_accuracy': self.current_best_accuracy,
            'formulas_discovered': len(best_results),
            'target_achieved': self.current_best_accuracy >= self.target_accuracy,
            'best_formula': best_results[-1] if best_results else None
        }
    
    def save_discovery_results(self, best_results: List[Dict], iterations: int):
        """ë°œê²¬ëœ ê³µì‹ë“¤ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        results = {
            'timestamp': timestamp,
            'total_iterations': iterations,
            'target_accuracy': self.target_accuracy,
            'best_accuracy_achieved': self.current_best_accuracy,
            'target_achieved': self.current_best_accuracy >= self.target_accuracy,
            'formulas_discovered': len(best_results),
            'best_formulas': best_results,
            'data_shape': self.historical_data.shape,
            'discovery_summary': {
                'avg_features_used': np.mean([len(f['features']) for f in best_results]) if best_results else 0,
                'most_common_prediction_hours': max([f['prediction_hours'] for f in best_results], key=[f['prediction_hours'] for f in best_results].count) if best_results else 0,
                'best_model_type': best_results[-1]['model_type'] if best_results else None
            }
        }
        
        filename = f"infinite_backtest_formula_discovery_{timestamp}.json"
        filepath = os.path.join(self.data_path, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ ë°œê²¬ ê²°ê³¼ ì €ì¥: {filename}")
        
        return filepath
    
    def run_discovery_process(self):
        """ì „ì²´ ë°œê²¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸ¯ ë¬´í•œ ë°±í…ŒìŠ¤íŠ¸ 95% ê³µì‹ ë°œê²¬ê¸° ì‹œì‘")
        print("="*70)
        
        # 1. ë°ì´í„° ë¡œë“œ
        if not self.load_data():
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return None
        
        # 2. ë¬´í•œ ê³µì‹ ë°œê²¬
        results = self.infinite_formula_discovery(max_iterations=500)  # 500íšŒ í…ŒìŠ¤íŠ¸
        
        return results

def main():
    discoverer = InfiniteBacktestFormulaDiscoverer()
    return discoverer.run_discovery_process()

if __name__ == "__main__":
    results = main()