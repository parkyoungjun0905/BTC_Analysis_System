#!/usr/bin/env python3
"""
üéØ ÌÜµÌï© 1000+ ÌäπÏÑ± ÎπÑÌä∏ÏΩîÏù∏ ÏòàÏ∏° ÏãúÏä§ÌÖú
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üíé ÏµúÍ≥† ÏàòÏ§Ä ÌäπÏÑ± ÏóîÏßÄÎãàÏñ¥ÎßÅ + Ïã§ÏãúÍ∞Ñ ÏµúÏ†ÅÌôî + ÏòàÏ∏° ÏãúÏä§ÌÖú
‚Ä¢ Ìè¨Í¥ÑÏ†Å ÌäπÏÑ± ÏóîÏßÄÎãàÏñ¥ÎßÅ ÌååÏù¥ÌîÑÎùºÏù∏
‚Ä¢ Í≥†ÎèÑÌôîÎêú ÌäπÏÑ± ÏµúÏ†ÅÌôî
‚Ä¢ Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ ÌÜµÌï©
‚Ä¢ ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
‚Ä¢ Î∞±ÌÖåÏä§ÌåÖ Í≤ÄÏ¶ù

üöÄ Ïã§Ìñâ Î∞©Î≤ï:
python integrated_1000_feature_system.py
"""

import asyncio
import pandas as pd
import numpy as np
import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import warnings
import sys
import os

# Î°úÏª¨ Î™®Îìà import
try:
    from comprehensive_feature_engineering_pipeline import ComprehensiveFeatureEngineer, FeatureConfig
    from advanced_feature_optimizer import AdvancedFeatureOptimizer, RealTimeFeatureMonitor
    FEATURE_MODULES_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è ÌäπÏÑ± Î™®Îìà import Ïã§Ìå®: {e}")
    FEATURE_MODULES_AVAILABLE = False

# ML ÎùºÏù¥Î∏åÎü¨Î¶¨
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.model_selection import TimeSeriesSplit, cross_val_score
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    from sklearn.preprocessing import StandardScaler
    import joblib
    SKLEARN_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è scikit-learn ÎØ∏ÏÑ§Ïπò")
    SKLEARN_AVAILABLE = False

warnings.filterwarnings('ignore')

class Integrated1000FeatureSystem:
    """ÌÜµÌï© 1000+ ÌäπÏÑ± ÎπÑÌä∏ÏΩîÏù∏ ÏòàÏ∏° ÏãúÏä§ÌÖú"""
    
    def __init__(self):
        self.feature_engineer = None
        self.feature_optimizer = None
        self.monitor = None
        
        # ÏÑ§Ï†ï
        self.config = FeatureConfig(
            max_features=1200,
            enable_advanced_math=True,
            enable_cross_features=True,
            feature_selection_method="mutual_info"
        )
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§
        self.db_path = "integrated_1000_feature_system.db"
        
        # ÏÑ±Îä• Í∏∞Î°ù
        self.performance_history = []
        
        # Ï¥àÍ∏∞Ìôî
        if FEATURE_MODULES_AVAILABLE:
            self.feature_engineer = ComprehensiveFeatureEngineer(self.config)
            self.feature_optimizer = AdvancedFeatureOptimizer(n_features_target=1000)
            self.monitor = RealTimeFeatureMonitor(self.feature_optimizer)
        
        self._init_database()
        print("‚úÖ ÌÜµÌï© 1000+ ÌäπÏÑ± ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
    
    def _init_database(self):
        """ÏãúÏä§ÌÖú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ÏòàÏ∏° Í≤∞Í≥º ÌÖåÏù¥Î∏î
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS predictions (
            timestamp TIMESTAMP PRIMARY KEY,
            current_price REAL,
            predicted_price_1h REAL,
            predicted_price_4h REAL,
            predicted_price_24h REAL,
            confidence_score REAL,
            n_features_used INTEGER,
            model_name TEXT,
            actual_price_1h REAL,
            actual_price_4h REAL,
            actual_price_24h REAL,
            accuracy_1h REAL,
            accuracy_4h REAL,
            accuracy_24h REAL
        )
        ''')
        
        # ÏãúÏä§ÌÖú ÏÑ±Îä• ÌÖåÏù¥Î∏î
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS system_performance (
            timestamp TIMESTAMP,
            feature_generation_time REAL,
            optimization_time REAL,
            prediction_time REAL,
            total_features REAL,
            selected_features INTEGER,
            r2_score REAL,
            mae REAL,
            mse REAL
        )
        ''')
        
        conn.commit()
        conn.close()
    
    async def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """Ìè¨Í¥ÑÏ†Å Î∂ÑÏÑù Ïã§Ìñâ"""
        
        print("\nüöÄ ÌÜµÌï© 1000+ ÌäπÏÑ± Î∂ÑÏÑù ÏãúÏûë")
        start_time = datetime.now()
        
        # 1. ÏãúÏû• Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
        market_data = await self._collect_comprehensive_market_data()
        print(f"‚úÖ ÏãúÏû• Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏôÑÎ£å: {len(market_data)} Ìï≠Î™©")
        
        # 2. ÌäπÏÑ± ÏÉùÏÑ±
        if not FEATURE_MODULES_AVAILABLE:
            print("‚ùå ÌäπÏÑ± Î™®Îìà ÏÇ¨Ïö© Î∂àÍ∞Ä")
            return {"status": "error", "message": "Feature modules not available"}
        
        feature_start = datetime.now()
        features_df = await self.feature_engineer.generate_all_features(market_data)
        feature_time = (datetime.now() - feature_start).total_seconds()
        
        print(f"‚úÖ ÌäπÏÑ± ÏÉùÏÑ± ÏôÑÎ£å: {len(features_df.columns)}Í∞ú, {feature_time:.2f}Ï¥à")
        
        # 3. ÌäπÏÑ± ÏµúÏ†ÅÌôî
        opt_start = datetime.now()
        target = await self._generate_prediction_target(market_data)
        optimized_features = await self.feature_optimizer.optimize_features(
            features_df, target, method='comprehensive'
        )
        opt_time = (datetime.now() - opt_start).total_seconds()
        
        print(f"‚úÖ ÌäπÏÑ± ÏµúÏ†ÅÌôî ÏôÑÎ£å: {len(optimized_features.columns)}Í∞ú, {opt_time:.2f}Ï¥à")
        
        # 4. ÏòàÏ∏° Î™®Îç∏ ÌïôÏäµ Î∞è ÏòàÏ∏°
        pred_start = datetime.now()
        predictions = await self._train_and_predict(optimized_features, target, market_data)
        pred_time = (datetime.now() - pred_start).total_seconds()
        
        print(f"‚úÖ ÏòàÏ∏° ÏôÑÎ£å: {pred_time:.2f}Ï¥à")
        
        # 5. ÏÑ±Îä• ÌèâÍ∞Ä
        performance = await self._evaluate_system_performance(
            optimized_features, target, predictions
        )
        
        # 6. Í≤∞Í≥º Ï†ÄÏû•
        await self._save_analysis_results(
            market_data, predictions, performance, 
            feature_time, opt_time, pred_time
        )
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        # Í≤∞Í≥º ÏöîÏïΩ
        result = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "execution_time": total_time,
            "market_data": {
                "btc_price": market_data.get('btc_price', 0),
                "volume": market_data.get('volume', 0),
                "data_points": len(market_data)
            },
            "features": {
                "total_generated": len(features_df.columns),
                "optimized_count": len(optimized_features.columns),
                "generation_time": feature_time,
                "optimization_time": opt_time
            },
            "predictions": predictions,
            "performance": performance,
            "feature_ranking": self.feature_optimizer.get_feature_ranking().head(20).to_dict('records')
        }
        
        print(f"\nüéØ Î∂ÑÏÑù ÏôÑÎ£å: {total_time:.2f}Ï¥à")
        print(f"üìä ÏµúÏ¢Ö ÌäπÏÑ± Ïàò: {len(optimized_features.columns)}")
        print(f"üìà ÏòàÏ∏° Ï†ïÌôïÎèÑ: {performance.get('r2_score', 0):.4f}")
        
        return result
    
    async def _collect_comprehensive_market_data(self) -> Dict[str, Any]:
        """Ìè¨Í¥ÑÏ†Å ÏãúÏû• Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        
        # Í∏∞Ï°¥ ÏãúÏä§ÌÖúÏóêÏÑú Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ ÏãúÎèÑ
        market_data = {}
        
        # 1. Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ ÌååÏùºÎì§ ÌôïÏù∏
        data_sources = [
            "historical_data",
            "ai_optimized_3month_data",
            "complete_historical_6month_data"
        ]
        
        for source_dir in data_sources:
            if os.path.exists(source_dir):
                try:
                    # CSV ÌååÏùºÎì§ ÏùΩÍ∏∞
                    csv_files = list(Path(source_dir).glob("*.csv"))
                    if csv_files:
                        latest_file = max(csv_files, key=os.path.getctime)
                        df = pd.read_csv(latest_file)
                        
                        if len(df) > 0:
                            latest_row = df.iloc[-1]
                            for col in df.columns:
                                if col not in market_data and pd.notna(latest_row[col]):
                                    market_data[col] = float(latest_row[col])
                                    
                except Exception as e:
                    print(f"‚ö†Ô∏è {source_dir} ÏùΩÍ∏∞ Ïã§Ìå®: {e}")
        
        # 2. Í∏∞Î≥∏Í∞íÏúºÎ°ú Î≥¥ÏôÑ
        defaults = {
            'btc_price': np.random.uniform(60000, 70000),
            'volume': np.random.uniform(800, 1500) * 1000000,
            'high': np.random.uniform(60000, 72000),
            'low': np.random.uniform(58000, 68000),
            'open': np.random.uniform(59000, 69000),
            'bid': np.random.uniform(60000, 70000),
            'ask': np.random.uniform(60000, 70000),
            'trade_count': np.random.randint(80000, 150000),
            'hash_rate': np.random.uniform(400, 500) * 1e18,
            'active_addresses': np.random.randint(700000, 900000),
            'funding_rate': np.random.uniform(-0.01, 0.01),
            'fear_greed_index': np.random.randint(20, 80),
            'mvrv': np.random.uniform(1.0, 3.0),
            'nvt_ratio': np.random.uniform(50, 150),
            'sopr': np.random.uniform(0.95, 1.05),
            'exchange_netflow': np.random.uniform(-5000, 5000),
            'whale_ratio': np.random.uniform(0.1, 0.3),
            'open_interest': np.random.uniform(10000000000, 20000000000),
            'basis': np.random.uniform(-100, 100),
            'realized_volatility': np.random.uniform(0.3, 0.8),
            'dxy': np.random.uniform(100, 108),
            'spx': np.random.uniform(4500, 5200),
            'vix': np.random.uniform(15, 30),
            'gold': np.random.uniform(1900, 2100),
            'us10y': np.random.uniform(3.5, 5.0)
        }
        
        for key, value in defaults.items():
            if key not in market_data:
                market_data[key] = value
        
        # 3. ÏãúÍ∞Ñ Í∏∞Î∞ò ÌäπÏÑ± Ï∂îÍ∞Ä
        now = datetime.now()
        market_data.update({
            'timestamp': now.isoformat(),
            'hour_of_day': now.hour,
            'day_of_week': now.weekday(),
            'day_of_month': now.day,
            'month': now.month,
            'quarter': (now.month - 1) // 3 + 1,
            'is_weekend': 1.0 if now.weekday() >= 5 else 0.0,
            'is_month_end': 1.0 if now.day >= 28 else 0.0,
        })
        
        # 4. Í≥ÑÏÇ∞Îêú ÌäπÏÑ± Ï∂îÍ∞Ä
        if market_data['btc_price'] > 0:
            market_data.update({
                'price_change_1h': np.random.uniform(-0.02, 0.02),
                'price_change_4h': np.random.uniform(-0.05, 0.05),
                'price_change_24h': np.random.uniform(-0.1, 0.1),
                'volatility_1h': abs(np.random.normal(0, 0.01)),
                'volatility_24h': abs(np.random.normal(0, 0.03)),
                'momentum_1h': np.random.uniform(-0.01, 0.01),
                'momentum_4h': np.random.uniform(-0.03, 0.03),
                'trend_strength': np.random.uniform(-1, 1),
                'market_sentiment': np.random.uniform(-0.5, 0.5),
            })
        
        return market_data
    
    async def _generate_prediction_target(self, market_data: Dict[str, Any]) -> np.ndarray:
        """ÏòàÏ∏° Î™©Ìëú Î≥ÄÏàò ÏÉùÏÑ±"""
        
        # Ïã§Ï†úÎ°úÎäî ÎØ∏Îûò Í∞ÄÍ≤© Î≥ÄÌôîÏú®ÏùÑ ÏòàÏ∏°
        # Ïó¨Í∏∞ÏÑúÎäî ÌòÑÏû¨ Í∞ÄÍ≤©Í≥º Ìå®ÌÑ¥ Í∏∞Î∞òÏúºÎ°ú Ìï©ÏÑ± Î™©Ìëú ÏÉùÏÑ±
        
        base_price = market_data.get('btc_price', 60000)
        
        # Îã§ÏñëÌïú ÏöîÏÜåÎ•º Í≥†Î†§Ìïú Î™©Ìëú Î≥ÄÏàò
        factors = [
            market_data.get('trend_strength', 0) * 0.02,
            market_data.get('market_sentiment', 0) * 0.01,
            market_data.get('momentum_4h', 0) * 0.5,
            np.random.normal(0, 0.005)  # ÎÖ∏Ïù¥Ï¶à
        ]
        
        # 1ÏãúÍ∞Ñ ÌõÑ Í∞ÄÍ≤© Î≥ÄÌôîÏú® Î™©Ìëú
        target_return = sum(factors)
        target_price = base_price * (1 + target_return)
        
        return np.array([target_return])  # Î≥ÄÌôîÏú® Î∞òÌôò
    
    async def _train_and_predict(self, features_df: pd.DataFrame, 
                               target: np.ndarray, 
                               market_data: Dict[str, Any]) -> Dict[str, Any]:
        """Î™®Îç∏ ÌïôÏäµ Î∞è ÏòàÏ∏°"""
        
        if not SKLEARN_AVAILABLE:
            return {
                "current_price": market_data.get('btc_price', 0),
                "predicted_price_1h": market_data.get('btc_price', 0) * 1.001,
                "predicted_price_4h": market_data.get('btc_price', 0) * 1.005,
                "predicted_price_24h": market_data.get('btc_price', 0) * 1.02,
                "confidence_score": 0.5
            }
        
        try:
            current_price = market_data.get('btc_price', 60000)
            features_array = features_df.fillna(0).values
            
            # ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ ÏãúÎÆ¨Î†àÏù¥ÏÖò (Ïã§Ï†úÎ°úÎäî historical data ÏÇ¨Ïö©)
            n_historical = 100
            historical_features = np.tile(features_array, (n_historical, 1))
            historical_features += np.random.normal(0, 0.1, historical_features.shape)
            
            historical_target = target[0] + np.random.normal(0, 0.01, n_historical)
            
            # Î™®Îç∏ ÏïôÏÉÅÎ∏î
            models = {
                'rf': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
                'gbm': GradientBoostingRegressor(n_estimators=100, random_state=42)
            }
            
            predictions = {}
            confidences = {}
            
            for name, model in models.items():
                # ÌïôÏäµ
                model.fit(historical_features, historical_target)
                
                # ÏòàÏ∏°
                pred = model.predict(features_array.reshape(1, -1))[0]
                predictions[name] = pred
                
                # Ïã†Î¢∞ÎèÑ (ÌäπÏÑ± Ï§ëÏöîÎèÑ Í∏∞Î∞ò)
                if hasattr(model, 'feature_importances_'):
                    importance_sum = np.sum(model.feature_importances_)
                    confidences[name] = min(1.0, importance_sum)
                else:
                    confidences[name] = 0.7
            
            # ÏïôÏÉÅÎ∏î ÏòàÏ∏°
            ensemble_pred = np.mean(list(predictions.values()))
            ensemble_confidence = np.mean(list(confidences.values()))
            
            # Îã§ÏñëÌïú ÏãúÍ∞ÑÎåÄ ÏòàÏ∏°
            pred_1h = current_price * (1 + ensemble_pred)
            pred_4h = current_price * (1 + ensemble_pred * 2.5)  # ÏãúÍ∞ÑÎåÄÎ≥Ñ Ï°∞Ï†ï
            pred_24h = current_price * (1 + ensemble_pred * 8.0)
            
            return {
                "current_price": current_price,
                "predicted_price_1h": pred_1h,
                "predicted_price_4h": pred_4h,
                "predicted_price_24h": pred_24h,
                "predicted_return": ensemble_pred,
                "confidence_score": ensemble_confidence,
                "model_predictions": predictions,
                "model_confidences": confidences
            }
            
        except Exception as e:
            print(f"‚ùå ÏòàÏ∏° Ïò§Î•ò: {e}")
            return {
                "current_price": current_price,
                "predicted_price_1h": current_price * 1.001,
                "predicted_price_4h": current_price * 1.005,
                "predicted_price_24h": current_price * 1.02,
                "confidence_score": 0.3,
                "error": str(e)
            }
    
    async def _evaluate_system_performance(self, features_df: pd.DataFrame,
                                         target: np.ndarray,
                                         predictions: Dict[str, Any]) -> Dict[str, Any]:
        """ÏãúÏä§ÌÖú ÏÑ±Îä• ÌèâÍ∞Ä"""
        
        performance = {
            "timestamp": datetime.now().isoformat(),
            "n_features": len(features_df.columns),
            "data_quality_score": 0.0,
            "feature_stability_score": 0.0,
            "prediction_confidence": predictions.get('confidence_score', 0.5),
            "r2_score": 0.0,
            "mae": 0.0,
            "mse": 0.0
        }
        
        try:
            # Îç∞Ïù¥ÌÑ∞ ÌíàÏßà ÌèâÍ∞Ä
            nan_ratio = features_df.isnull().sum().sum() / (len(features_df.columns) * len(features_df))
            performance["data_quality_score"] = 1 - nan_ratio
            
            # ÌäπÏÑ± ÏïàÏ†ïÏÑ± (Î∂ÑÏÇ∞ Í∏∞Î∞ò)
            if len(features_df.columns) > 0:
                variances = features_df.var()
                stable_features = (variances > 1e-8).sum()
                performance["feature_stability_score"] = stable_features / len(features_df.columns)
            
            # Î™®Îç∏ ÏÑ±Îä• (Ìï©ÏÑ± Îç∞Ïù¥ÌÑ∞Î°ú Í∑ºÏÇ¨)
            if SKLEARN_AVAILABLE and len(features_df) > 0:
                try:
                    # Í∞ÑÎã®Ìïú ÍµêÏ∞® Í≤ÄÏ¶ù
                    model = RandomForestRegressor(n_estimators=50, random_state=42)
                    
                    # Í∞ÄÏÉÅÏùò ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î°ú ÏÑ±Îä• ÌèâÍ∞Ä
                    n_samples = 50
                    synthetic_features = np.tile(features_df.fillna(0).values, (n_samples, 1))
                    synthetic_features += np.random.normal(0, 0.1, synthetic_features.shape)
                    
                    synthetic_target = np.random.normal(target[0], 0.01, n_samples)
                    
                    scores = cross_val_score(model, synthetic_features, synthetic_target, cv=3, scoring='r2')
                    performance["r2_score"] = max(0, scores.mean())
                    
                    # MAE, MSE Í∑ºÏÇ¨
                    model.fit(synthetic_features, synthetic_target)
                    y_pred = model.predict(synthetic_features)
                    
                    performance["mae"] = mean_absolute_error(synthetic_target, y_pred)
                    performance["mse"] = mean_squared_error(synthetic_target, y_pred)
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è ÏÑ±Îä• ÌèâÍ∞Ä Ïò§Î•ò: {e}")
                    performance["r2_score"] = 0.5
            
        except Exception as e:
            print(f"‚ùå ÏÑ±Îä• ÌèâÍ∞Ä Ïã§Ìå®: {e}")
        
        return performance
    
    async def _save_analysis_results(self, market_data: Dict[str, Any],
                                   predictions: Dict[str, Any],
                                   performance: Dict[str, Any],
                                   feature_time: float,
                                   opt_time: float,
                                   pred_time: float):
        """Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû•"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû•
            cursor.execute('''
            INSERT OR REPLACE INTO predictions 
            (timestamp, current_price, predicted_price_1h, predicted_price_4h, predicted_price_24h,
             confidence_score, n_features_used, model_name)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                datetime.now(),
                market_data.get('btc_price', 0),
                predictions.get('predicted_price_1h', 0),
                predictions.get('predicted_price_4h', 0),
                predictions.get('predicted_price_24h', 0),
                predictions.get('confidence_score', 0),
                performance.get('n_features', 0),
                'ensemble_rf_gbm'
            ))
            
            # ÏÑ±Îä• Í∏∞Î°ù Ï†ÄÏû•
            cursor.execute('''
            INSERT INTO system_performance
            (timestamp, feature_generation_time, optimization_time, prediction_time,
             total_features, selected_features, r2_score, mae, mse)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                datetime.now(),
                feature_time,
                opt_time,
                pred_time,
                performance.get('n_features', 0),
                performance.get('n_features', 0),
                performance.get('r2_score', 0),
                performance.get('mae', 0),
                performance.get('mse', 0)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Í≤∞Í≥º Ï†ÄÏû• Ïã§Ìå®: {e}")
    
    def get_prediction_history(self, days: int = 7) -> pd.DataFrame:
        """ÏòàÏ∏° ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå"""
        
        conn = sqlite3.connect(self.db_path)
        
        query = '''
        SELECT * FROM predictions 
        WHERE timestamp >= datetime('now', '-{} days')
        ORDER BY timestamp DESC
        '''.format(days)
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        return df
    
    def get_system_performance(self, days: int = 7) -> pd.DataFrame:
        """ÏãúÏä§ÌÖú ÏÑ±Îä• ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå"""
        
        conn = sqlite3.connect(self.db_path)
        
        query = '''
        SELECT * FROM system_performance 
        WHERE timestamp >= datetime('now', '-{} days')
        ORDER BY timestamp DESC
        '''.format(days)
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        return df
    
    async def run_continuous_monitoring(self, interval_minutes: int = 60):
        """Ïó∞ÏÜç Î™®ÎãàÌÑ∞ÎßÅ Ïã§Ìñâ"""
        
        print(f"üîÑ Ïó∞ÏÜç Î™®ÎãàÌÑ∞ÎßÅ ÏãúÏûë ({interval_minutes}Î∂Ñ Í∞ÑÍ≤©)")
        
        while True:
            try:
                print(f"\n‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Î∂ÑÏÑù Ïã§Ìñâ")
                
                result = await self.run_comprehensive_analysis()
                
                if result["status"] == "success":
                    print(f"‚úÖ ÏÑ±Í≥µ - Ï†ïÌôïÎèÑ: {result['performance']['r2_score']:.4f}")
                    print(f"üí∞ ÌòÑÏû¨Í∞Ä: ${result['market_data']['btc_price']:,.0f}")
                    print(f"üìà 1ÏãúÍ∞Ñ ÏòàÏ∏°: ${result['predictions']['predicted_price_1h']:,.0f}")
                else:
                    print(f"‚ùå Ïã§Ìå®: {result.get('message', 'Unknown error')}")
                
                await asyncio.sleep(interval_minutes * 60)
                
            except KeyboardInterrupt:
                print("\nüõë Î™®ÎãàÌÑ∞ÎßÅ Ï§ëÎã®")
                break
            except Exception as e:
                print(f"‚ùå Î™®ÎãàÌÑ∞ÎßÅ Ïò§Î•ò: {e}")
                await asyncio.sleep(300)  # 5Î∂Ñ ÌõÑ Ïû¨ÏãúÎèÑ

# Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò
async def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    
    print("üéØ ÌÜµÌï© 1000+ ÌäπÏÑ± ÎπÑÌä∏ÏΩîÏù∏ ÏòàÏ∏° ÏãúÏä§ÌÖú")
    print("‚îÅ" * 60)
    
    # ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî
    system = Integrated1000FeatureSystem()
    
    if not FEATURE_MODULES_AVAILABLE:
        print("‚ùå ÌäπÏÑ± Î™®ÎìàÏùÑ Î®ºÏ†Ä Ïã§ÌñâÌïòÏó¨ ÏùòÏ°¥ÏÑ±ÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî")
        return
    
    # Îã®Ïùº Î∂ÑÏÑù Ïã§Ìñâ
    print("\nüìä Ìè¨Í¥ÑÏ†Å Î∂ÑÏÑù Ïã§Ìñâ")
    result = await system.run_comprehensive_analysis()
    
    # Í≤∞Í≥º Ï∂úÎ†•
    if result["status"] == "success":
        print("\nüéØ Î∂ÑÏÑù Í≤∞Í≥º ÏöîÏïΩ:")
        print(f"  ‚Ä¢ Ïã§Ìñâ ÏãúÍ∞Ñ: {result['execution_time']:.2f}Ï¥à")
        print(f"  ‚Ä¢ ÌòÑÏû¨ BTC Í∞ÄÍ≤©: ${result['market_data']['btc_price']:,.0f}")
        print(f"  ‚Ä¢ ÏÉùÏÑ±Îêú ÌäπÏÑ±: {result['features']['total_generated']}Í∞ú")
        print(f"  ‚Ä¢ ÏµúÏ†ÅÌôîÎêú ÌäπÏÑ±: {result['features']['optimized_count']}Í∞ú")
        print(f"  ‚Ä¢ ÏòàÏ∏° Ï†ïÌôïÎèÑ (R¬≤): {result['performance']['r2_score']:.4f}")
        print(f"  ‚Ä¢ Ïã†Î¢∞ÎèÑ: {result['predictions']['confidence_score']:.3f}")
        
        print(f"\nüìà Í∞ÄÍ≤© ÏòàÏ∏°:")
        print(f"  ‚Ä¢ 1ÏãúÍ∞Ñ ÌõÑ: ${result['predictions']['predicted_price_1h']:,.0f}")
        print(f"  ‚Ä¢ 4ÏãúÍ∞Ñ ÌõÑ: ${result['predictions']['predicted_price_4h']:,.0f}")
        print(f"  ‚Ä¢ 24ÏãúÍ∞Ñ ÌõÑ: ${result['predictions']['predicted_price_24h']:,.0f}")
        
        print(f"\nüèÜ Top 10 Ï§ëÏöî ÌäπÏÑ±:")
        for i, feature in enumerate(result['feature_ranking'][:10], 1):
            print(f"  {i:2d}. {feature['feature_name']} ({feature['final_score']:.4f})")
    
    # ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå
    print(f"\nüìã ÏµúÍ∑º ÏòàÏ∏° ÌûàÏä§ÌÜ†Î¶¨:")
    history = system.get_prediction_history(days=1)
    if len(history) > 0:
        print(history.head())
    else:
        print("  (ÌûàÏä§ÌÜ†Î¶¨ ÏóÜÏùå)")
    
    print(f"\n‚öôÔ∏è ÏãúÏä§ÌÖú ÏÑ±Îä• ÌûàÏä§ÌÜ†Î¶¨:")
    perf_history = system.get_system_performance(days=1)
    if len(perf_history) > 0:
        print(perf_history.head())
    else:
        print("  (ÏÑ±Îä• Í∏∞Î°ù ÏóÜÏùå)")
    
    # Ïó∞ÏÜç Î™®ÎãàÌÑ∞ÎßÅ ÏòµÏÖò
    print(f"\nüîÑ Ïó∞ÏÜç Î™®ÎãàÌÑ∞ÎßÅÏùÑ ÏãúÏûëÌïòÏãúÍ≤†ÏäµÎãàÍπå? (y/N): ", end="")
    try:
        if input().lower() == 'y':
            await system.run_continuous_monitoring(interval_minutes=60)
    except KeyboardInterrupt:
        print("\nüëã ÏãúÏä§ÌÖú Ï¢ÖÎ£å")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüëã ÌîÑÎ°úÍ∑∏Îû® Ï¢ÖÎ£å")