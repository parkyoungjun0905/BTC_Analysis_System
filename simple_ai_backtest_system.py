#!/usr/bin/env python3
"""
ğŸ¯ ì‹¤ìš©ì  AI BTC ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ (90% ì •í™•ë„ ëª©í‘œ)
1-3ì‹œê°„ ë‹¨ìœ„ ë¯¸ë˜ ê°€ê²© ì˜ˆì¸¡ - ë‹¨ê³„ë³„ êµ¬í˜„

Step 1: ê¸°ë³¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ ì‹œì‘
Step 2: ì •í™•ë„ ë‹¬ì„±ì‹œ ê³ ê¸‰ ì•™ìƒë¸”ë¡œ í™•ì¥
"""

import os
import sys
import json
import numpy as np
import pandas as pd
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import pickle

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings('ignore')

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì‚¬ìš©
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

print("ğŸš€ ì‹¤ìš©ì  AI ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì‹œì‘")
print("=" * 60)

class SimpleFeatureEngineer:
    """ê¸°ë³¸ íŠ¹ì„±ê³µí•™ - í•µì‹¬ ì§€í‘œë§Œ ì¶”ì¶œ"""
    
    def __init__(self):
        self.scaler = MinMaxScaler()
        print("âœ… ê¸°ë³¸ íŠ¹ì„±ê³µí•™ ì—”ì§„ ì´ˆê¸°í™”")
    
    def create_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """í•µì‹¬ ê¸°ìˆ  ì§€í‘œë§Œ ìƒì„±"""
        print("ğŸ“Š ê¸°ë³¸ ê¸°ìˆ  ì§€í‘œ ìƒì„± ì¤‘...")
        
        try:
            # ê¸°ë³¸ ê°€ê²© ë³€í™”ìœ¨
            df['price_change'] = df['close'].pct_change()
            df['price_change_ma'] = df['price_change'].rolling(5).mean()
            
            # ë³¼ë¥¨ ì§€í‘œ (ì‘ì€ ìœˆë„ìš°)
            df['volume_ma'] = df['volume'].rolling(5).mean()
            df['volume_ratio'] = df['volume'] / df['volume_ma']
            
            # ê¸°ë³¸ ì´ë™í‰ê·  (ì‘ì€ ìœˆë„ìš°)
            for window in [3, 5]:
                df[f'ma_{window}'] = df['close'].rolling(window).mean()
                df[f'ma_{window}_ratio'] = df['close'] / df[f'ma_{window}']
            
            # RSI (ê°„ë‹¨ ê³„ì‚°, ì‘ì€ ìœˆë„ìš°)
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=7).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=7).mean()
            rs = gain / loss
            df['rsi'] = 100 - (100 / (1 + rs))
            
            # ë³€ë™ì„± (ì‘ì€ ìœˆë„ìš°)
            df['volatility'] = df['close'].rolling(5).std()
            
            print(f"âœ… {len(df.columns)} ê°œ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
            return df.dropna()
            
        except Exception as e:
            print(f"âŒ íŠ¹ì„± ìƒì„± ì˜¤ë¥˜: {e}")
            return df

class SimpleAIPredictor:
    """ê°„ë‹¨í•˜ì§€ë§Œ íš¨ê³¼ì ì¸ AI ì˜ˆì¸¡ê¸°"""
    
    def __init__(self, lookback_hours: int = 5):
        self.lookback_hours = lookback_hours
        self.model = None
        self.scaler_X = StandardScaler()
        self.scaler_y = StandardScaler()
        self.feature_columns = []
        print(f"âœ… AI ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” (lookback: {lookback_hours}ì‹œê°„)")
    
    def create_sequences(self, df: pd.DataFrame, target_col: str = 'close') -> Tuple:
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        print("ğŸ”„ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")
        
        # íŠ¹ì„± ì„ íƒ (í•µì‹¬ë§Œ)
        feature_cols = ['price_change', 'volume_ratio', 'ma_5_ratio', 
                       'ma_10_ratio', 'rsi', 'volatility']
        feature_cols = [col for col in feature_cols if col in df.columns]
        
        if len(feature_cols) < 3:
            print("âŒ ì¶©ë¶„í•œ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤")
            return None, None
        
        self.feature_columns = feature_cols
        print(f"ğŸ“Š ì‚¬ìš© íŠ¹ì„±: {feature_cols}")
        
        # ë°ì´í„° ì¤€ë¹„
        X, y = [], []
        for i in range(self.lookback_hours, len(df) - 1):  # -1 ì¶”ê°€ë¡œ y ë²”ìœ„ ë³´ì¥
            # ê³¼ê±° lookback_hours ì‹œê°„ì˜ íŠ¹ì„±ë“¤
            X.append(df[feature_cols].iloc[i-self.lookback_hours:i].values.flatten())
            # 1ì‹œê°„ í›„ ê°€ê²© (ëª©í‘œ)
            y.append(df[target_col].iloc[i + 1])
        
        X = np.array(X)
        y = np.array(y)
        
        # ê¸¸ì´ í™•ì¸ ë° ì¡°ì •
        if len(X) != len(y):
            min_len = min(len(X), len(y))
            X = X[:min_len]
            y = y[:min_len]
            print(f"âš ï¸ ê¸¸ì´ ë¶ˆì¼ì¹˜ ìˆ˜ì •: {min_len}ê°œ ìƒ˜í”Œë¡œ ì¡°ì •")
        
        print(f"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: X={X.shape}, y={y.shape}")
        return X, y
    
    def train_model(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ëª¨ë¸ í•™ìŠµ"""
        print("ğŸ¤– AI ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler_X.fit_transform(X)
        y_scaled = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()
        
        # ê°„ë‹¨í•˜ì§€ë§Œ ê°•ë ¥í•œ RandomForest ì‚¬ìš©
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        
        # ê°„ë‹¨í•œ train/validation ë¶„í•  (ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ)
        if len(X_scaled) < 10:
            # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ
            self.model.fit(X_scaled, y_scaled)
            avg_score = 0.5  # ê¸°ë³¸ê°’
            scores = [avg_score]
            print("âš ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ êµì°¨ê²€ì¦ ê±´ë„ˆëœ€")
        else:
            # 80:20 ë¶„í• 
            split_idx = int(len(X_scaled) * 0.8)
            X_train, X_val = X_scaled[:split_idx], X_scaled[split_idx:]
            y_train, y_val = y_scaled[:split_idx], y_scaled[split_idx:]
            
            # í•™ìŠµ
            self.model.fit(X_train, y_train)
            
            # ì˜ˆì¸¡ ë° í‰ê°€
            if len(y_val) > 0:
                y_pred = self.model.predict(X_val)
                if len(y_val) == len(y_pred):
                    avg_score = r2_score(y_val, y_pred)
                    scores = [avg_score]
                    print(f"  ê²€ì¦ RÂ²: {avg_score:.4f}")
                else:
                    avg_score = 0.5
                    scores = [avg_score]
                    print(f"  ê¸¸ì´ ë¶ˆì¼ì¹˜: y_val={len(y_val)}, y_pred={len(y_pred)}")
            else:
                avg_score = 0.5
                scores = [avg_score]
                print("  ê²€ì¦ ë°ì´í„° ë¶€ì¡±")
            
            # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ
            self.model.fit(X_scaled, y_scaled)
        accuracy_percent = max(0, avg_score * 100)
        
        results = {
            'cv_scores': scores,
            'average_r2': avg_score,
            'accuracy_percent': accuracy_percent,
            'model_type': 'RandomForest'
        }
        
        print(f"âœ… í•™ìŠµ ì™„ë£Œ! í‰ê·  ì •í™•ë„: {accuracy_percent:.2f}%")
        return results
    
    def predict_future(self, df: pd.DataFrame, hours_ahead: int = 3) -> Dict:
        """ë¯¸ë˜ ê°€ê²© ì˜ˆì¸¡"""
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return {}
        
        # ìµœê·¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡
        recent_data = df[self.feature_columns].tail(self.lookback_hours).values.flatten()
        recent_scaled = self.scaler_X.transform([recent_data])
        
        # ì˜ˆì¸¡ (ìŠ¤ì¼€ì¼ë§ëœ ê°’)
        pred_scaled = self.model.predict(recent_scaled)[0]
        
        # ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›
        pred_price = self.scaler_y.inverse_transform([[pred_scaled]])[0][0]
        
        current_price = df['close'].iloc[-1]
        price_change = pred_price - current_price
        change_percent = (price_change / current_price) * 100
        
        confidence = min(95, max(50, abs(self.model.score(
            self.scaler_X.transform([recent_data]), 
            [self.scaler_y.transform([[current_price]])[0][0]]
        )) * 100))
        
        result = {
            'current_price': current_price,
            'predicted_price': pred_price,
            'price_change': price_change,
            'change_percent': change_percent,
            'confidence': confidence,
            'prediction_time': datetime.now().isoformat(),
            'hours_ahead': hours_ahead
        }
        
        print(f"ğŸ¯ {hours_ahead}ì‹œê°„ í›„ ì˜ˆì¸¡:")
        print(f"   í˜„ì¬ê°€: ${current_price:,.2f}")
        print(f"   ì˜ˆì¸¡ê°€: ${pred_price:,.2f}")
        print(f"   ë³€í™”: {change_percent:+.2f}% (ì‹ ë¢°ë„: {confidence:.1f}%)")
        
        return result

class SimpleBacktester:
    """ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„"""
    
    def __init__(self):
        self.results = []
        print("âœ… ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì´ˆê¸°í™”")
    
    def run_backtest(self, df: pd.DataFrame, test_size: int = 200) -> Dict:
        """ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"ğŸ” ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìµœê·¼ {test_size}ì‹œê°„ ë°ì´í„°)")
        
        # íŠ¹ì„±ê³µí•™
        engineer = SimpleFeatureEngineer()
        df_featured = engineer.create_basic_features(df.copy())
        
        if len(df_featured) < 20:
            print("âŒ ë°ì´í„°ê°€ ë„ˆë¬´ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 20í–‰ í•„ìš”)")
            return {}
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  (ì‘ì€ ë°ì´í„°ì— ë§ê²Œ ì¡°ì •)
        train_size = max(15, len(df_featured) - test_size)
        if train_size >= len(df_featured):
            train_size = len(df_featured) - 3
            test_size = 3
            
        train_df = df_featured.iloc[:train_size]
        test_df = df_featured.iloc[train_size:]
        
        print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_df)}ì‹œê°„, í…ŒìŠ¤íŠ¸: {len(test_df)}ì‹œê°„")
        
        # AI ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ë° í•™ìŠµ
        predictor = SimpleAIPredictor()
        X_train, y_train = predictor.create_sequences(train_df)
        
        if X_train is None or len(X_train) < 5:
            print("âŒ í•™ìŠµ ì‹œí€€ìŠ¤ ìƒì„± ì‹¤íŒ¨")
            return {}
        
        # ëª¨ë¸ í•™ìŠµ
        train_results = predictor.train_model(X_train, y_train)
        
        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        print("ğŸ¯ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")
        predictions = []
        actuals = []
        
        for i in range(len(test_df) - 3):
            test_window = pd.concat([
                train_df.tail(predictor.lookback_hours),
                test_df.iloc[:i+1]
            ]).tail(len(train_df) + i + 1)
            
            if len(test_window) < predictor.lookback_hours + 1:
                continue
                
            pred_result = predictor.predict_future(test_window)
            if pred_result:
                predictions.append(pred_result['predicted_price'])
                
                # ì‹¤ì œê°’ (3ì‹œê°„ í›„)
                if i + 3 < len(test_df):
                    actuals.append(test_df['close'].iloc[i + 3])
                else:
                    break
        
        if len(predictions) < 10:
            print("âŒ ì¶©ë¶„í•œ ì˜ˆì¸¡ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return train_results
        
        # ì •í™•ë„ ê³„ì‚°
        predictions = np.array(predictions[:len(actuals)])
        actuals = np.array(actuals)
        
        # ë°©í–¥ì„± ì •í™•ë„ (ìƒìŠ¹/í•˜ë½ ë§ì¶”ê¸°)
        pred_directions = np.where(predictions > test_df['close'].iloc[:-3].values[:len(predictions)], 1, -1)
        actual_directions = np.where(actuals > test_df['close'].iloc[:-3].values[:len(actuals)], 1, -1)
        direction_accuracy = (pred_directions == actual_directions).mean() * 100
        
        # ê°€ê²© ì •í™•ë„
        mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100
        price_accuracy = max(0, 100 - mape)
        
        # ìµœì¢… ì •í™•ë„ (ë°©í–¥ì„± + ê°€ê²© ì •í™•ë„ í‰ê· )
        final_accuracy = (direction_accuracy + price_accuracy) / 2
        
        backtest_results = {
            **train_results,
            'test_predictions': len(predictions),
            'direction_accuracy': direction_accuracy,
            'price_accuracy': price_accuracy,
            'final_accuracy': final_accuracy,
            'mape': mape,
            'predictions': predictions.tolist(),
            'actuals': actuals.tolist()
        }
        
        print(f"ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   ë°©í–¥ì„± ì •í™•ë„: {direction_accuracy:.2f}%")
        print(f"   ê°€ê²© ì •í™•ë„: {price_accuracy:.2f}%")
        print(f"   ğŸ¯ ìµœì¢… ì •í™•ë„: {final_accuracy:.2f}%")
        
        return backtest_results

def load_data() -> pd.DataFrame:
    """ë°ì´í„° ë¡œë”©"""
    print("ğŸ“ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    try:
        # ê¸°ì¡´ ë°ì´í„° ì°¾ê¸°
        data_files = [
            'ai_optimized_3month_data/ai_matrix_complete.csv',
            'complete_indicators_data.csv',
            'btc_hourly_data.csv',
            'hourly_data.csv'
        ]
        
        df = None
        for file in data_files:
            if os.path.exists(file):
                print(f"ğŸ“Š {file} ë¡œë”© ì¤‘...")
                df = pd.read_csv(file)
                break
        
        if df is None:
            print("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ê¸°ë³¸ ì»¬ëŸ¼ í™•ì¸ ë° ë§¤í•‘
        price_col = None
        volume_col = None
        
        # ê°€ê²© ì»¬ëŸ¼ ì°¾ê¸°
        price_candidates = ['close', 'legacy_market_data_avg_price', 'market_avg_price', 'price',
                           'onchain_blockchain_info_network_stats_market_price_usd']
        for col in price_candidates:
            if col in df.columns:
                price_col = col
                break
        
        # ë³¼ë¥¨ ì»¬ëŸ¼ ì°¾ê¸°
        volume_candidates = ['volume', 'onchain_blockchain_info_network_stats_trade_volume_btc',
                            'legacy_market_data_total_volume', 'market_total_volume', 'total_volume']
        for col in volume_candidates:
            if col in df.columns:
                volume_col = col
                break
        
        if not price_col:
            print(f"âŒ ê°€ê²© ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë„í•œ ì»¬ëŸ¼: {price_candidates}")
            return None
            
        # ì»¬ëŸ¼ëª… í‘œì¤€í™”
        if price_col != 'close':
            df['close'] = df[price_col]
        if volume_col and volume_col != 'volume':
            df['volume'] = df[volume_col]
        elif not volume_col:
            # ë³¼ë¥¨ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ë³¼ë¥¨ ìƒì„±
            df['volume'] = 1000
            print("âš ï¸ ë³¼ë¥¨ ë°ì´í„° ì—†ìŒ - ë”ë¯¸ ë³¼ë¥¨ ì‚¬ìš©")
        
        # ì‹œê°„ ì •ë ¬
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp')
        
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}í–‰, {len(df.columns)}ì—´")
        print(f"   ê¸°ê°„: {df.index[0]} ~ {df.index[-1]}")
        
        return df
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ ì‹¤ìš©ì  AI BTC ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ")
    print("   ëª©í‘œ: 1-3ì‹œê°„ í›„ 90% ì •í™•ë„ ë‹¬ì„±")
    print("=" * 60)
    
    # ë°ì´í„° ë¡œë”©
    df = load_data()
    if df is None:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì¢…ë£Œ")
        return
    
    # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    backtester = SimpleBacktester()
    results = backtester.run_backtest(df)
    
    if not results:
        print("âŒ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return
    
    # ê²°ê³¼ ì €ì¥
    results['system_version'] = 'SimpleAI_v1.0'
    results['timestamp'] = datetime.now().isoformat()
    
    with open('simple_ai_backtest_results.json', 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print("=" * 60)
    print("ğŸ‰ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ¯ ë‹¬ì„± ì •í™•ë„: {results.get('final_accuracy', 0):.2f}%")
    
    if results.get('final_accuracy', 0) >= 90:
        print("ğŸ† 90% ì •í™•ë„ ë‹¬ì„±! ê³ ê¸‰ ì•™ìƒë¸”ë¡œ ì—…ê·¸ë ˆì´ë“œ ì¤€ë¹„")
    else:
        print("âš¡ 90% ë¯¸ë‹¬ - ëª¨ë¸ ê°œì„  í•„ìš”")
    
    print("ğŸ“„ ê²°ê³¼ ì €ì¥: simple_ai_backtest_results.json")

if __name__ == "__main__":
    main()