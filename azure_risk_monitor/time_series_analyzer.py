"""
ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù ÏãúÏä§ÌÖú
Í≥ºÍ±∞ ÏßÄÏàòÎì§Ïùò Î≥ÄÌôî Ìå®ÌÑ¥ÏúºÎ°ú ÎØ∏Îûò ÏòàÏ∏°
30Î∂Ñ Í∞ÑÍ≤©Ïù¥ÏßÄÎßå 1Î∂Ñ Îç∞Ïù¥ÌÑ∞Î°ú ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù
"""

import asyncio
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import numpy as np
from dataclasses import dataclass
import logging
import json

logger = logging.getLogger(__name__)

@dataclass
class TimeSeriesData:
    """ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞"""
    timestamp: datetime
    price: float
    volume: float
    indicators: Dict
    
class TimeSeriesAnalyzer:
    """ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑùÍ∏∞ - Í≥ºÍ±∞ Ìå®ÌÑ¥ÏúºÎ°ú ÎØ∏Îûò ÏòàÏ∏°"""
    
    def __init__(self, db_path: str = "timeseries.db"):
        self.db_path = db_path
        self.logger = logger
        self.init_database()
        
        # ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù ÌååÎùºÎØ∏ÌÑ∞
        self.analysis_windows = {
            "short": 30,    # 30Î∂Ñ (1Î∂Ñ √ó 30)
            "medium": 180,  # 3ÏãúÍ∞Ñ (1Î∂Ñ √ó 180)
            "long": 720     # 12ÏãúÍ∞Ñ (1Î∂Ñ √ó 720)
        }
        
    def init_database(self):
        """ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # 1Î∂Ñ Í∞ÑÍ≤© Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS price_series (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    price REAL NOT NULL,
                    volume REAL,
                    change_1m REAL,
                    change_5m REAL,
                    change_15m REAL,
                    rsi_14 REAL,
                    macd_signal TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ÏßÄÌëúÎ≥Ñ ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS indicator_series (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    indicator_name TEXT NOT NULL,
                    value REAL NOT NULL,
                    signal TEXT,
                    strength REAL,
                    trend TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ìå®ÌÑ¥ Îß§Ïπ≠ Í≤∞Í≥º
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS pattern_matches (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    pattern_type TEXT NOT NULL,
                    similarity REAL NOT NULL,
                    predicted_direction TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    actual_outcome TEXT,
                    accuracy_score REAL,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ïù∏Îç±Ïä§ ÏÉùÏÑ± (ÏøºÎ¶¨ ÏµúÏ†ÅÌôî)
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_price_timestamp ON price_series(timestamp)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_indicator_timestamp ON indicator_series(timestamp)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_pattern_timestamp ON pattern_matches(timestamp)')
            
            conn.commit()
            conn.close()
            
            self.logger.info("‚úÖ ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
            
        except Exception as e:
            self.logger.error(f"ÏãúÍ≥ÑÏó¥ DB Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
    
    async def store_realtime_data(self, current_data: Dict, indicators: Dict) -> bool:
        """Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• (Îß§Î≤à Ìò∏Ï∂ú Ïãú)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            timestamp = datetime.utcnow().isoformat()
            price_data = current_data.get("price_data", {})
            
            # 1. Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            current_price = price_data.get("current_price", 0)
            volume = price_data.get("volume_24h", 0)
            
            # Í≥ºÍ±∞ Í∞ÄÍ≤©Îì§Í≥º ÎπÑÍµêÌïòÏó¨ Î≥ÄÌôîÏú® Í≥ÑÏÇ∞
            changes = self._calculate_price_changes(current_price)
            
            cursor.execute('''
                INSERT INTO price_series 
                (timestamp, price, volume, change_1m, change_5m, change_15m, rsi_14, macd_signal)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                timestamp, current_price, volume,
                changes.get("1m", 0), changes.get("5m", 0), changes.get("15m", 0),
                0, "NEUTRAL"  # RSI, MACDÎäî Î≥ÑÎèÑ Í≥ÑÏÇ∞ ÌïÑÏöî
            ))
            
            # 2. ÏßÄÌëú Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            for indicator_name, indicator_data in indicators.items():
                if isinstance(indicator_data, dict):
                    value = indicator_data.get("strength", 0)
                    signal = indicator_data.get("signal", "NEUTRAL")
                    trend = indicator_data.get("trend", "stable")
                    
                    cursor.execute('''
                        INSERT INTO indicator_series 
                        (timestamp, indicator_name, value, signal, strength, trend)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (timestamp, indicator_name, value, signal, value, trend))
            
            conn.commit()
            conn.close()
            
            return True
            
        except Exception as e:
            self.logger.error(f"Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ïã§Ìå®: {e}")
            return False
    
    def _calculate_price_changes(self, current_price: float) -> Dict:
        """Í≥ºÍ±∞ Í∞ÄÍ≤©Í≥º ÎπÑÍµêÌïòÏó¨ Î≥ÄÌôîÏú® Í≥ÑÏÇ∞"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            changes = {}
            
            # 1Î∂Ñ, 5Î∂Ñ, 15Î∂Ñ Ï†Ñ Í∞ÄÍ≤© Í∞ÄÏ†∏Ïò§Í∏∞
            time_frames = {
                "1m": 1,
                "5m": 5,
                "15m": 15
            }
            
            for tf_name, minutes_ago in time_frames.items():
                past_time = (datetime.utcnow() - timedelta(minutes=minutes_ago)).isoformat()
                
                cursor.execute('''
                    SELECT price FROM price_series 
                    WHERE timestamp <= ? 
                    ORDER BY timestamp DESC 
                    LIMIT 1
                ''', (past_time,))
                
                result = cursor.fetchone()
                if result:
                    past_price = result[0]
                    change_pct = ((current_price - past_price) / past_price) * 100 if past_price > 0 else 0
                    changes[tf_name] = change_pct
                else:
                    changes[tf_name] = 0
            
            conn.close()
            return changes
            
        except Exception as e:
            self.logger.error(f"Í∞ÄÍ≤© Î≥ÄÌôîÏú® Í≥ÑÏÇ∞ Ïã§Ìå®: {e}")
            return {"1m": 0, "5m": 0, "15m": 0}
    
    async def analyze_time_series_patterns(self) -> Dict:
        """ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ Î∂ÑÏÑù (ÌïµÏã¨ Í∏∞Îä•)"""
        try:
            self.logger.info("üîç ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ Î∂ÑÏÑù ÏãúÏûë...")
            
            # 1. ÏµúÍ∑º Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞
            recent_patterns = self._get_recent_patterns()
            
            if not recent_patterns:
                self.logger.warning("ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±")
                return {"pattern_found": False, "confidence": 0}
            
            # 2. Í≥ºÍ±∞ Ïú†ÏÇ¨ Ìå®ÌÑ¥ Í≤ÄÏÉâ
            similar_patterns = self._find_similar_patterns(recent_patterns)
            
            # 3. ÏòàÏ∏° ÏÉùÏÑ±
            prediction = self._generate_pattern_prediction(similar_patterns)
            
            # 4. Ìå®ÌÑ¥ Îß§Ïπ≠ Í≤∞Í≥º Ï†ÄÏû•
            self._store_pattern_result(prediction)
            
            return prediction
            
        except Exception as e:
            self.logger.error(f"ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ Î∂ÑÏÑù Ïã§Ìå®: {e}")
            return {"pattern_found": False, "confidence": 0}
    
    def _get_recent_patterns(self, lookback_minutes: int = 60) -> List[Dict]:
        """ÏµúÍ∑º Ìå®ÌÑ¥ Ï∂îÏ∂ú"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ÏµúÍ∑º 60Î∂Ñ Îç∞Ïù¥ÌÑ∞
            since_time = (datetime.utcnow() - timedelta(minutes=lookback_minutes)).isoformat()
            
            cursor.execute('''
                SELECT timestamp, price, change_1m, change_5m, change_15m
                FROM price_series 
                WHERE timestamp >= ? 
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (since_time, lookback_minutes))
            
            rows = cursor.fetchall()
            
            patterns = []
            for row in rows:
                patterns.append({
                    "timestamp": row[0],
                    "price": row[1],
                    "change_1m": row[2],
                    "change_5m": row[3], 
                    "change_15m": row[4]
                })
            
            conn.close()
            return patterns
            
        except Exception as e:
            self.logger.error(f"ÏµúÍ∑º Ìå®ÌÑ¥ Ï∂îÏ∂ú Ïã§Ìå®: {e}")
            return []
    
    def _find_similar_patterns(self, current_pattern: List[Dict]) -> List[Dict]:
        """Í≥ºÍ±∞ Ïú†ÏÇ¨ Ìå®ÌÑ¥ Í≤ÄÏÉâ"""
        try:
            if len(current_pattern) < 10:
                return []
                
            # ÌòÑÏû¨ Ìå®ÌÑ¥Ïùò ÌäπÏßï Î≤°ÌÑ∞ ÏÉùÏÑ±
            current_features = self._extract_pattern_features(current_pattern)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Í≥ºÍ±∞ Î™®Îì† Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ïú†ÏÇ¨ Íµ¨Í∞Ñ Í≤ÄÏÉâ
            cursor.execute('''
                SELECT timestamp, price, change_1m, change_5m, change_15m
                FROM price_series 
                WHERE timestamp < ? 
                ORDER BY timestamp DESC
                LIMIT 1440
            ''', ((datetime.utcnow() - timedelta(hours=2)).isoformat(),))
            
            historical_data = cursor.fetchall()
            
            similar_patterns = []
            
            # Ïä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞Î°ú Ïú†ÏÇ¨ÏÑ± Í≤ÄÏÇ¨
            for i in range(len(historical_data) - len(current_pattern)):
                window = historical_data[i:i + len(current_pattern)]
                
                # ÌäπÏßï Î≤°ÌÑ∞ Ï∂îÏ∂ú
                window_features = self._extract_pattern_features([{
                    "price": row[1], "change_1m": row[2], 
                    "change_5m": row[3], "change_15m": row[4]
                } for row in window])
                
                # Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
                similarity = self._calculate_similarity(current_features, window_features)
                
                if similarity > 0.7:  # 70% Ïù¥ÏÉÅ Ïú†ÏÇ¨
                    # Ìï¥Îãπ Ìå®ÌÑ¥ Ïù¥ÌõÑ Í≤∞Í≥º ÌôïÏù∏
                    future_outcome = self._get_pattern_outcome(historical_data[i]["timestamp"])
                    
                    similar_patterns.append({
                        "similarity": similarity,
                        "outcome": future_outcome,
                        "timestamp": historical_data[i][0]
                    })
            
            conn.close()
            
            # Ïú†ÏÇ¨ÎèÑ ÏàúÏúºÎ°ú Ï†ïÎ†¨
            similar_patterns.sort(key=lambda x: x["similarity"], reverse=True)
            return similar_patterns[:5]  # ÏÉÅÏúÑ 5Í∞ú
            
        except Exception as e:
            self.logger.error(f"Ïú†ÏÇ¨ Ìå®ÌÑ¥ Í≤ÄÏÉâ Ïã§Ìå®: {e}")
            return []
    
    def _extract_pattern_features(self, pattern: List[Dict]) -> np.ndarray:
        """Ìå®ÌÑ¥ÏóêÏÑú ÌäπÏßï Î≤°ÌÑ∞ Ï∂îÏ∂ú"""
        features = []
        
        for data in pattern:
            features.extend([
                data.get("change_1m", 0),
                data.get("change_5m", 0), 
                data.get("change_15m", 0)
            ])
        
        return np.array(features)
    
    def _calculate_similarity(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """Îëê Ìå®ÌÑ¥ Í∞Ñ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞ (ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ)"""
        try:
            if len(features1) != len(features2):
                return 0.0
                
            dot_product = np.dot(features1, features2)
            norm_a = np.linalg.norm(features1)
            norm_b = np.linalg.norm(features2)
            
            if norm_a == 0 or norm_b == 0:
                return 0.0
                
            return dot_product / (norm_a * norm_b)
            
        except Exception:
            return 0.0
    
    def _get_pattern_outcome(self, pattern_timestamp: str) -> Dict:
        """Ìå®ÌÑ¥ Ïù¥ÌõÑ Ïã§Ï†ú Í≤∞Í≥º ÌôïÏù∏"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # 30Î∂Ñ ÌõÑ Í∞ÄÍ≤©
            future_time = (datetime.fromisoformat(pattern_timestamp) + timedelta(minutes=30)).isoformat()
            
            cursor.execute('''
                SELECT price FROM price_series 
                WHERE timestamp >= ? 
                ORDER BY timestamp ASC 
                LIMIT 1
            ''', (future_time,))
            
            result = cursor.fetchone()
            
            if result:
                # ÌòÑÏû¨ Í∞ÄÍ≤©Í≥º 30Î∂Ñ ÌõÑ Í∞ÄÍ≤© ÎπÑÍµê
                cursor.execute('''
                    SELECT price FROM price_series 
                    WHERE timestamp <= ? 
                    ORDER BY timestamp DESC 
                    LIMIT 1
                ''', (pattern_timestamp,))
                
                current_result = cursor.fetchone()
                
                if current_result:
                    current_price = current_result[0]
                    future_price = result[0]
                    change_pct = ((future_price - current_price) / current_price) * 100
                    
                    if change_pct > 0.5:
                        direction = "BULLISH"
                    elif change_pct < -0.5:
                        direction = "BEARISH"
                    else:
                        direction = "NEUTRAL"
                        
                    return {
                        "direction": direction,
                        "change_percent": change_pct,
                        "confidence": min(abs(change_pct) * 20, 100)
                    }
            
            conn.close()
            return {"direction": "NEUTRAL", "change_percent": 0, "confidence": 0}
            
        except Exception as e:
            self.logger.error(f"Ìå®ÌÑ¥ Í≤∞Í≥º ÌôïÏù∏ Ïã§Ìå®: {e}")
            return {"direction": "NEUTRAL", "change_percent": 0, "confidence": 0}
    
    def _generate_pattern_prediction(self, similar_patterns: List[Dict]) -> Dict:
        """Ïú†ÏÇ¨ Ìå®ÌÑ¥Îì§Î°úÎ∂ÄÌÑ∞ ÏòàÏ∏° ÏÉùÏÑ±"""
        try:
            if not similar_patterns:
                return {
                    "pattern_found": False,
                    "prediction": "NEUTRAL",
                    "confidence": 0,
                    "reasoning": "Ïú†ÏÇ¨ Ìå®ÌÑ¥ ÏóÜÏùå"
                }
            
            # Ïú†ÏÇ¨ Ìå®ÌÑ¥Îì§Ïùò Í≤∞Í≥º Î∂ÑÏÑù
            bullish_count = 0
            bearish_count = 0
            total_confidence = 0
            
            for pattern in similar_patterns:
                outcome = pattern.get("outcome", {})
                direction = outcome.get("direction", "NEUTRAL")
                similarity = pattern.get("similarity", 0)
                
                if direction == "BULLISH":
                    bullish_count += 1
                    total_confidence += outcome.get("confidence", 0) * similarity
                elif direction == "BEARISH":
                    bearish_count += 1
                    total_confidence += outcome.get("confidence", 0) * similarity
            
            # ÏòàÏ∏° Í≤∞Ï†ï
            if bullish_count > bearish_count:
                prediction = "BULLISH"
                confidence = (total_confidence / len(similar_patterns)) * (bullish_count / len(similar_patterns))
            elif bearish_count > bullish_count:
                prediction = "BEARISH"  
                confidence = (total_confidence / len(similar_patterns)) * (bearish_count / len(similar_patterns))
            else:
                prediction = "NEUTRAL"
                confidence = 30
            
            return {
                "pattern_found": True,
                "prediction": prediction,
                "confidence": min(confidence, 95),
                "similar_patterns_count": len(similar_patterns),
                "bullish_patterns": bullish_count,
                "bearish_patterns": bearish_count,
                "reasoning": f"{len(similar_patterns)}Í∞ú Ïú†ÏÇ¨ Ìå®ÌÑ¥ Ï§ë {bullish_count}Í∞ú Í∞ïÏÑ∏, {bearish_count}Í∞ú ÏïΩÏÑ∏"
            }
            
        except Exception as e:
            self.logger.error(f"Ìå®ÌÑ¥ ÏòàÏ∏° ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return {"pattern_found": False, "prediction": "NEUTRAL", "confidence": 0}
    
    def _store_pattern_result(self, prediction: Dict):
        """Ìå®ÌÑ¥ Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû•"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO pattern_matches 
                (timestamp, pattern_type, similarity, predicted_direction, confidence)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                datetime.utcnow().isoformat(),
                "time_series_pattern",
                prediction.get("similar_patterns_count", 0) / 10,
                prediction.get("prediction", "NEUTRAL"),
                prediction.get("confidence", 0)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Ìå®ÌÑ¥ Í≤∞Í≥º Ï†ÄÏû• Ïã§Ìå®: {e}")
    
    def get_time_series_summary(self) -> Dict:
        """ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù ÏöîÏïΩ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Îç∞Ïù¥ÌÑ∞ ÌòÑÌô©
            cursor.execute('SELECT COUNT(*) FROM price_series')
            price_count = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(*) FROM indicator_series')
            indicator_count = cursor.fetchone()[0]
            
            # ÏµúÍ∑º Ìå®ÌÑ¥ Ï†ïÌôïÎèÑ
            cursor.execute('''
                SELECT AVG(accuracy_score) FROM pattern_matches 
                WHERE accuracy_score IS NOT NULL 
                AND timestamp >= ?
            ''', ((datetime.utcnow() - timedelta(days=7)).isoformat(),))
            
            accuracy = cursor.fetchone()[0] or 0
            
            conn.close()
            
            return {
                "price_data_points": price_count,
                "indicator_data_points": indicator_count,
                "pattern_accuracy_7d": f"{accuracy:.1%}",
                "data_coverage": f"{price_count}Î∂Ñ" if price_count < 1440 else f"{price_count/1440:.1f}Ïùº"
            }
            
        except Exception as e:
            self.logger.error(f"ÏãúÍ≥ÑÏó¥ ÏöîÏïΩ ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return {}

async def test_time_series_analyzer():
    """ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑùÍ∏∞ ÌÖåÏä§Ìä∏"""
    print("üß™ ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù ÏãúÏä§ÌÖú ÌÖåÏä§Ìä∏")
    print("="*50)
    
    analyzer = TimeSeriesAnalyzer()
    
    # ÏãúÎÆ¨Î†àÏù¥ÏÖò Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
    print("üìä ÏãúÎÆ¨Î†àÏù¥ÏÖò Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± Ï§ë...")
    
    for i in range(100):
        fake_data = {
            "price_data": {
                "current_price": 58000 + i * 10 + np.random.normal(0, 50),
                "volume_24h": 25000000000
            }
        }
        fake_indicators = {
            "test_indicator": {
                "strength": np.random.random(),
                "signal": np.random.choice(["BULLISH", "BEARISH", "NEUTRAL"]),
                "trend": np.random.choice(["rising", "falling", "stable"])
            }
        }
        
        await analyzer.store_realtime_data(fake_data, fake_indicators)
        await asyncio.sleep(0.01)  # ÏßßÏùÄ ÏßÄÏó∞
    
    # Ìå®ÌÑ¥ Î∂ÑÏÑù Ïã§Ìñâ
    print("üîç ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ Î∂ÑÏÑù Ï§ë...")
    result = await analyzer.analyze_time_series_patterns()
    
    if result.get("pattern_found"):
        print(f"‚úÖ Ìå®ÌÑ¥ Î∞úÍ≤¨!")
        print(f"  ‚Ä¢ ÏòàÏ∏°: {result.get('prediction')}")
        print(f"  ‚Ä¢ Ïã†Î¢∞ÎèÑ: {result.get('confidence'):.1f}%")
        print(f"  ‚Ä¢ Ïú†ÏÇ¨ Ìå®ÌÑ¥: {result.get('similar_patterns_count')}Í∞ú")
        print(f"  ‚Ä¢ Ïù¥Ïú†: {result.get('reasoning')}")
    else:
        print("‚ùå Ïú†ÏÇ¨ Ìå®ÌÑ¥ÏùÑ Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§")
    
    # ÏãúÍ≥ÑÏó¥ ÏöîÏïΩ
    summary = analyzer.get_time_series_summary()
    print(f"\nüìà ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ ÌòÑÌô©:")
    for key, value in summary.items():
        print(f"  ‚Ä¢ {key}: {value}")

if __name__ == "__main__":
    asyncio.run(test_time_series_analyzer())