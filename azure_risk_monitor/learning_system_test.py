#!/usr/bin/env python3
"""
ì ì‘ì  í•™ìŠµ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import sqlite3
from datetime import datetime, timedelta
from adaptive_learning_engine import AdaptiveLearningEngine
from prediction_tracker import PredictionTracker

async def test_learning_system():
    """í•™ìŠµ ì‹œìŠ¤í…œ ì „ì²´ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print("ğŸ§  ì ì‘ì  í•™ìŠµ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    print("\nğŸ“¦ 1/7 - ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
    learning_engine = AdaptiveLearningEngine()
    tracker = PredictionTracker()
    
    # 2. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±
    print("ğŸ“ 2/7 - í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±...")
    test_predictions = await generate_test_predictions(tracker)
    print(f"   âœ… {len(test_predictions)} ê°œ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìƒì„±")
    
    # 3. ì‹¤íŒ¨ ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("ğŸ” 3/7 - ì‹¤íŒ¨ ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...")
    failure_analysis = learning_engine.analyze_prediction_failures(7)
    
    if failure_analysis.get("total_failures", 0) > 0:
        print(f"   âœ… {failure_analysis['total_failures']}ê°œ ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„ ì™„ë£Œ")
        print(f"   ğŸ“Š ê°€ì¥ í”í•œ ì‹¤íŒ¨ ìœ í˜•: {failure_analysis['pattern_summary']['most_common_failure_type']}")
    else:
        print("   â„¹ï¸  ë¶„ì„í•  ì‹¤íŒ¨ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # 4. ê°€ì¤‘ì¹˜ ì ì‘ í…ŒìŠ¤íŠ¸
    print("âš–ï¸ 4/7 - ê°€ì¤‘ì¹˜ ì ì‘ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...")
    if failure_analysis.get("failure_analyses"):
        adaptation_result = learning_engine.adapt_indicator_weights(
            failure_analysis["failure_analyses"]
        )
        
        if adaptation_result.get("total_adjustments", 0) > 0:
            print(f"   âœ… {adaptation_result['total_adjustments']}ê°œ ì§€í‘œ ê°€ì¤‘ì¹˜ ì¡°ì • ì™„ë£Œ")
            print(f"   ğŸ“ˆ {adaptation_result['adaptation_summary']}")
        else:
            print("   â„¹ï¸  ì¡°ì •ëœ ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤")
    else:
        print("   â­ï¸  ì‹¤íŒ¨ ë°ì´í„° ì—†ìŒ, ê°€ì¤‘ì¹˜ ì¡°ì • ê±´ë„ˆëœ€")
    
    # 5. ì„ê³„ê°’ ìµœì í™” í…ŒìŠ¤íŠ¸
    print("ğŸ¯ 5/7 - ë™ì  ì„ê³„ê°’ ìµœì í™” í…ŒìŠ¤íŠ¸...")
    threshold_result = learning_engine.optimize_dynamic_thresholds()
    
    if "new_confidence_threshold" in threshold_result:
        old_th = threshold_result.get("old_confidence_threshold", 0)
        new_th = threshold_result.get("new_confidence_threshold", 0)
        print(f"   âœ… ì„ê³„ê°’ ìµœì í™”: {old_th}% â†’ {new_th}%")
        
        improvement = threshold_result.get("expected_accuracy_improvement", 0)
        print(f"   ğŸ“Š ì˜ˆìƒ ì •í™•ë„ í–¥ìƒ: +{improvement:.1f}%")
    else:
        print("   â„¹ï¸  ì„ê³„ê°’ ìµœì í™”í•  ë°ì´í„° ë¶€ì¡±")
    
    # 6. í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
    print("ğŸ’¡ 6/7 - í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
    insights = learning_engine.generate_learning_insights()
    
    if insights.get("top_performing_indicators"):
        top_indicators = insights["top_performing_indicators"][:3]
        print("   ğŸ† ìµœê³  ì„±ëŠ¥ ì§€í‘œë“¤:")
        for i, indicator in enumerate(top_indicators, 1):
            print(f"      {i}. {indicator['indicator']}: {indicator['weight']:.2f}")
    
    if insights.get("recommendations"):
        print(f"   ğŸ’­ ì¶”ì²œì‚¬í•­: {len(insights['recommendations'])}ê°œ")
        for rec in insights["recommendations"][:2]:
            print(f"      â€¢ {rec}")
    
    # 7. ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€
    print("ğŸ“ˆ 7/7 - ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€...")
    performance_stats = await evaluate_system_performance(tracker)
    
    print(f"   ğŸ“Š ì „ì²´ ì„±ëŠ¥ í†µê³„:")
    print(f"      â€¢ ì´ ì˜ˆì¸¡: {performance_stats['total_predictions']}ê°œ")
    print(f"      â€¢ ë°©í–¥ ì •í™•ë„: {performance_stats['direction_accuracy']:.1f}%")
    print(f"      â€¢ ê°€ê²© ì •í™•ë„: {performance_stats['price_accuracy']:.1f}%")
    print(f"      â€¢ ê±°ì§“ ì–‘ì„±ë¥ : {performance_stats['false_positive_rate']:.1f}%")
    
    # í•™ìŠµ íš¨ê³¼ í™•ì¸
    learning_effectiveness = calculate_learning_effectiveness(learning_engine)
    print(f"      â€¢ í•™ìŠµ íš¨ê³¼: {learning_effectiveness['score']:.1f}/10")
    print(f"      â€¢ ì ì‘ ë¹ˆë„: {learning_effectiveness['adaptation_frequency']}")
    
    print("\n" + "="*80)
    print("ğŸ‰ ì ì‘ì  í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)
    
    # ìµœì¢… ìš”ì•½
    return {
        "test_status": "completed",
        "failure_analysis": failure_analysis,
        "adaptation_result": adaptation_result if 'adaptation_result' in locals() else None,
        "threshold_optimization": threshold_result,
        "insights": insights,
        "performance_stats": performance_stats,
        "learning_effectiveness": learning_effectiveness
    }

async def generate_test_predictions(tracker: PredictionTracker) -> list:
    """í…ŒìŠ¤íŠ¸ìš© ì˜ˆì¸¡ ë°ì´í„° ìƒì„±"""
    test_data = []
    
    # ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì˜ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìƒì„±
    base_time = datetime.utcnow() - timedelta(days=10)
    base_price = 45000
    
    scenarios = [
        # ì„±ê³µì ì¸ ì˜ˆì¸¡ë“¤
        {"direction": "BULLISH", "prob": 85, "conf": "HIGH", "actual_dir": "BULLISH", "success": True},
        {"direction": "BEARISH", "prob": 78, "conf": "HIGH", "actual_dir": "BEARISH", "success": True},
        {"direction": "NEUTRAL", "prob": 65, "conf": "MEDIUM", "actual_dir": "NEUTRAL", "success": True},
        
        # ì‹¤íŒ¨í•œ ì˜ˆì¸¡ë“¤
        {"direction": "BULLISH", "prob": 82, "conf": "HIGH", "actual_dir": "BEARISH", "success": False},
        {"direction": "BEARISH", "prob": 75, "conf": "MEDIUM", "actual_dir": "BULLISH", "success": False},
        {"direction": "NEUTRAL", "prob": 90, "conf": "HIGH", "actual_dir": "BULLISH", "success": False},
        
        # ë‚®ì€ ì‹ ë¢°ë„ ì˜ˆì¸¡ë“¤
        {"direction": "BULLISH", "prob": 55, "conf": "LOW", "actual_dir": "NEUTRAL", "success": False},
        {"direction": "BEARISH", "prob": 58, "conf": "LOW", "actual_dir": "BULLISH", "success": False},
    ]
    
    for i, scenario in enumerate(scenarios):
        timestamp = base_time + timedelta(hours=i*6)
        current_price = base_price + (i * 500)  # ê°€ê²© ë³€ë™
        predicted_price = current_price * (1.03 if scenario["direction"] == "BULLISH" 
                                         else 0.97 if scenario["direction"] == "BEARISH" 
                                         else 1.0)
        
        # ì‹¤ì œ ê°€ê²© (ì„±ê³µ/ì‹¤íŒ¨ì— ë”°ë¼)
        if scenario["success"]:
            actual_price = predicted_price
        else:
            actual_price = current_price * (0.98 if scenario["direction"] == "BULLISH" 
                                          else 1.02 if scenario["direction"] == "BEARISH" 
                                          else 1.05)
        
        # í…ŒìŠ¤íŠ¸ ì§€í‘œ ë°ì´í„°
        indicators_data = {
            "mempool_pressure": {"value": 0.7, "signal": scenario["direction"]},
            "funding_rate": {"value": 0.002, "signal": scenario["direction"]},
            "orderbook_imbalance": {"value": 0.6, "signal": scenario["direction"]},
        }
        
        # ì˜ˆì¸¡ ê¸°ë¡
        pred_id = tracker.record_prediction(
            current_price=current_price,
            prediction_direction=scenario["direction"],
            predicted_price=predicted_price,
            probability=scenario["prob"],
            confidence=scenario["conf"],
            timeframe_hours=4,
            leading_indicators=indicators_data,
            claude_reasoning=f"Test prediction {i+1}",
            current_data={"price_data": {"current_price": current_price}}
        )
        
        # ì¦‰ì‹œ í‰ê°€ë¥¼ ìœ„í•´ ê³¼ê±° ì‹œê°„ìœ¼ë¡œ ì„¤ì •
        if pred_id > 0:
            conn = sqlite3.connect(tracker.db_path)
            cursor = conn.cursor()
            
            # ì˜ˆì¸¡ì„ ê³¼ê±°ë¡œ ì´ë™í•˜ì—¬ í‰ê°€ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
            past_timestamp = (timestamp - timedelta(hours=5)).isoformat()
            cursor.execute('''
                UPDATE predictions 
                SET timestamp = ?
                WHERE id = ?
            ''', (past_timestamp, pred_id))
            
            conn.commit()
            conn.close()
            
            test_data.append({
                "id": pred_id,
                "scenario": scenario,
                "current_price": current_price,
                "predicted_price": predicted_price,
                "actual_price": actual_price
            })
    
    # ì˜ˆì¸¡ë“¤ì„ í‰ê°€
    current_data = {"price_data": {"current_price": base_price + 4000}}
    evaluation_result = tracker.evaluate_predictions(current_data)
    
    return test_data

async def evaluate_system_performance(tracker: PredictionTracker) -> dict:
    """ì‹œìŠ¤í…œ ì „ì²´ ì„±ëŠ¥ í‰ê°€"""
    try:
        # ìµœê·¼ 7ì¼ê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
        metrics = tracker.calculate_accuracy_metrics(7)
        
        return {
            "total_predictions": metrics.get("total_predictions", 0),
            "direction_accuracy": metrics.get("direction_accuracy", 0) * 100,
            "price_accuracy": metrics.get("avg_price_accuracy", 0) * 100,
            "false_positive_rate": metrics.get("false_positive_rate", 0) * 100,
            "quality_score": metrics.get("quality_score", 0)
        }
        
    except Exception as e:
        print(f"   âš ï¸  ì„±ëŠ¥ í‰ê°€ ì˜¤ë¥˜: {e}")
        return {
            "total_predictions": 0,
            "direction_accuracy": 0,
            "price_accuracy": 0,
            "false_positive_rate": 0,
            "quality_score": 0
        }

def calculate_learning_effectiveness(learning_engine: AdaptiveLearningEngine) -> dict:
    """í•™ìŠµ íš¨ê³¼ ê³„ì‚°"""
    try:
        # ê°€ì¤‘ì¹˜ ë¶„ì‚°ë„ (ë‚®ì„ìˆ˜ë¡ ê· í˜•ì¡í˜)
        weights = list(learning_engine.learned_weights.values())
        weight_variance = sum((w - sum(weights)/len(weights))**2 for w in weights) / len(weights)
        
        # ì •ê·œí™”ëœ íš¨ê³¼ ì ìˆ˜ (0-10)
        balance_score = max(0, 5 - weight_variance)  # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        adaptation_score = min(5, len(learning_engine.learned_weights) / 4)  # ì ì‘ëœ ì§€í‘œ ìˆ˜
        
        total_score = balance_score + adaptation_score
        
        return {
            "score": total_score,
            "balance_score": balance_score,
            "adaptation_score": adaptation_score,
            "weight_variance": weight_variance,
            "adapted_indicators": len(learning_engine.learned_weights),
            "adaptation_frequency": "ì •ìƒ" if len(learning_engine.learned_weights) > 10 else "ì œí•œì "
        }
        
    except Exception as e:
        return {
            "score": 0,
            "error": str(e),
            "adaptation_frequency": "ì˜¤ë¥˜"
        }

if __name__ == "__main__":
    asyncio.run(test_learning_system())