#!/usr/bin/env python3
"""
ì ì‘ì  í•™ìŠµ ì—”ì§„
ì‹¤íŒ¨ ì›ì¸ì„ ë¶„ì„í•˜ê³  ì‹œìŠ¤í…œì„ ìŠ¤ìŠ¤ë¡œ ê°œì„ í•˜ëŠ” AI í•™ìŠµ ì‹œìŠ¤í…œ
"""

import json
import sqlite3
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
from collections import defaultdict
import statistics

class AdaptiveLearningEngine:
    """ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ê°œì„ í•˜ëŠ” ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self, db_path: str = "predictions.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self.init_learning_database()
        
        # í•™ìŠµëœ ê°€ì¤‘ì¹˜ë“¤ (ì´ˆê¸°ê°’)
        self.learned_weights = {
            "mempool_pressure": 1.4,
            "funding_rate": 1.5,
            "orderbook_imbalance": 1.2,
            "options_put_call": 1.3,
            "stablecoin_flows": 1.6,
            "fear_greed": 1.1,
            "social_volume": 0.9,
            "exchange_flows": 1.7,
            "whale_activity": 1.8,
            "miner_flows": 1.4,
            "price_momentum": 1.3,
            "volume_profile": 1.2,
            "liquidation_cascades": 1.5,
            "futures_basis": 1.4,
            "derivatives_oi": 1.3,
            "institutional_flows": 1.6,
            "correlation_breakdown": 1.1,
            "macro_indicators": 0.8,
            "regulatory_sentiment": 0.7
        }
        
        # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        self.failure_patterns = {}
        
        # ë™ì  ì„ê³„ê°’ë“¤
        self.dynamic_thresholds = {
            "confidence_threshold": 70.0,
            "volatility_threshold": 0.03,
            "correlation_threshold": 0.7
        }
    
    def init_learning_database(self):
        """í•™ìŠµ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì‹¤íŒ¨ ë¶„ì„ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS failure_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                prediction_id INTEGER NOT NULL,
                failure_type TEXT NOT NULL,
                root_cause TEXT NOT NULL,
                failed_indicators TEXT NOT NULL,
                market_condition TEXT NOT NULL,
                severity_score REAL NOT NULL,
                corrective_action TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                FOREIGN KEY (prediction_id) REFERENCES predictions (id)
            )
        ''')
        
        # ê°€ì¤‘ì¹˜ ì§„í™” í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS weight_evolution (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                indicator_name TEXT NOT NULL,
                old_weight REAL NOT NULL,
                new_weight REAL NOT NULL,
                performance_improvement REAL NOT NULL,
                market_condition TEXT NOT NULL,
                adjustment_reason TEXT NOT NULL,
                timestamp TEXT NOT NULL
            )
        ''')
        
        # í•™ìŠµ ì„±ê³¼ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                period_start TEXT NOT NULL,
                period_end TEXT NOT NULL,
                accuracy_before REAL NOT NULL,
                accuracy_after REAL NOT NULL,
                improvement_score REAL NOT NULL,
                key_insights TEXT NOT NULL,
                timestamp TEXT NOT NULL
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def analyze_prediction_failures(self, days: int = 7) -> Dict:
        """ìµœê·¼ ì‹¤íŒ¨í•œ ì˜ˆì¸¡ë“¤ì„ ë¶„ì„í•˜ì—¬ íŒ¨í„´ê³¼ ì›ì¸ íŒŒì•…"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ìµœê·¼ ì‹¤íŒ¨í•œ ì˜ˆì¸¡ë“¤ ì¡°íšŒ
            cursor.execute('''
                SELECT id, timestamp, prediction_direction, predicted_price, 
                       probability, confidence, leading_indicators, claude_reasoning,
                       actual_price, actual_direction, direction_correct, price_accuracy,
                       market_condition, volatility_regime
                FROM predictions 
                WHERE is_evaluated = TRUE 
                AND direction_correct = FALSE
                AND datetime(timestamp) >= datetime('now', '-' || ? || ' days')
                ORDER BY timestamp DESC
            ''', (days,))
            
            failed_predictions = cursor.fetchall()
            
            if not failed_predictions:
                return {"message": "ë¶„ì„í•  ì‹¤íŒ¨ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤", "failures": []}
            
            analysis_results = []
            
            for failure in failed_predictions:
                (pred_id, timestamp, pred_dir, pred_price, probability, confidence, 
                 indicators_json, reasoning, actual_price, actual_dir, correct, 
                 price_acc, market_cond, volatility) = failure
                
                # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
                failure_analysis = self._analyze_single_failure(
                    pred_id, pred_dir, pred_price, probability, confidence,
                    indicators_json, reasoning, actual_price, actual_dir,
                    market_cond, volatility
                )
                
                analysis_results.append(failure_analysis)
                
                # ì‹¤íŒ¨ ë¶„ì„ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                self._save_failure_analysis(pred_id, failure_analysis)
            
            # íŒ¨í„´ ìš”ì•½
            pattern_summary = self._summarize_failure_patterns(analysis_results)
            
            conn.close()
            
            return {
                "period_days": days,
                "total_failures": len(failed_predictions),
                "failure_analyses": analysis_results,
                "pattern_summary": pattern_summary,
                "recommended_actions": self._generate_corrective_actions(pattern_summary)
            }
            
        except Exception as e:
            self.logger.error(f"ì‹¤íŒ¨ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _analyze_single_failure(self, pred_id: int, pred_dir: str, pred_price: float, 
                               probability: float, confidence: str, indicators_json: str,
                               reasoning: str, actual_price: float, actual_dir: str,
                               market_cond: str, volatility: str) -> Dict:
        """ê°œë³„ ì‹¤íŒ¨ ì‚¬ë¡€ ì‹¬ì¸µ ë¶„ì„"""
        try:
            indicators = json.loads(indicators_json) if indicators_json else {}
            
            # ì‹¤íŒ¨ ìœ í˜• ë¶„ë¥˜
            failure_type = self._classify_failure_type(
                pred_dir, actual_dir, pred_price, actual_price, probability
            )
            
            # ê·¼ë³¸ ì›ì¸ ë¶„ì„
            root_cause = self._identify_root_cause(
                indicators, market_cond, volatility, failure_type
            )
            
            # ì‹¤íŒ¨í•œ ì§€í‘œë“¤ ì‹ë³„
            failed_indicators = self._identify_failed_indicators(
                indicators, pred_dir, actual_dir
            )
            
            # ì‹¬ê°ë„ ì ìˆ˜ (0-10)
            severity_score = self._calculate_failure_severity(
                probability, confidence, pred_price, actual_price
            )
            
            return {
                "prediction_id": pred_id,
                "failure_type": failure_type,
                "root_cause": root_cause,
                "failed_indicators": failed_indicators,
                "severity_score": severity_score,
                "market_condition": market_cond,
                "volatility_regime": volatility,
                "prediction_confidence": confidence,
                "probability": probability,
                "price_deviation_pct": abs(actual_price - pred_price) / pred_price * 100
            }
            
        except Exception as e:
            self.logger.error(f"ë‹¨ì¼ ì‹¤íŒ¨ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _classify_failure_type(self, pred_dir: str, actual_dir: str, 
                              pred_price: float, actual_price: float, 
                              probability: float) -> str:
        """ì‹¤íŒ¨ ìœ í˜• ë¶„ë¥˜"""
        price_change_pct = abs(actual_price - pred_price) / pred_price * 100
        
        if pred_dir != actual_dir and probability >= 80:
            return "HIGH_CONFIDENCE_DIRECTION_ERROR"
        elif pred_dir != actual_dir and probability < 60:
            return "LOW_CONFIDENCE_DIRECTION_ERROR"
        elif pred_dir == actual_dir and price_change_pct > 10:
            return "CORRECT_DIRECTION_WRONG_MAGNITUDE"
        elif pred_dir == "NEUTRAL" and price_change_pct > 5:
            return "FALSE_NEUTRAL_PREDICTION"
        else:
            return "GENERAL_PREDICTION_ERROR"
    
    def _identify_root_cause(self, indicators: Dict, market_cond: str, 
                            volatility: str, failure_type: str) -> str:
        """ê·¼ë³¸ ì›ì¸ ì‹ë³„"""
        causes = []
        
        # ì§€í‘œ ì‹ ë¢°ë„ ë¶„ì„
        if indicators:
            low_confidence_indicators = [
                name for name, data in indicators.items() 
                if isinstance(data, dict) and data.get('confidence', 100) < 50
            ]
            if len(low_confidence_indicators) > 5:
                causes.append("INDICATOR_RELIABILITY_ISSUE")
        
        # ì‹œì¥ ìƒí™© ë¶„ì„
        if market_cond == "HIGH_VOLATILITY" and failure_type.startswith("HIGH_CONFIDENCE"):
            causes.append("VOLATILITY_UNDERESTIMATION")
        
        if volatility == "REGIME_CHANGE":
            causes.append("MARKET_REGIME_SHIFT")
        
        # ì™¸ë¶€ ìš”ì¸
        current_hour = datetime.now().hour
        if current_hour in [14, 15, 21, 22]:  # ë¯¸êµ­/ì•„ì‹œì•„ ì‹œì¥ ê²¹ì¹˜ëŠ” ì‹œê°„
            causes.append("CROSS_MARKET_INTERFERENCE")
        
        return "|".join(causes) if causes else "UNKNOWN_CAUSE"
    
    def _identify_failed_indicators(self, indicators: Dict, 
                                   pred_dir: str, actual_dir: str) -> List[str]:
        """ì‹¤íŒ¨ì— ê¸°ì—¬í•œ ì§€í‘œë“¤ ì‹ë³„"""
        failed = []
        
        for indicator_name, data in indicators.items():
            if isinstance(data, dict):
                signal = data.get('signal', 'NEUTRAL')
                confidence = data.get('confidence', 50)
                
                # ì˜ˆì¸¡ ë°©í–¥ê³¼ ë°˜ëŒ€ ì‹ í˜¸ë¥¼ ì¤€ ì§€í‘œë“¤
                if ((pred_dir == "BULLISH" and signal == "BEARISH") or
                    (pred_dir == "BEARISH" and signal == "BULLISH")):
                    if confidence > 70:  # ë†’ì€ í™•ì‹ ìœ¼ë¡œ ì˜ëª»ëœ ì‹ í˜¸
                        failed.append(indicator_name)
        
        return failed
    
    def _calculate_failure_severity(self, probability: float, confidence: str,
                                   pred_price: float, actual_price: float) -> float:
        """ì‹¤íŒ¨ ì‹¬ê°ë„ ê³„ì‚° (0-10)"""
        severity = 0.0
        
        # í™•ë¥  ê¸°ë°˜ (ë†’ì€ í™•ë¥ ì¼ìˆ˜ë¡ ì‹¤íŒ¨ì‹œ ì‹¬ê°)
        severity += (probability / 100) * 4
        
        # ì‹ ë¢°ë„ ê¸°ë°˜
        confidence_multiplier = {"HIGH": 3, "MEDIUM": 2, "LOW": 1}
        severity += confidence_multiplier.get(confidence, 1)
        
        # ê°€ê²© ì˜¤ì°¨ ê¸°ë°˜
        price_error_pct = abs(actual_price - pred_price) / pred_price * 100
        severity += min(price_error_pct / 10, 3)  # ìµœëŒ€ 3ì 
        
        return min(severity, 10.0)
    
    def adapt_indicator_weights(self, analysis_results: List[Dict]) -> Dict:
        """ì‹¤íŒ¨ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€í‘œ ê°€ì¤‘ì¹˜ ì ì‘ì  ì¡°ì •"""
        try:
            adjustments = {}
            
            # ì‹¤íŒ¨í•œ ì§€í‘œë“¤ ìˆ˜ì§‘
            failed_indicator_counts = defaultdict(int)
            total_failures = len(analysis_results)
            
            for analysis in analysis_results:
                failed_indicators = analysis.get("failed_indicators", [])
                severity = analysis.get("severity_score", 0)
                
                for indicator in failed_indicators:
                    failed_indicator_counts[indicator] += severity
            
            # ê°€ì¤‘ì¹˜ ì¡°ì • ê³„ì‚°
            for indicator, failure_score in failed_indicator_counts.items():
                if indicator in self.learned_weights:
                    old_weight = self.learned_weights[indicator]
                    
                    # ì‹¤íŒ¨ ë¹ˆë„ì™€ ì‹¬ê°ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ê°ì†Œ
                    penalty_factor = min(failure_score / total_failures, 0.3)
                    new_weight = old_weight * (1 - penalty_factor)
                    
                    # ìµœì†Œ ê°€ì¤‘ì¹˜ ë³´ì¥
                    new_weight = max(new_weight, 0.3)
                    
                    adjustments[indicator] = {
                        "old_weight": old_weight,
                        "new_weight": new_weight,
                        "change_pct": ((new_weight - old_weight) / old_weight) * 100,
                        "failure_score": failure_score
                    }
                    
                    self.learned_weights[indicator] = new_weight
            
            # ì„±ê³µì ì¸ ì§€í‘œë“¤ ê°€ì¤‘ì¹˜ ì¦ê°€
            self._boost_successful_indicators(analysis_results)
            
            # ì¡°ì • ê²°ê³¼ ì €ì¥
            self._save_weight_adjustments(adjustments)
            
            return {
                "total_adjustments": len(adjustments),
                "weight_changes": adjustments,
                "adaptation_summary": self._summarize_adaptation(adjustments)
            }
            
        except Exception as e:
            self.logger.error(f"ê°€ì¤‘ì¹˜ ì ì‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _boost_successful_indicators(self, analysis_results: List[Dict]):
        """ì„±ê³µì ì¸ ì§€í‘œë“¤ì˜ ê°€ì¤‘ì¹˜ ì¦ê°€"""
        # ìµœê·¼ ì„±ê³µí•œ ì˜ˆì¸¡ë“¤ì—ì„œ ê¸°ì—¬ë„ ë†’ì€ ì§€í‘œë“¤ ì°¾ê¸°
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT leading_indicators FROM predictions 
                WHERE is_evaluated = TRUE 
                AND direction_correct = TRUE
                AND datetime(timestamp) >= datetime('now', '-7 days')
            ''')
            
            successful_predictions = cursor.fetchall()
            
            successful_indicator_scores = defaultdict(float)
            
            for (indicators_json,) in successful_predictions:
                if indicators_json:
                    indicators = json.loads(indicators_json)
                    for name, data in indicators.items():
                        if isinstance(data, dict):
                            confidence = data.get('confidence', 50)
                            successful_indicator_scores[name] += confidence / 100
            
            # ì„±ê³µ ì§€í‘œë“¤ ê°€ì¤‘ì¹˜ ì¦ê°€
            for indicator, success_score in successful_indicator_scores.items():
                if indicator in self.learned_weights and success_score > 3:
                    boost_factor = min(success_score / 10, 0.1)  # ìµœëŒ€ 10% ì¦ê°€
                    self.learned_weights[indicator] *= (1 + boost_factor)
                    self.learned_weights[indicator] = min(self.learned_weights[indicator], 2.5)
            
            conn.close()
            
        except Exception as e:
            self.logger.error(f"ì„±ê³µ ì§€í‘œ ë¶€ìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    def optimize_dynamic_thresholds(self) -> Dict:
        """ë™ì  ì„ê³„ê°’ ìµœì í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ìµœê·¼ ì˜ˆì¸¡ ì„±ê³¼ ë¶„ì„
            cursor.execute('''
                SELECT probability, confidence, direction_correct, price_accuracy,
                       market_condition, volatility_regime
                FROM predictions 
                WHERE is_evaluated = TRUE 
                AND datetime(timestamp) >= datetime('now', '-14 days')
            ''')
            
            results = cursor.fetchall()
            
            if len(results) < 10:
                return {"message": "ìµœì í™”ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # í™•ë¥ ë³„ ì •í™•ë„ ë¶„ì„
            probability_accuracies = defaultdict(list)
            for prob, conf, correct, price_acc, market, vol in results:
                prob_range = int(prob // 10) * 10  # 10% ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
                probability_accuracies[prob_range].append(1.0 if correct else 0.0)
            
            # ìµœì  í™•ë¥  ì„ê³„ê°’ ì°¾ê¸°
            best_threshold = 70
            best_score = 0
            
            for threshold in range(60, 90, 5):
                high_prob_predictions = [r for r in results if r[0] >= threshold]
                if high_prob_predictions:
                    accuracy = sum(1 for r in high_prob_predictions if r[2]) / len(high_prob_predictions)
                    # ì •í™•ë„ì™€ ì˜ˆì¸¡ ìˆ˜ì˜ ê· í˜•
                    score = accuracy * min(len(high_prob_predictions) / len(results), 1)
                    if score > best_score:
                        best_score = score
                        best_threshold = threshold
            
            # ì„ê³„ê°’ ì—…ë°ì´íŠ¸
            old_threshold = self.dynamic_thresholds["confidence_threshold"]
            self.dynamic_thresholds["confidence_threshold"] = best_threshold
            
            conn.close()
            
            return {
                "old_confidence_threshold": old_threshold,
                "new_confidence_threshold": best_threshold,
                "expected_accuracy_improvement": (best_score - 0.7) * 100,
                "optimization_date": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì„ê³„ê°’ ìµœì í™” ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def generate_learning_insights(self) -> Dict:
        """í•™ìŠµ ê²°ê³¼ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ìµœê·¼ í•™ìŠµ ì„±ê³¼
            cursor.execute('''
                SELECT * FROM learning_performance 
                ORDER BY timestamp DESC LIMIT 1
            ''')
            
            latest_performance = cursor.fetchone()
            
            # ê°€ì¤‘ì¹˜ ì§„í™” íŠ¸ë Œë“œ
            cursor.execute('''
                SELECT indicator_name, AVG(performance_improvement) as avg_improvement
                FROM weight_evolution 
                WHERE datetime(timestamp) >= datetime('now', '-30 days')
                GROUP BY indicator_name
                ORDER BY avg_improvement DESC
            ''')
            
            weight_trends = cursor.fetchall()
            
            # ì‹¤íŒ¨ íŒ¨í„´ ë¹ˆë„
            cursor.execute('''
                SELECT failure_type, COUNT(*) as count, AVG(severity_score) as avg_severity
                FROM failure_analysis 
                WHERE datetime(timestamp) >= datetime('now', '-30 days')
                GROUP BY failure_type
                ORDER BY count DESC
            ''')
            
            failure_patterns = cursor.fetchall()
            
            conn.close()
            
            insights = {
                "learning_summary": {
                    "latest_performance": latest_performance,
                    "total_weight_adjustments": len(self.learned_weights),
                    "avg_weight": statistics.mean(self.learned_weights.values()),
                    "weight_std": statistics.stdev(self.learned_weights.values()) if len(self.learned_weights) > 1 else 0
                },
                "top_performing_indicators": [
                    {"indicator": name, "weight": weight} 
                    for name, weight in sorted(self.learned_weights.items(), 
                                             key=lambda x: x[1], reverse=True)[:5]
                ],
                "improvement_trends": [
                    {"indicator": name, "avg_improvement": improvement} 
                    for name, improvement in weight_trends[:5]
                ],
                "common_failure_patterns": [
                    {"type": ftype, "frequency": count, "avg_severity": severity}
                    for ftype, count, severity in failure_patterns
                ],
                "current_thresholds": self.dynamic_thresholds.copy(),
                "recommendations": self._generate_learning_recommendations()
            }
            
            return insights
            
        except Exception as e:
            self.logger.error(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
    
    def _generate_learning_recommendations(self) -> List[str]:
        """í•™ìŠµ ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ê°€ì¤‘ì¹˜ ë¶„ì‚°ë„ ì²´í¬
        weight_std = statistics.stdev(self.learned_weights.values()) if len(self.learned_weights) > 1 else 0
        if weight_std > 0.5:
            recommendations.append("ì§€í‘œê°„ ê°€ì¤‘ì¹˜ í¸ì°¨ê°€ í½ë‹ˆë‹¤. ê· í˜• ì¡°ì •ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # ì„ê³„ê°’ ì²´í¬
        if self.dynamic_thresholds["confidence_threshold"] > 85:
            recommendations.append("ì‹ ë¢°ë„ ì„ê³„ê°’ì´ ë„ˆë¬´ ë†’ì•„ ì˜ˆì¸¡ ë¹ˆë„ê°€ ì¤„ì–´ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ìµœê³  ì„±ëŠ¥ ì§€í‘œ
        top_indicator = max(self.learned_weights.items(), key=lambda x: x[1])
        if top_indicator[1] > 2.0:
            recommendations.append(f"{top_indicator[0]} ì§€í‘œì˜ ì„±ëŠ¥ì´ ë§¤ìš° ìš°ìˆ˜í•©ë‹ˆë‹¤. ê´€ë ¨ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™•ì¥ ê³ ë ¤í•˜ì„¸ìš”.")
        
        return recommendations
    
    def _save_failure_analysis(self, pred_id: int, analysis: Dict):
        """ì‹¤íŒ¨ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO failure_analysis 
                (prediction_id, failure_type, root_cause, failed_indicators, 
                 market_condition, severity_score, corrective_action, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                pred_id,
                analysis.get("failure_type", ""),
                analysis.get("root_cause", ""),
                json.dumps(analysis.get("failed_indicators", [])),
                analysis.get("market_condition", ""),
                analysis.get("severity_score", 0),
                "WEIGHT_ADJUSTMENT",
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"ì‹¤íŒ¨ ë¶„ì„ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _save_weight_adjustments(self, adjustments: Dict):
        """ê°€ì¤‘ì¹˜ ì¡°ì • ê¸°ë¡ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for indicator, adjustment in adjustments.items():
                cursor.execute('''
                    INSERT INTO weight_evolution 
                    (indicator_name, old_weight, new_weight, performance_improvement,
                     market_condition, adjustment_reason, timestamp)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    indicator,
                    adjustment["old_weight"],
                    adjustment["new_weight"],
                    adjustment["change_pct"],
                    "MIXED",
                    f"Failure-based adjustment: {adjustment['failure_score']:.2f} severity",
                    datetime.now().isoformat()
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"ê°€ì¤‘ì¹˜ ì¡°ì • ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _summarize_failure_patterns(self, analyses: List[Dict]) -> Dict:
        """ì‹¤íŒ¨ íŒ¨í„´ ìš”ì•½"""
        if not analyses:
            return {}
        
        failure_types = defaultdict(int)
        root_causes = defaultdict(int)
        total_severity = 0
        
        for analysis in analyses:
            failure_types[analysis.get("failure_type", "UNKNOWN")] += 1
            causes = analysis.get("root_cause", "").split("|")
            for cause in causes:
                if cause.strip():
                    root_causes[cause.strip()] += 1
            total_severity += analysis.get("severity_score", 0)
        
        return {
            "most_common_failure_type": max(failure_types.items(), key=lambda x: x[1])[0],
            "failure_type_distribution": dict(failure_types),
            "root_cause_distribution": dict(root_causes),
            "average_severity": total_severity / len(analyses),
            "critical_failures": sum(1 for a in analyses if a.get("severity_score", 0) >= 8)
        }
    
    def _generate_corrective_actions(self, pattern_summary: Dict) -> List[str]:
        """êµì • ì¡°ì¹˜ ìƒì„±"""
        actions = []
        
        common_failure = pattern_summary.get("most_common_failure_type", "")
        if "HIGH_CONFIDENCE" in common_failure:
            actions.append("ë†’ì€ í™•ì‹  ì˜ˆì¸¡ì˜ ì„ê³„ê°’ì„ ìƒí–¥ ì¡°ì •")
        
        if "VOLATILITY" in str(pattern_summary.get("root_cause_distribution", {})):
            actions.append("ë³€ë™ì„± ì§€í‘œì˜ ê°€ì¤‘ì¹˜ ì¦ê°€")
        
        if pattern_summary.get("average_severity", 0) > 7:
            actions.append("ì „ì²´ì ì¸ ì˜ˆì¸¡ ë³´ìˆ˜ì„± ì¦ê°€")
        
        return actions
    
    def _summarize_adaptation(self, adjustments: Dict) -> str:
        """ì ì‘ ê²°ê³¼ ìš”ì•½"""
        if not adjustments:
            return "ì¡°ì •ëœ ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤"
        
        total_changes = len(adjustments)
        avg_change = statistics.mean([abs(adj["change_pct"]) for adj in adjustments.values()])
        
        return f"{total_changes}ê°œ ì§€í‘œ ê°€ì¤‘ì¹˜ ì¡°ì • ì™„ë£Œ, í‰ê·  ë³€í™”ìœ¨: {avg_change:.1f}%"

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_learning_engine():
    """í•™ìŠµ ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  ì ì‘ì  í•™ìŠµ ì—”ì§„ í…ŒìŠ¤íŠ¸...")
    
    engine = AdaptiveLearningEngine()
    
    # ì‹¤íŒ¨ ë¶„ì„
    failure_analysis = engine.analyze_prediction_failures(7)
    print(f"ì‹¤íŒ¨ ë¶„ì„: {failure_analysis}")
    
    # ê°€ì¤‘ì¹˜ ì ì‘
    if failure_analysis.get("failure_analyses"):
        adaptation_result = engine.adapt_indicator_weights(failure_analysis["failure_analyses"])
        print(f"ê°€ì¤‘ì¹˜ ì ì‘: {adaptation_result}")
    
    # ì„ê³„ê°’ ìµœì í™”
    threshold_optimization = engine.optimize_dynamic_thresholds()
    print(f"ì„ê³„ê°’ ìµœì í™”: {threshold_optimization}")
    
    # í•™ìŠµ ì¸ì‚¬ì´íŠ¸
    insights = engine.generate_learning_insights()
    print(f"í•™ìŠµ ì¸ì‚¬ì´íŠ¸: {insights}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_learning_engine())