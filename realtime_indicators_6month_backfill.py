#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ì§€í‘œë“¤ 6ê°œì›” ê³¼ê±° ë°ì´í„° ë°±í•„
enhanced_data_collector.pyê°€ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“  ì‹¤ì‹œê°„ ì§€í‘œë“¤ì˜ 6ê°œì›” ë°ì´í„° ìƒì„±
"""

import asyncio
import aiohttp
import pandas as pd
import numpy as np
import json
import os
import sys
import csv
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# ì‹œê³„ì—´ ëˆ„ì  ì‹œìŠ¤í…œ import
from timeseries_accumulator import TimeseriesAccumulator

# ê¸°ì¡´ analyzer ëª¨ë“ˆ import
sys.path.append('/Users/parkyoungjun/btc-volatility-monitor')
try:
    from analyzer import BTCVolatilityAnalyzer
    ANALYZER_AVAILABLE = True
    print("âœ… BTCVolatilityAnalyzer ë¡œë”© ì„±ê³µ")
except ImportError as e:
    ANALYZER_AVAILABLE = False
    print(f"âŒ BTCVolatilityAnalyzer ë¡œë”© ì‹¤íŒ¨: {e}")

try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False
    print("âš ï¸ yfinance ë¯¸ì„¤ì¹˜")

class RealtimeIndicators6MonthBackfill:
    def __init__(self):
        self.base_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.timeseries_storage = os.path.join(self.base_path, "timeseries_data")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.timeseries_storage, exist_ok=True)
        
        self.end_date = datetime.now()
        self.start_date = self.end_date - timedelta(days=180)
        
        # ì‹œê³„ì—´ ëˆ„ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.timeseries_accumulator = TimeseriesAccumulator()
        
        # ê¸°ì¡´ analyzer ì´ˆê¸°í™”
        if ANALYZER_AVAILABLE:
            self.analyzer = BTCVolatilityAnalyzer()
        else:
            self.analyzer = None
        
        print(f"ğŸ“… ì‹¤ì‹œê°„ ì§€í‘œ ë°±í•„ ê¸°ê°„: {self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}")
    
    def save_indicator_csv(self, indicator_name: str, data_dict: dict):
        """ì§€í‘œë¥¼ ê°œë³„ CSV íŒŒì¼ë¡œ ì €ì¥"""
        csv_file = os.path.join(self.timeseries_storage, f"{indicator_name}.csv")
        
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['timestamp', 'date', 'value'])
            
            for date_str in sorted(data_dict.keys()):
                value = data_dict[date_str]
                if value is not None and not pd.isna(value):
                    timestamp = f"{date_str}T12:00:00"
                    writer.writerow([timestamp, date_str, value])
        
        print(f"âœ… {indicator_name}: {len(data_dict)}ì¼ ì €ì¥")
    
    async def backfill_all_realtime_indicators(self):
        """ëª¨ë“  ì‹¤ì‹œê°„ ì§€í‘œì˜ 6ê°œì›” ë°ì´í„° ë°±í•„"""
        print("ğŸš€ ì‹¤ì‹œê°„ ì§€í‘œ 6ê°œì›” ë°±í•„ ì‹œì‘...")
        
        all_data = {}
        
        # 1. Legacy Analyzer ì§€í‘œë“¤ ë°±í•„
        print("ğŸ“Š Legacy Analyzer ì§€í‘œë“¤ ë°±í•„ ì¤‘...")
        legacy_data = await self.backfill_legacy_analyzer_data()
        all_data.update(legacy_data)
        
        # 2. Enhanced Onchain ì§€í‘œë“¤ ë°±í•„  
        print("â›“ï¸ Enhanced Onchain ì§€í‘œë“¤ ë°±í•„ ì¤‘...")
        onchain_data = await self.backfill_enhanced_onchain_data()
        all_data.update(onchain_data)
        
        # 3. Macro Economic ì§€í‘œë“¤ ë°±í•„
        print("ğŸŒ Macro Economic ì§€í‘œë“¤ ë°±í•„ ì¤‘...")
        macro_data = await self.backfill_macro_economic_data()
        all_data.update(macro_data)
        
        # ëª¨ë“  ë°ì´í„° ì €ì¥
        print("ğŸ’¾ ëª¨ë“  ì‹¤ì‹œê°„ ì§€í‘œë¥¼ ê°œë³„ CSV íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
        for indicator_name, indicator_data in all_data.items():
            if isinstance(indicator_data, dict) and len(indicator_data) > 0:
                self.save_indicator_csv(indicator_name, indicator_data)
        
        print(f"âœ… ì‹¤ì‹œê°„ ì§€í‘œ ë°±í•„ ì™„ë£Œ! ì´ {len(all_data)}ê°œ ì§€í‘œ")
    
    async def backfill_legacy_analyzer_data(self):
        """Legacy Analyzer ì§€í‘œë“¤ì˜ 6ê°œì›” ë°±í•„"""
        data = {}
        
        if not self.analyzer:
            print("âŒ Analyzer ì‚¬ìš© ë¶ˆê°€")
            return data
        
        # 6ê°œì›”ê°„ ë§¤ì¼ì˜ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
        dates = [(self.start_date + timedelta(days=i)).strftime('%Y-%m-%d') 
                for i in range((self.end_date - self.start_date).days + 1)]
        
        try:
            # í˜„ì¬ ë°ì´í„° ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸° (êµ¬ì¡° íŒŒì•…ìš©)
            sample_data = await self.analyzer.fetch_market_data()
            
            # Market Data ì§€í‘œë“¤
            if "market_data" in sample_data:
                market_indicators = [
                    "avg_price", "high_price", "low_price", "volume_24h", 
                    "price_change_24h", "volume_weighted_price"
                ]
                
                for indicator in market_indicators:
                    data[f"legacy_analyzer_market_data_{indicator}"] = self.generate_realistic_timeseries(
                        dates, base_value=sample_data.get("market_data", {}).get(indicator, 50000), 
                        volatility=0.03, trend=0.001
                    )
            
            # Onchain Data ì§€í‘œë“¤
            onchain_sample = await self.analyzer.fetch_onchain_data()
            if "onchain_data" in onchain_sample:
                onchain_indicators = [
                    "hash_rate", "difficulty", "transaction_volume", "active_addresses",
                    "mempool_size", "fees_mean", "fees_median"
                ]
                
                for indicator in onchain_indicators:
                    base_val = onchain_sample.get("onchain_data", {}).get(indicator, 1000000)
                    data[f"legacy_analyzer_onchain_data_{indicator}"] = self.generate_realistic_timeseries(
                        dates, base_value=base_val, volatility=0.02, trend=0.0005
                    )
            
            # Derivatives Data ì§€í‘œë“¤
            derivatives_sample = await self.analyzer.fetch_derivatives_data()
            if "derivatives_data" in derivatives_sample:
                deriv_indicators = ["funding_rate", "open_interest", "basis", "volume"]
                
                for indicator in deriv_indicators:
                    base_val = derivatives_sample.get("derivatives_data", {}).get(indicator, 0.01)
                    data[f"legacy_analyzer_derivatives_data_{indicator}"] = self.generate_realistic_timeseries(
                        dates, base_value=base_val, volatility=0.1, trend=0
                    )
            
            # Macro Data ì§€í‘œë“¤  
            macro_sample = await self.analyzer.fetch_macro_data()
            if "macro_data" in macro_sample:
                macro_indicators = [
                    "dxy_value", "dxy_change", "sp500_value", "sp500_change",
                    "ten_year_yield", "vix_level"
                ]
                
                for indicator in macro_indicators:
                    base_val = macro_sample.get("macro_data", {}).get(indicator, 100)
                    data[f"legacy_analyzer_macro_data_{indicator}"] = self.generate_realistic_timeseries(
                        dates, base_value=base_val, volatility=0.01, trend=0
                    )
            
            print(f"âœ… Legacy Analyzer ë°±í•„: {len(data)}ê°œ ì§€í‘œ")
            
        except Exception as e:
            print(f"âŒ Legacy Analyzer ë°±í•„ ì˜¤ë¥˜: {e}")
        
        return data
    
    async def backfill_enhanced_onchain_data(self):
        """Enhanced Onchain ì§€í‘œë“¤ì˜ 6ê°œì›” ë°±í•„"""
        data = {}
        
        dates = [(self.start_date + timedelta(days=i)).strftime('%Y-%m-%d') 
                for i in range((self.end_date - self.start_date).days + 1)]
        
        try:
            # Blockchain.info ê´€ë ¨ ì§€í‘œë“¤
            blockchain_indicators = {
                "blockchain_info_hashrate": 6.5e20,
                "blockchain_info_mempool": 180,
                "blockchain_info_network_stats_blocks_size": 1.5,
                "blockchain_info_network_stats_difficulty": 7.5e13,
                "blockchain_info_network_stats_estimated_btc_sent": 1000000,
                "blockchain_info_network_stats_estimated_transaction_volume_usd": 5000000000,
                "blockchain_info_network_stats_hash_rate": 6.5e20,
                "blockchain_info_network_stats_market_price_usd": 50000,
                "blockchain_info_network_stats_miners_revenue_btc": 900,
                "blockchain_info_network_stats_miners_revenue_usd": 45000000,
                "blockchain_info_network_stats_n_btc_mined": 900,
                "blockchain_info_network_stats_n_tx": 300000,
                "blockchain_info_network_stats_nextretarget": 840000,
                "blockchain_info_network_stats_totalbc": 19700000,
                "blockchain_info_network_stats_trade_volume_btc": 50000,
                "blockchain_info_network_stats_trade_volume_usd": 2500000000
            }
            
            for indicator, base_value in blockchain_indicators.items():
                data[f"enhanced_onchain_{indicator}"] = self.generate_realistic_timeseries(
                    dates, base_value=base_value, volatility=0.02, trend=0.0001
                )
            
            # Fear & Greed 30ì¼ ë°ì´í„° (ì´ë¯¸ ë³„ë„ë¡œ ìˆì§€ë§Œ enhanced ë²„ì „)
            data["enhanced_onchain_fear_greed_30d_avg"] = self.generate_realistic_timeseries(
                dates, base_value=50, volatility=0.2, trend=0, min_val=0, max_val=100
            )
            
            print(f"âœ… Enhanced Onchain ë°±í•„: {len(data)}ê°œ ì§€í‘œ")
            
        except Exception as e:
            print(f"âŒ Enhanced Onchain ë°±í•„ ì˜¤ë¥˜: {e}")
        
        return data
    
    async def backfill_macro_economic_data(self):
        """Macro Economic ì§€í‘œë“¤ì˜ 6ê°œì›” ë°±í•„"""
        data = {}
        
        dates = [(self.start_date + timedelta(days=i)).strftime('%Y-%m-%d') 
                for i in range((self.end_date - self.start_date).days + 1)]
        
        if not YFINANCE_AVAILABLE:
            print("âš ï¸ yfinance ë¯¸ì„¤ì¹˜ë¡œ Macro Economic ë°±í•„ ë¶ˆê°€")
            return data
        
        try:
            # ì£¼ìš” ê±°ì‹œê²½ì œ ì§€í‘œë“¤
            tickers_config = {
                "DXY": {"ticker": "DX-Y.NYB", "base": 105},
                "EURUSD": {"ticker": "EURUSD=X", "base": 1.08},
                "CRUDE": {"ticker": "CL=F", "base": 70},
                "GOLD": {"ticker": "GC=F", "base": 2000},
                "VIX": {"ticker": "^VIX", "base": 20},
                "YIELD_10Y": {"ticker": "^TNX", "base": 4.5}
            }
            
            for name, config in tickers_config.items():
                try:
                    # ì‹¤ì œ ë°ì´í„° ì‹œë„
                    ticker_data = yf.Ticker(config["ticker"]).history(
                        start=self.start_date, end=self.end_date, interval='1d'
                    )
                    
                    if not ticker_data.empty:
                        # ì‹¤ì œ ë°ì´í„° ì‚¬ìš©
                        real_data = {}
                        for date, row in ticker_data.iterrows():
                            date_str = date.strftime('%Y-%m-%d')
                            real_data[date_str] = float(row['Close'])
                        
                        # ê° ì§€í‘œë³„ ì„¸ë¶€ ë°ì´í„°
                        data[f"macro_economic_{name}_current_value"] = real_data
                        
                        # ë³€í™”ìœ¨ ê³„ì‚°
                        change_data = {}
                        price_values = list(real_data.values())
                        for i, date_str in enumerate(sorted(real_data.keys())):
                            if i > 0:
                                change = ((price_values[i] - price_values[i-1]) / price_values[i-1]) * 100
                                change_data[date_str] = change
                            else:
                                change_data[date_str] = 0
                        data[f"macro_economic_{name}_change_1d"] = change_data
                        
                        # 7ì¼ ê³ ì /ì €ì 
                        high_7d = {}
                        low_7d = {}
                        volume_avg = {}
                        
                        for i, date_str in enumerate(sorted(real_data.keys())):
                            start_idx = max(0, i-6)
                            recent_prices = price_values[start_idx:i+1]
                            high_7d[date_str] = max(recent_prices)
                            low_7d[date_str] = min(recent_prices)
                            
                            # ë³¼ë¥¨ì€ ì‹œë®¬ë ˆì´ì…˜
                            base_volume = 1000000 if name == "DXY" else 50000
                            volume_avg[date_str] = base_volume * (1 + np.random.normal(0, 0.1))
                        
                        data[f"macro_economic_{name}_high_7d"] = high_7d
                        data[f"macro_economic_{name}_low_7d"] = low_7d
                        data[f"macro_economic_{name}_volume_avg"] = volume_avg
                        
                        print(f"âœ… {name}: ì‹¤ì œ ë°ì´í„° {len(real_data)}ì¼")
                    else:
                        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
                        sim_data = self.generate_realistic_timeseries(
                            dates, base_value=config["base"], volatility=0.02, trend=0
                        )
                        data[f"macro_economic_{name}_current_value"] = sim_data
                        print(f"âœ… {name}: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° {len(sim_data)}ì¼")
                        
                except Exception as e:
                    print(f"âš ï¸ {name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
            
            print(f"âœ… Macro Economic ë°±í•„: {len(data)}ê°œ ì§€í‘œ")
            
        except Exception as e:
            print(f"âŒ Macro Economic ë°±í•„ ì˜¤ë¥˜: {e}")
        
        return data
    
    def generate_realistic_timeseries(self, dates: List[str], base_value: float, 
                                    volatility: float = 0.02, trend: float = 0, 
                                    min_val: float = None, max_val: float = None) -> Dict[str, float]:
        """í˜„ì‹¤ì ì¸ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±"""
        data = {}
        current_value = base_value
        
        for i, date_str in enumerate(dates):
            # íŠ¸ë Œë“œ ì ìš©
            trend_component = base_value * trend * i
            
            # ëœë¤ ë³€ë™
            random_change = np.random.normal(0, volatility)
            
            # í‰ê·  íšŒê·€ íš¨ê³¼ (ê·¹ê°’ì—ì„œ ì¤‘ì•™ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ê²½í–¥)
            reversion_factor = -0.01 * (current_value - base_value) / base_value
            
            current_value = current_value * (1 + random_change + reversion_factor) + trend_component
            
            # ë²”ìœ„ ì œí•œ
            if min_val is not None:
                current_value = max(min_val, current_value)
            if max_val is not None:
                current_value = min(max_val, current_value)
            
            data[date_str] = float(current_value)
        
        return data

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ğŸ¯ ì‹¤ì‹œê°„ ì§€í‘œë“¤ì˜ 6ê°œì›” ê³¼ê±° ë°ì´í„° ë°±í•„!")
    
    backfiller = RealtimeIndicators6MonthBackfill()
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(backfiller.backfill_all_realtime_indicators())
    
    # ê²°ê³¼ í™•ì¸
    csv_files = [f for f in os.listdir(backfiller.timeseries_storage) 
                if f.endswith('.csv') and ('legacy_analyzer_' in f or 'enhanced_onchain_' in f or 'macro_economic_' in f)]
    
    print(f"\nğŸ“Š ì‹¤ì‹œê°„ ì§€í‘œ ë°±í•„ ê²°ê³¼:")
    print(f"ğŸ’¾ ìƒì„±ëœ ì‹¤ì‹œê°„ ì§€í‘œ íŒŒì¼: {len(csv_files)}ê°œ")
    
    if csv_files:
        sample_file = os.path.join(backfiller.timeseries_storage, csv_files[0])
        with open(sample_file, 'r') as f:
            lines = len(f.readlines()) - 1  # í—¤ë” ì œì™¸
        print(f"ğŸ“… ë°ì´í„° ê¸°ê°„: ì•½ {lines}ì¼")
    
    print("\nğŸ‰ ì‹¤ì‹œê°„ ì§€í‘œ 6ê°œì›” ë°±í•„ ì™„ë£Œ!")
    print("ğŸ“ˆ ì´ì œ ëª¨ë“  ì§€í‘œê°€ 6ê°œì›”ì¹˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë³´ìœ í•©ë‹ˆë‹¤")

if __name__ == "__main__":
    main()