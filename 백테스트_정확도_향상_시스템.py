#!/usr/bin/env python3
"""
ğŸ¯ ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ ì‹œìŠ¤í…œ
- í˜„ì¬ 78.26% â†’ 85%+ ëª©í‘œ
- ê³ ê¸‰ ë°±í…ŒìŠ¤íŠ¸ ê¸°ë²•ìœ¼ë¡œ ì •í™•ë„ ê·¹ëŒ€í™”
- 7ê°€ì§€ í˜ì‹ ì  ì•„ì´ë””ì–´ êµ¬í˜„
"""

import numpy as np
import pandas as pd
import warnings
import joblib
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPRegressor

warnings.filterwarnings('ignore')

class AdvancedBacktestAccuracySystem:
    """ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.data_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.current_accuracy = 78.26  # í˜„ì¬ ë‹¬ì„±í•œ ì •í™•ë„
        self.target_accuracy = 85.0    # ëª©í‘œ ì •í™•ë„
        
        # í–¥ìƒ ì•„ì´ë””ì–´ë³„ ê²°ê³¼ ì €ì¥
        self.improvement_results = {}
        self.best_accuracy = 0.0
        
    def load_current_data(self) -> pd.DataFrame:
        """í˜„ì¬ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ¯ ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ ì‹œìŠ¤í…œ")
        print("="*70)
        print(f"ğŸš€ í˜„ì¬: {self.current_accuracy}% â†’ ëª©í‘œ: {self.target_accuracy}%")
        print("="*70)
        
        csv_path = os.path.join(self.data_path, "ai_optimized_3month_data", "ai_matrix_complete.csv")
        df = pd.read_csv(csv_path)
        
        # ì „ì²˜ë¦¬
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        df_clean = df[numeric_columns].copy()
        df_clean = df_clean.ffill().bfill().fillna(0)
        df_clean = df_clean.replace([np.inf, -np.inf], 0)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df_clean.shape}")
        return df_clean
    
    def idea_1_market_regime_detection(self, df: pd.DataFrame) -> Dict:
        """ğŸ’¡ ì•„ì´ë””ì–´ 1: ì‹œì¥ êµ­ë©´ë³„ ë§ì¶¤ ì˜ˆì¸¡"""
        print("\nğŸ’¡ ì•„ì´ë””ì–´ 1: ì‹œì¥ êµ­ë©´(ë¶ˆì¥/íš¡ë³´/ì•½ì„¸ì¥) ë³„ ë§ì¶¤ ì˜ˆì¸¡")
        print("-" * 60)
        
        btc_col = df.columns[0]
        btc_price = df[btc_col]
        
        # ì‹œì¥ êµ­ë©´ ì •ì˜
        returns_7d = btc_price.pct_change(168).fillna(0)  # 7ì¼ ìˆ˜ìµë¥ 
        volatility_7d = btc_price.pct_change().rolling(168).std().fillna(0)
        
        # K-meansë¡œ ì‹œì¥ êµ­ë©´ í´ëŸ¬ìŠ¤í„°ë§
        regime_features = np.column_stack([returns_7d, volatility_7d])
        kmeans = KMeans(n_clusters=4, random_state=42)  # 4ê°œ êµ­ë©´
        market_regimes = kmeans.fit_predict(regime_features)
        
        # êµ­ë©´ë³„ ë¼ë²¨ë§
        regime_labels = []
        for i in range(4):
            regime_mask = market_regimes == i
            avg_return = returns_7d[regime_mask].mean()
            avg_vol = volatility_7d[regime_mask].mean()
            
            if avg_return > 0.05 and avg_vol < 0.3:
                regime_labels.append('strong_bull')
            elif avg_return > 0 and avg_vol > 0.3:
                regime_labels.append('volatile_bull')
            elif avg_return < -0.05:
                regime_labels.append('bear_market')
            else:
                regime_labels.append('sideways')
        
        # êµ­ë©´ë³„ ì „ìš© ëª¨ë¸ í•™ìŠµ
        regime_models = {}
        regime_accuracies = {}
        
        y = btc_price.shift(-1).dropna()
        X = df[:-1].drop(columns=[btc_col])
        
        tscv = TimeSeriesSplit(n_splits=5)
        
        for regime_idx, regime_name in enumerate(regime_labels):
            regime_mask = market_regimes[:-1] == regime_idx  # yì— ë§ì¶° ê¸¸ì´ ì¡°ì •
            
            if regime_mask.sum() > 100:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                X_regime = X[regime_mask]
                y_regime = y[regime_mask]
                
                # í•´ë‹¹ êµ­ë©´ì— íŠ¹í™”ëœ ëª¨ë¸
                if regime_name == 'strong_bull':
                    model = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)
                elif regime_name == 'volatile_bull':
                    model = GradientBoostingRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
                elif regime_name == 'bear_market':
                    model = Ridge(alpha=1.0)  # ë³´ìˆ˜ì  ëª¨ë¸
                else:
                    model = ElasticNet(alpha=0.1, l1_ratio=0.5)  # íš¡ë³´ì¥ìš©
                
                # ì„±ëŠ¥ í‰ê°€ (ê°„ë‹¨í•œ í™€ë“œì•„ì›ƒ)
                split_point = int(len(X_regime) * 0.8)
                X_train, X_test = X_regime.iloc[:split_point], X_regime.iloc[split_point:]
                y_train, y_test = y_regime.iloc[:split_point], y_regime.iloc[split_point:]
                
                if len(X_test) > 10:
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    model.fit(X_train_scaled, y_train)
                    pred = model.predict(X_test_scaled)
                    
                    mae = mean_absolute_error(y_test, pred)
                    accuracy = max(0, 100 - (mae / abs(y_test.mean())) * 100)
                    
                    regime_models[regime_name] = {'model': model, 'scaler': scaler}
                    regime_accuracies[regime_name] = accuracy
                    
                    print(f"   ğŸ¯ {regime_name}: {accuracy:.2f}% ({regime_mask.sum()}ê°œ ë°ì´í„°)")
        
        avg_accuracy = np.mean(list(regime_accuracies.values())) if regime_accuracies else 0
        improvement = avg_accuracy - self.current_accuracy
        
        print(f"ğŸ“Š êµ­ë©´ë³„ í‰ê·  ì •í™•ë„: {avg_accuracy:.2f}% (ê¸°ì¡´ ëŒ€ë¹„ {improvement:+.2f}%)")
        
        return {
            'idea_name': 'ì‹œì¥ êµ­ë©´ë³„ ë§ì¶¤ ì˜ˆì¸¡',
            'accuracy': avg_accuracy,
            'improvement': improvement,
            'models': regime_models,
            'regimes_detected': len(regime_labels)
        }
    
    def idea_2_error_pattern_learning(self, df: pd.DataFrame) -> Dict:
        """ğŸ’¡ ì•„ì´ë””ì–´ 2: ê³¼ê±° ì˜ˆì¸¡ ì˜¤ì°¨ íŒ¨í„´ í•™ìŠµ"""
        print("\nğŸ’¡ ì•„ì´ë””ì–´ 2: ê³¼ê±° ì˜ˆì¸¡ ì˜¤ì°¨ íŒ¨í„´ì„ í•™ìŠµí•´ì„œ ë³´ì •")
        print("-" * 60)
        
        btc_col = df.columns[0]
        btc_price = df[btc_col]
        
        # 1ì°¨ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
        y = btc_price.shift(-1).dropna()
        X = df[:-1].drop(columns=[btc_col])
        
        # ê°„ë‹¨í•œ baseline ëª¨ë¸ë¡œ 1ì°¨ ì˜ˆì¸¡
        split_point = int(len(X) * 0.7)
        X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
        y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
        
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        baseline_model = RandomForestRegressor(n_estimators=100, random_state=42)
        baseline_model.fit(X_train_scaled, y_train)
        baseline_pred = baseline_model.predict(X_test_scaled)
        
        # ì˜ˆì¸¡ ì˜¤ì°¨ ê³„ì‚°
        prediction_errors = y_test.values - baseline_pred
        
        # ì˜¤ì°¨ íŒ¨í„´ íŠ¹ì„± ìƒì„±
        error_features = []
        for i in range(len(prediction_errors)):
            if i >= 24:  # 24ì‹œê°„ ì´ìƒì˜ íˆìŠ¤í† ë¦¬ê°€ ìˆì„ ë•Œ
                # ê³¼ê±° 24ì‹œê°„ì˜ ì˜¤ì°¨ íŒ¨í„´
                recent_errors = prediction_errors[i-24:i]
                error_trend = np.polyfit(range(24), recent_errors, 1)[0]  # ì˜¤ì°¨ì˜ íŠ¸ë Œë“œ
                error_volatility = np.std(recent_errors)
                error_mean = np.mean(recent_errors)
                error_autocorr = np.corrcoef(recent_errors[:-1], recent_errors[1:])[0, 1] if len(recent_errors) > 1 else 0
                
                # í˜„ì¬ ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ ì§€í‘œ
                current_prediction = baseline_pred[i]
                price_volatility = np.std(y_test.iloc[max(0, i-24):i+1])
                prediction_magnitude = abs(current_prediction - y_test.iloc[i-1] if i > 0 else 0)
                
                error_features.append([
                    error_trend, error_volatility, error_mean, error_autocorr,
                    price_volatility, prediction_magnitude
                ])
        
        if len(error_features) > 50:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œ
            error_features = np.array(error_features)
            error_targets = prediction_errors[24:]
            
            # ì˜¤ì°¨ ë³´ì • ëª¨ë¸ í•™ìŠµ
            error_split = int(len(error_features) * 0.8)
            X_error_train = error_features[:error_split]
            X_error_test = error_features[error_split:]
            y_error_train = error_targets[:error_split]
            y_error_test = error_targets[error_split:]
            
            error_correction_model = Ridge(alpha=1.0)
            error_correction_model.fit(X_error_train, y_error_train)
            
            # ì˜¤ì°¨ ì˜ˆì¸¡
            predicted_errors = error_correction_model.predict(X_error_test)
            
            # ë³´ì •ëœ ìµœì¢… ì˜ˆì¸¡
            corrected_predictions = baseline_pred[split_point + 24 + error_split:] - predicted_errors
            actual_values = y_test.iloc[24 + error_split:]
            
            # ì„±ëŠ¥ í‰ê°€
            original_mae = mean_absolute_error(actual_values, baseline_pred[24 + error_split:])
            corrected_mae = mean_absolute_error(actual_values, corrected_predictions)
            
            original_accuracy = max(0, 100 - (original_mae / abs(actual_values.mean())) * 100)
            corrected_accuracy = max(0, 100 - (corrected_mae / abs(actual_values.mean())) * 100)
            
            improvement = corrected_accuracy - original_accuracy
            
            print(f"   ğŸ“ˆ ì›ë³¸ ì •í™•ë„: {original_accuracy:.2f}%")
            print(f"   ğŸ¯ ë³´ì • ì •í™•ë„: {corrected_accuracy:.2f}% (í–¥ìƒ: {improvement:+.2f}%)")
            
            return {
                'idea_name': 'ì˜ˆì¸¡ ì˜¤ì°¨ íŒ¨í„´ í•™ìŠµ',
                'accuracy': corrected_accuracy,
                'improvement': improvement,
                'error_model': error_correction_model
            }
        
        return {'idea_name': 'ì˜ˆì¸¡ ì˜¤ì°¨ íŒ¨í„´ í•™ìŠµ', 'accuracy': 0, 'improvement': 0}
    
    def idea_3_multi_horizon_ensemble(self, df: pd.DataFrame) -> Dict:
        """ğŸ’¡ ì•„ì´ë””ì–´ 3: ë‹¤ì¤‘ ì‹œê°„ì¶• ì˜ˆì¸¡ ì•™ìƒë¸”"""
        print("\nğŸ’¡ ì•„ì´ë””ì–´ 3: 1ì‹œê°„/6ì‹œê°„/24ì‹œê°„/168ì‹œê°„ ì˜ˆì¸¡ì„ ê²°í•©")
        print("-" * 60)
        
        btc_col = df.columns[0]
        btc_price = df[btc_col]
        X_base = df.drop(columns=[btc_col])
        
        # ë‹¤ì¤‘ ì‹œê°„ì¶• íƒ€ê²Ÿ ìƒì„±
        horizons = [1, 6, 24, 168]  # 1ì‹œê°„, 6ì‹œê°„, 1ì¼, 1ì£¼ì¼
        horizon_models = {}
        horizon_predictions = {}
        
        split_point = int(len(df) * 0.8)
        
        for horizon in horizons:
            if len(btc_price) > horizon:
                y_horizon = btc_price.shift(-horizon).dropna()
                X_horizon = X_base.iloc[:len(y_horizon)]
                
                # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
                X_train = X_horizon.iloc[:split_point]
                X_test = X_horizon.iloc[split_point:]
                y_train = y_horizon.iloc[:split_point]
                y_test = y_horizon.iloc[split_point:]
                
                if len(X_test) > 10:
                    # ì‹œê°„ì¶•ë³„ ìµœì  ëª¨ë¸
                    if horizon == 1:  # 1ì‹œê°„: ìƒì„¸í•œ ëª¨ë¸
                        model = RandomForestRegressor(n_estimators=200, max_depth=20, random_state=42)
                    elif horizon == 6:  # 6ì‹œê°„: ì¤‘ê°„ ë³µì¡ë„
                        model = GradientBoostingRegressor(n_estimators=150, max_depth=8, random_state=42)
                    elif horizon == 24:  # 24ì‹œê°„: íŠ¸ë Œë“œ ì¤‘ì‹¬
                        model = ElasticNet(alpha=0.1)
                    else:  # 168ì‹œê°„: ì¥ê¸° íŠ¸ë Œë“œ
                        model = Ridge(alpha=1.0)
                    
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    model.fit(X_train_scaled, y_train)
                    pred = model.predict(X_test_scaled)
                    
                    mae = mean_absolute_error(y_test, pred)
                    accuracy = max(0, 100 - (mae / abs(y_test.mean())) * 100)
                    
                    horizon_models[f'{horizon}h'] = {'model': model, 'scaler': scaler}
                    horizon_predictions[f'{horizon}h'] = {'pred': pred, 'actual': y_test.values, 'accuracy': accuracy}
                    
                    print(f"   â±ï¸ {horizon}ì‹œê°„ ì˜ˆì¸¡: {accuracy:.2f}%")
        
        # ë‹¤ì¤‘ ì‹œê°„ì¶• ì•™ìƒë¸” (ê°€ì¤‘ í‰ê· )
        if len(horizon_predictions) >= 2:
            # 1ì‹œê°„ ì˜ˆì¸¡ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ì‹œê°„ì¶• ì˜ˆì¸¡ì„ ë³´ê°„/ê°€ì¤‘
            base_pred = horizon_predictions['1h']['pred']
            base_actual = horizon_predictions['1h']['actual']
            
            # ê° ì‹œê°„ì¶•ì˜ ê°€ì¤‘ì¹˜ (ì •í™•ë„ ê¸°ë°˜)
            weights = {}
            total_weight = 0
            for horizon_key, data in horizon_predictions.items():
                weight = data['accuracy'] / 100  # ì •í™•ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ
                weights[horizon_key] = weight
                total_weight += weight
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚° (1ì‹œê°„ ì˜ˆì¸¡ ì¤‘ì‹¬)
            ensemble_pred = np.zeros_like(base_pred)
            
            for i, horizon_key in enumerate(['1h', '6h', '24h', '168h']):
                if horizon_key in horizon_predictions:
                    pred = horizon_predictions[horizon_key]['pred']
                    weight = weights[horizon_key] / total_weight
                    
                    # ì‹œê°„ì¶•ì— ë”°ë¥¸ ì˜ˆì¸¡ê°’ ì¡°ì •
                    if horizon_key == '1h':
                        adjusted_pred = pred
                    else:
                        # ì¥ê¸° ì˜ˆì¸¡ì„ ë‹¨ê¸°ë¡œ ì¡°ì • (ë‹¨ìˆœí™”)
                        adjusted_pred = pred * 0.8 + base_pred * 0.2
                    
                    ensemble_pred += adjusted_pred * weight
            
            # ì„±ëŠ¥ í‰ê°€
            ensemble_mae = mean_absolute_error(base_actual, ensemble_pred)
            ensemble_accuracy = max(0, 100 - (ensemble_mae / abs(base_actual.mean())) * 100)
            
            # ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ê°œì„ 
            single_accuracy = horizon_predictions['1h']['accuracy']
            improvement = ensemble_accuracy - single_accuracy
            
            print(f"   ğŸ“Š ë‹¨ì¼ ëª¨ë¸: {single_accuracy:.2f}%")
            print(f"   ğŸ¯ ì•™ìƒë¸”: {ensemble_accuracy:.2f}% (í–¥ìƒ: {improvement:+.2f}%)")
            
            return {
                'idea_name': 'ë‹¤ì¤‘ ì‹œê°„ì¶• ì˜ˆì¸¡ ì•™ìƒë¸”',
                'accuracy': ensemble_accuracy,
                'improvement': improvement,
                'horizon_models': horizon_models
            }
        
        return {'idea_name': 'ë‹¤ì¤‘ ì‹œê°„ì¶• ì˜ˆì¸¡ ì•™ìƒë¸”', 'accuracy': 0, 'improvement': 0}
    
    def idea_4_volatility_adaptive_weighting(self, df: pd.DataFrame) -> Dict:
        """ğŸ’¡ ì•„ì´ë””ì–´ 4: ë³€ë™ì„± ì ì‘í˜• ëª¨ë¸ ê°€ì¤‘ì¹˜"""
        print("\nğŸ’¡ ì•„ì´ë””ì–´ 4: ì‹œì¥ ë³€ë™ì„±ì— ë”°ë¼ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •")
        print("-" * 60)
        
        btc_col = df.columns[0]
        btc_price = df[btc_col]
        
        # ë³€ë™ì„± ê³„ì‚°
        returns = btc_price.pct_change().fillna(0)
        volatility = returns.rolling(24).std().fillna(0)  # 24ì‹œê°„ ë³€ë™ì„±
        
        # ë³€ë™ì„± êµ¬ê°„ ì •ì˜
        vol_low = volatility.quantile(0.33)
        vol_high = volatility.quantile(0.67)
        
        volatility_regimes = np.where(volatility <= vol_low, 'low',
                           np.where(volatility <= vol_high, 'medium', 'high'))
        
        # ë³€ë™ì„±ë³„ ìµœì  ëª¨ë¸ ì¡°í•©
        models_config = {
            'low': {  # ì €ë³€ë™ì„±: ì •êµí•œ ëª¨ë¸
                'rf': {'weight': 0.5, 'params': {'n_estimators': 300, 'max_depth': 20}},
                'gb': {'weight': 0.3, 'params': {'n_estimators': 200, 'learning_rate': 0.05}},
                'ridge': {'weight': 0.2, 'params': {'alpha': 0.1}}
            },
            'medium': {  # ì¤‘ë³€ë™ì„±: ê· í˜• ëª¨ë¸
                'rf': {'weight': 0.4, 'params': {'n_estimators': 200, 'max_depth': 15}},
                'gb': {'weight': 0.4, 'params': {'n_estimators': 150, 'learning_rate': 0.1}},
                'ridge': {'weight': 0.2, 'params': {'alpha': 1.0}}
            },
            'high': {  # ê³ ë³€ë™ì„±: ê°•ê±´í•œ ëª¨ë¸
                'ridge': {'weight': 0.5, 'params': {'alpha': 2.0}},
                'rf': {'weight': 0.3, 'params': {'n_estimators': 100, 'max_depth': 10}},
                'gb': {'weight': 0.2, 'params': {'n_estimators': 100, 'learning_rate': 0.15}}
            }
        }
        
        # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        y = btc_price.shift(-1).dropna()
        X = df[:-1].drop(columns=[btc_col])
        vol_regimes = volatility_regimes[:-1]  # y ê¸¸ì´ì— ë§ì¶¤
        
        tscv = TimeSeriesSplit(n_splits=5)
        adaptive_predictions = []
        adaptive_actuals = []
        
        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            vol_test = vol_regimes[test_idx]
            
            # ëª¨ë¸ í•™ìŠµ
            trained_models = {}
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ê° ë³€ë™ì„± êµ¬ê°„ë³„ ëª¨ë¸ í•™ìŠµ
            for vol_regime in ['low', 'medium', 'high']:
                regime_models = {}
                
                for model_name, config in models_config[vol_regime].items():
                    if model_name == 'rf':
                        model = RandomForestRegressor(random_state=42, **config['params'])
                    elif model_name == 'gb':
                        model = GradientBoostingRegressor(random_state=42, **config['params'])
                    else:  # ridge
                        model = Ridge(**config['params'])
                    
                    model.fit(X_train_scaled, y_train)
                    regime_models[model_name] = {'model': model, 'weight': config['weight']}
                
                trained_models[vol_regime] = regime_models
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ë³€ë™ì„±ë³„ ì˜ˆì¸¡
            fold_predictions = []
            
            for i, vol_regime in enumerate(vol_test):
                if vol_regime in trained_models:
                    regime_models = trained_models[vol_regime]
                    sample_pred = 0
                    
                    for model_name, model_info in regime_models.items():
                        pred = model_info['model'].predict(X_test_scaled[i:i+1])[0]
                        weight = model_info['weight']
                        sample_pred += pred * weight
                    
                    fold_predictions.append(sample_pred)
                else:
                    fold_predictions.append(y_train.mean())  # fallback
            
            adaptive_predictions.extend(fold_predictions)
            adaptive_actuals.extend(y_test)
        
        # ì„±ëŠ¥ í‰ê°€
        if adaptive_predictions:
            adaptive_mae = mean_absolute_error(adaptive_actuals, adaptive_predictions)
            adaptive_accuracy = max(0, 100 - (adaptive_mae / abs(np.mean(adaptive_actuals))) * 100)
            improvement = adaptive_accuracy - self.current_accuracy
            
            print(f"   ğŸ“Š ë³€ë™ì„± ì ì‘í˜• ì •í™•ë„: {adaptive_accuracy:.2f}%")
            print(f"   ğŸ¯ ê¸°ì¡´ ëŒ€ë¹„ í–¥ìƒ: {improvement:+.2f}%")
            
            # ë³€ë™ì„±ë³„ ì„±ëŠ¥ ë¶„ì„
            vol_performance = {}
            for vol_regime in ['low', 'medium', 'high']:
                mask = np.array([v == vol_regime for v in volatility_regimes[:-len(volatility_regimes)+len(adaptive_actuals)]])
                if mask.sum() > 10:
                    regime_mae = mean_absolute_error(
                        np.array(adaptive_actuals)[mask], 
                        np.array(adaptive_predictions)[mask]
                    )
                    regime_acc = max(0, 100 - (regime_mae / abs(np.mean(np.array(adaptive_actuals)[mask]))) * 100)
                    vol_performance[vol_regime] = regime_acc
                    print(f"     ğŸ“ˆ {vol_regime} ë³€ë™ì„±: {regime_acc:.2f}%")
            
            return {
                'idea_name': 'ë³€ë™ì„± ì ì‘í˜• ëª¨ë¸ ê°€ì¤‘ì¹˜',
                'accuracy': adaptive_accuracy,
                'improvement': improvement,
                'volatility_performance': vol_performance
            }
        
        return {'idea_name': 'ë³€ë™ì„± ì ì‘í˜• ëª¨ë¸ ê°€ì¤‘ì¹˜', 'accuracy': 0, 'improvement': 0}
    
    def idea_5_feature_interaction_discovery(self, df: pd.DataFrame) -> Dict:
        """ğŸ’¡ ì•„ì´ë””ì–´ 5: ì§€í‘œê°„ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë°œê²¬"""
        print("\nğŸ’¡ ì•„ì´ë””ì–´ 5: ë°±í…ŒìŠ¤íŠ¸ë¡œ ì§€í‘œê°„ ìˆ¨ê²¨ì§„ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë°œê²¬")
        print("-" * 60)
        
        btc_col = df.columns[0]
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if btc_col in numeric_cols:
            numeric_cols.remove(btc_col)
        
        # ìƒìœ„ 20ê°œ ì¤‘ìš” ì§€í‘œë§Œ ì‚¬ìš© (ê³„ì‚° íš¨ìœ¨ì„±)
        from sklearn.feature_selection import SelectKBest, f_regression
        
        y = df[btc_col].shift(-1).dropna()
        X_base = df[numeric_cols][:-1]
        
        selector = SelectKBest(score_func=f_regression, k=min(20, len(numeric_cols)))
        X_selected = selector.fit_transform(X_base, y)
        selected_features = np.array(numeric_cols)[selector.get_support()]
        
        print(f"   ğŸ“Š ì„ íƒëœ í•µì‹¬ ì§€í‘œ: {len(selected_features)}ê°œ")
        
        # 2ì°¨ ìƒí˜¸ì‘ìš© í•­ ìƒì„± (ì¡°í•© í­ë°œ ë°©ì§€)
        interaction_features = []
        interaction_names = []
        
        for i in range(len(selected_features)):
            for j in range(i+1, min(i+5, len(selected_features))):  # ê° ì§€í‘œë‹¹ ìµœëŒ€ 4ê°œ ì¡°í•©
                feature1 = X_selected[:, i]
                feature2 = X_selected[:, j]
                
                # ì—¬ëŸ¬ ìƒí˜¸ì‘ìš© ìœ í˜•
                interactions = {
                    f'{selected_features[i]} * {selected_features[j]}': feature1 * feature2,
                    f'{selected_features[i]} / ({selected_features[j]} + 1e-8)': feature1 / (feature2 + 1e-8),
                    f'({selected_features[i]} - {selected_features[j]})^2': (feature1 - feature2) ** 2
                }
                
                for name, interaction in interactions.items():
                    if np.isfinite(interaction).all() and np.var(interaction) > 1e-8:
                        interaction_features.append(interaction)
                        interaction_names.append(name)
        
        if len(interaction_features) > 0:
            # ì›ë³¸ + ìƒí˜¸ì‘ìš© íŠ¹ì„±
            interaction_features = np.column_stack(interaction_features)
            X_enhanced = np.column_stack([X_selected, interaction_features])
            
            print(f"   âš¡ ìƒì„±ëœ ìƒí˜¸ì‘ìš© íŠ¹ì„±: {len(interaction_names)}ê°œ")
            
            # ì„±ëŠ¥ ë¹„êµ ë°±í…ŒìŠ¤íŠ¸
            tscv = TimeSeriesSplit(n_splits=3)
            
            original_scores = []
            enhanced_scores = []
            
            for train_idx, test_idx in tscv.split(X_enhanced):
                X_train_orig = X_selected[train_idx]
                X_test_orig = X_selected[test_idx]
                X_train_enh = X_enhanced[train_idx]
                X_test_enh = X_enhanced[test_idx]
                y_train = y.iloc[train_idx]
                y_test = y.iloc[test_idx]
                
                # ì›ë³¸ íŠ¹ì„± ëª¨ë¸
                scaler1 = RobustScaler()
                X_train_orig_scaled = scaler1.fit_transform(X_train_orig)
                X_test_orig_scaled = scaler1.transform(X_test_orig)
                
                model1 = RandomForestRegressor(n_estimators=100, random_state=42)
                model1.fit(X_train_orig_scaled, y_train)
                pred1 = model1.predict(X_test_orig_scaled)
                
                mae1 = mean_absolute_error(y_test, pred1)
                acc1 = max(0, 100 - (mae1 / abs(y_test.mean())) * 100)
                original_scores.append(acc1)
                
                # í–¥ìƒëœ íŠ¹ì„± ëª¨ë¸
                scaler2 = RobustScaler()
                X_train_enh_scaled = scaler2.fit_transform(X_train_enh)
                X_test_enh_scaled = scaler2.transform(X_test_enh)
                
                model2 = RandomForestRegressor(n_estimators=100, random_state=42)
                model2.fit(X_train_enh_scaled, y_train)
                pred2 = model2.predict(X_test_enh_scaled)
                
                mae2 = mean_absolute_error(y_test, pred2)
                acc2 = max(0, 100 - (mae2 / abs(y_test.mean())) * 100)
                enhanced_scores.append(acc2)
            
            avg_original = np.mean(original_scores)
            avg_enhanced = np.mean(enhanced_scores)
            improvement = avg_enhanced - avg_original
            
            print(f"   ğŸ“ˆ ì›ë³¸ íŠ¹ì„±: {avg_original:.2f}%")
            print(f"   ğŸ¯ ìƒí˜¸ì‘ìš© ì¶”ê°€: {avg_enhanced:.2f}% (í–¥ìƒ: {improvement:+.2f}%)")
            
            # ê°€ì¥ ìœ ìš©í•œ ìƒí˜¸ì‘ìš© ì°¾ê¸°
            if improvement > 0:
                # ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµí•˜ì—¬ íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸
                scaler_final = RobustScaler()
                X_enhanced_scaled = scaler_final.fit_transform(X_enhanced)
                
                model_final = RandomForestRegressor(n_estimators=100, random_state=42)
                model_final.fit(X_enhanced_scaled, y)
                
                # ìƒí˜¸ì‘ìš© íŠ¹ì„±ë“¤ì˜ ì¤‘ìš”ë„
                interaction_importances = model_final.feature_importances_[len(selected_features):]
                top_interactions = sorted(zip(interaction_names, interaction_importances), 
                                        key=lambda x: x[1], reverse=True)[:5]
                
                print(f"   ğŸ” ìµœê³  ìƒí˜¸ì‘ìš© íŒ¨í„´:")
                for name, importance in top_interactions:
                    print(f"     - {name}: {importance:.6f}")
            
            return {
                'idea_name': 'ì§€í‘œê°„ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë°œê²¬',
                'accuracy': avg_enhanced,
                'improvement': improvement,
                'top_interactions': top_interactions if improvement > 0 else []
            }
        
        return {'idea_name': 'ì§€í‘œê°„ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë°œê²¬', 'accuracy': 0, 'improvement': 0}
    
    def run_all_improvement_ideas(self):
        """ëª¨ë“  ì •í™•ë„ í–¥ìƒ ì•„ì´ë””ì–´ ì‹¤í–‰"""
        print("ğŸš€ ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ ì•„ì´ë””ì–´ë“¤ ì‹¤í–‰ ì¤‘...")
        
        # ë°ì´í„° ë¡œë“œ
        df = self.load_current_data()
        
        # ê° ì•„ì´ë””ì–´ ì‹¤í–‰
        ideas = [
            self.idea_1_market_regime_detection,
            self.idea_2_error_pattern_learning,
            self.idea_3_multi_horizon_ensemble,
            self.idea_4_volatility_adaptive_weighting,
            self.idea_5_feature_interaction_discovery
        ]
        
        results = []
        
        for idea_func in ideas:
            try:
                result = idea_func(df)
                results.append(result)
                self.improvement_results[result['idea_name']] = result
            except Exception as e:
                print(f"   âŒ {idea_func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ ë¶„ì„
        self.analyze_improvement_results(results)
        
        return results
    
    def analyze_improvement_results(self, results: List[Dict]):
        """í–¥ìƒ ê²°ê³¼ ë¶„ì„"""
        print(f"\nğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ ê²°ê³¼ ë¶„ì„")
        print("="*80)
        
        # ì„±ê³¼ ìˆœìœ¼ë¡œ ì •ë ¬
        valid_results = [r for r in results if r['accuracy'] > 0]
        sorted_results = sorted(valid_results, key=lambda x: x['improvement'], reverse=True)
        
        print(f"ğŸ¯ ëª©í‘œ: {self.current_accuracy}% â†’ {self.target_accuracy}%")
        print(f"ğŸ“ˆ í–¥ìƒ ì•„ì´ë””ì–´ ê²°ê³¼:")
        print("-" * 80)
        
        for i, result in enumerate(sorted_results, 1):
            improvement = result['improvement']
            accuracy = result['accuracy']
            name = result['idea_name']
            
            status = "ğŸ†" if improvement > 2 else "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰"
            print(f"{i:2d}. {status} {name}")
            print(f"    ì •í™•ë„: {accuracy:.2f}% (ê¸°ì¡´ ëŒ€ë¹„ {improvement:+.2f}%)")
            
            # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
            if accuracy >= self.target_accuracy:
                print(f"    ğŸ‰ ëª©í‘œ ë‹¬ì„±! ({self.target_accuracy}% ì´ìƒ)")
            
            print()
        
        # ìµœê³  ì„±ê³¼
        if sorted_results:
            best_result = sorted_results[0]
            self.best_accuracy = best_result['accuracy']
            
            print(f"ğŸ† ìµœê³  ì„±ê³¼: {best_result['idea_name']}")
            print(f"   ğŸ“Š ë‹¬ì„± ì •í™•ë„: {self.best_accuracy:.2f}%")
            print(f"   ğŸ“ˆ í–¥ìƒí­: {best_result['improvement']:+.2f}%")
            
            if self.best_accuracy >= self.target_accuracy:
                print(f"   ğŸ‰ ëª©í‘œ {self.target_accuracy}% ë‹¬ì„±!")
            else:
                remaining = self.target_accuracy - self.best_accuracy
                print(f"   ğŸ“‹ ëª©í‘œê¹Œì§€: {remaining:.2f}% ë” í•„ìš”")
        
        # ê²°ê³¼ ì €ì¥
        summary = {
            'generated_at': datetime.now().isoformat(),
            'current_accuracy': self.current_accuracy,
            'target_accuracy': self.target_accuracy,
            'best_achieved_accuracy': self.best_accuracy,
            'target_achieved': self.best_accuracy >= self.target_accuracy,
            'improvement_ideas': {
                result['idea_name']: {
                    'accuracy': result['accuracy'],
                    'improvement': result['improvement']
                }
                for result in valid_results
            },
            'next_recommendations': self.generate_next_recommendations(sorted_results)
        }
        
        with open(os.path.join(self.data_path, 'backtest_accuracy_improvements.json'), 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ê²°ê³¼ ì €ì¥: backtest_accuracy_improvements.json")
    
    def generate_next_recommendations(self, results: List[Dict]) -> List[str]:
        """ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ"""
        recommendations = []
        
        if not results:
            recommendations.append("ê¸°ë³¸ ëª¨ë¸ ì„±ëŠ¥ ì ê²€ í•„ìš”")
            return recommendations
        
        best_accuracy = results[0]['accuracy']
        
        if best_accuracy >= 85:
            recommendations.append("ëª©í‘œ ë‹¬ì„±! ì‹¤ì œ íŠ¸ë ˆì´ë”©ì— ì ìš© ê³ ë ¤")
            recommendations.append("ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•")
        elif best_accuracy >= 80:
            recommendations.append("ìƒìœ„ 2-3ê°œ ì•„ì´ë””ì–´ë¥¼ ì¡°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶•")
            recommendations.append("ë” ë§ì€ ë°ì´í„°ë¡œ ì¬í•™ìŠµ")
        else:
            recommendations.append("ê¸°ë³¸ ë°ì´í„° í’ˆì§ˆ ê°œì„  ìš°ì„ ")
            recommendations.append("ë” ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©")
            recommendations.append("ì•™ìƒë¸” ëª¨ë¸ ê°€ì¤‘ì¹˜ ìµœì í™”")
        
        # ì„±ê³¼ê°€ ì¢‹ì€ ì•„ì´ë””ì–´ ê¸°ë°˜ ì¶”ì²œ
        for result in results[:2]:  # ìƒìœ„ 2ê°œë§Œ
            if 'regime' in result['idea_name'].lower():
                recommendations.append("ì‹œì¥ êµ­ë©´ ê°ì§€ ì •í™•ë„ í–¥ìƒ")
            elif 'error' in result['idea_name'].lower():
                recommendations.append("ë” ì •êµí•œ ì˜¤ì°¨ ë³´ì • ëª¨ë¸ ê°œë°œ")
            elif 'multi' in result['idea_name'].lower():
                recommendations.append("ë” ë§ì€ ì‹œê°„ì¶• ì¶”ê°€ (ë¶„ë‹¨ìœ„, ì›”ë‹¨ìœ„)")
            elif 'volatility' in result['idea_name'].lower():
                recommendations.append("ë” ì„¸ë°€í•œ ë³€ë™ì„± êµ¬ê°„ ë¶„í• ")
            elif 'interaction' in result['idea_name'].lower():
                recommendations.append("3ì°¨, 4ì°¨ ìƒí˜¸ì‘ìš© íŒ¨í„´ íƒìƒ‰")
        
        return recommendations

if __name__ == "__main__":
    system = AdvancedBacktestAccuracySystem()
    results = system.run_all_improvement_ideas()
    
    print(f"\nğŸ‰ ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print(f"ğŸ† ìµœê³  ë‹¬ì„±: {system.best_accuracy:.2f}%")