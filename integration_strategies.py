#!/usr/bin/env python3
"""
ğŸ¯ Integration Strategies System
í†µí•© ì „ëµ ì‹œìŠ¤í…œ - ê³„ì¸µì  ì˜ˆì¸¡ í†µí•© ë° ì„±ëŠ¥ ìµœì í™”

ì£¼ìš” ê¸°ëŠ¥:
1. Hierarchical Prediction Reconciliation - ê³„ì¸µì  ì˜ˆì¸¡ ì¡°ì •
2. Multi-Objective Optimization - ë‹¤ëª©ì  ìµœì í™”
3. Performance Attribution Analysis - ì„±ê³¼ ê¸°ì—¬ë„ ë¶„ì„
4. Cross-Horizon Validation - êµì°¨ ì‹œê°„ëŒ€ ê²€ì¦
5. Adaptive Ensemble Methods - ì ì‘í˜• ì•™ìƒë¸” ë°©ë²•
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import defaultdict, deque
import json
import logging
from scipy.optimize import minimize, differential_evolution
from scipy.stats import pearsonr, spearmanr
from sklearn.linear_model import LinearRegression, RidgeCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import warnings

warnings.filterwarnings('ignore')

@dataclass
class PredictionRecord:
    """ì˜ˆì¸¡ ê¸°ë¡"""
    timestamp: datetime
    horizon: int
    prediction: float
    confidence: float
    uncertainty: float
    method: str
    market_regime: str = ""
    volatility: float = 0.0
    features: List[float] = field(default_factory=list)

@dataclass
class IntegrationResult:
    """í†µí•© ê²°ê³¼"""
    integrated_predictions: Dict[int, float]
    confidence_scores: Dict[int, float]
    uncertainty_bounds: Dict[int, Tuple[float, float]]
    attribution_scores: Dict[str, float]
    performance_metrics: Dict[str, float]
    optimization_details: Dict = field(default_factory=dict)

class HierarchicalReconciliation:
    """ê³„ì¸µì  ì˜ˆì¸¡ ì¡°ì •"""
    
    def __init__(self, horizons: List[int]):
        self.horizons = sorted(horizons)
        self.reconciliation_matrix = None
        self.hierarchy_constraints = self._build_hierarchy_constraints()
        
    def _build_hierarchy_constraints(self) -> Dict[str, List[Tuple[int, int, float]]]:
        """ê³„ì¸µ êµ¬ì¡° ì œì•½ ì¡°ê±´ êµ¬ì¶•"""
        constraints = {
            'temporal_consistency': [],  # ì‹œê°„ì  ì¼ê´€ì„±
            'trend_coherence': [],       # íŠ¸ë Œë“œ ì¼ê´€ì„±
            'volatility_scaling': []     # ë³€ë™ì„± ìŠ¤ì¼€ì¼ë§
        }
        
        # ì‹œê°„ì  ì¼ê´€ì„±: ë‹¨ê¸° ì˜ˆì¸¡ì´ ì¥ê¸° ì˜ˆì¸¡ì˜ ë°©í–¥ê³¼ ì¼ì¹˜í•´ì•¼ í•¨
        for i in range(len(self.horizons) - 1):
            short_h = self.horizons[i]
            long_h = self.horizons[i + 1]
            
            # ê°€ì¤‘ì¹˜: ì‹œê°„ ì°¨ì´ì— ë¹„ë¡€
            weight = 1.0 / (long_h - short_h)
            constraints['temporal_consistency'].append((short_h, long_h, weight))
        
        # íŠ¸ë Œë“œ ì¼ê´€ì„±: ì¤‘ì¥ê¸° íŠ¸ë Œë“œì™€ ë‹¨ê¸° ì˜ˆì¸¡ ê°„ ì¡°í™”
        for short_h in self.horizons[:2]:  # ë‹¨ê¸° (1h, 4h)
            for long_h in self.horizons[-2:]:  # ì¥ê¸° (72h, 168h)
                weight = 0.5 / (long_h / short_h)
                constraints['trend_coherence'].append((short_h, long_h, weight))
        
        return constraints
    
    def reconcile_predictions(self, raw_predictions: Dict[int, float], 
                            confidence_scores: Dict[int, float],
                            current_price: float) -> Dict[int, float]:
        """ì˜ˆì¸¡ê°’ ê³„ì¸µì  ì¡°ì •"""
        if not raw_predictions:
            return {}
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        total_confidence = sum(confidence_scores.values())
        if total_confidence == 0:
            weights = {h: 1.0/len(raw_predictions) for h in raw_predictions.keys()}
        else:
            weights = {h: conf/total_confidence for h, conf in confidence_scores.items()}
        
        reconciled = raw_predictions.copy()
        
        # ë°˜ë³µì  ì¡°ì • (5íšŒ)
        for iteration in range(5):
            prev_reconciled = reconciled.copy()
            
            # ì‹œê°„ì  ì¼ê´€ì„± ì¡°ì •
            reconciled = self._apply_temporal_consistency(reconciled, weights, current_price)
            
            # íŠ¸ë Œë“œ ì¼ê´€ì„± ì¡°ì •
            reconciled = self._apply_trend_coherence(reconciled, weights, current_price)
            
            # ë³€ë™ì„± ìŠ¤ì¼€ì¼ë§
            reconciled = self._apply_volatility_scaling(reconciled, weights, current_price)
            
            # ìˆ˜ë ´ ê²€ì‚¬
            changes = sum(abs(reconciled[h] - prev_reconciled[h]) for h in reconciled.keys())
            if changes < 1e-6:  # ìˆ˜ë ´
                break
        
        return reconciled
    
    def _apply_temporal_consistency(self, predictions: Dict[int, float], 
                                  weights: Dict[int, float], 
                                  current_price: float) -> Dict[int, float]:
        """ì‹œê°„ì  ì¼ê´€ì„± ì ìš©"""
        adjusted = predictions.copy()
        
        for short_h, long_h, constraint_weight in self.hierarchy_constraints['temporal_consistency']:
            if short_h in adjusted and long_h in adjusted:
                short_pred = adjusted[short_h]
                long_pred = adjusted[long_h]
                
                # ì˜ˆìƒ ìˆ˜ìµë¥  ê³„ì‚°
                short_return = (short_pred - current_price) / current_price
                long_return = (long_pred - current_price) / current_price
                
                # ì—°ìœ¨í™”ëœ ìˆ˜ìµë¥ ë¡œ ë¹„êµ (ì‹œê°„ ì •ê·œí™”)
                short_annual = short_return * (8760 / short_h)  # ì—°ê°„ ì‹œê°„ ìˆ˜
                long_annual = long_return * (8760 / long_h)
                
                # ì¼ê´€ì„± ì¡°ì • (ë‹¨ê¸°ê°€ ì¥ê¸°ë³´ë‹¤ ê³¼ë„í•˜ê²Œ ë‹¤ë¥´ë©´ ì¡°ì •)
                if abs(short_annual - long_annual) > 0.5:  # 50% ì´ìƒ ì°¨ì´
                    # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¡°ì •
                    short_weight = weights.get(short_h, 0.5)
                    long_weight = weights.get(long_h, 0.5)
                    
                    total_weight = short_weight + long_weight
                    if total_weight > 0:
                        target_annual = (short_annual * short_weight + long_annual * long_weight) / total_weight
                        
                        # ì¡°ì • ê°•ë„
                        adjustment_strength = constraint_weight * 0.1
                        
                        # ìƒˆë¡œìš´ ìˆ˜ìµë¥  ê³„ì‚°
                        new_short_return = target_annual * (short_h / 8760)
                        new_long_return = target_annual * (long_h / 8760)
                        
                        # ê°€ê²© ì—…ë°ì´íŠ¸ (ë¶€ë¶„ì  ì¡°ì •)
                        adjusted[short_h] = short_pred * (1 - adjustment_strength) + \
                                          (current_price * (1 + new_short_return)) * adjustment_strength
                        adjusted[long_h] = long_pred * (1 - adjustment_strength) + \
                                         (current_price * (1 + new_long_return)) * adjustment_strength
        
        return adjusted
    
    def _apply_trend_coherence(self, predictions: Dict[int, float], 
                             weights: Dict[int, float], 
                             current_price: float) -> Dict[int, float]:
        """íŠ¸ë Œë“œ ì¼ê´€ì„± ì ìš©"""
        adjusted = predictions.copy()
        
        # ì „ì²´ íŠ¸ë Œë“œ ë°©í–¥ ê³„ì‚° (ì‹ ë¢°ë„ ê°€ì¤‘)
        total_weighted_return = 0.0
        total_weight = 0.0
        
        for horizon, pred in predictions.items():
            return_rate = (pred - current_price) / current_price
            weight = weights.get(horizon, 1.0)
            
            total_weighted_return += return_rate * weight
            total_weight += weight
        
        if total_weight == 0:
            return adjusted
        
        overall_trend = total_weighted_return / total_weight
        
        # ê° ì˜ˆì¸¡ì„ ì „ì²´ íŠ¸ë Œë“œì™€ ì¡°í™”ì‹œí‚´
        for short_h, long_h, constraint_weight in self.hierarchy_constraints['trend_coherence']:
            if short_h in adjusted and long_h in adjusted:
                short_pred = adjusted[short_h]
                long_pred = adjusted[long_h]
                
                short_return = (short_pred - current_price) / current_price
                long_return = (long_pred - current_price) / current_price
                
                # íŠ¸ë Œë“œì™€ì˜ í¸ì°¨ ê³„ì‚°
                short_deviation = short_return - overall_trend * (short_h / 24)  # ì¼ ë‹¨ìœ„ ì •ê·œí™”
                long_deviation = long_return - overall_trend * (long_h / 24)
                
                # í¸ì°¨ê°€ í° ê²½ìš° ì¡°ì •
                if abs(short_deviation) > 0.1 or abs(long_deviation) > 0.1:
                    adjustment_strength = constraint_weight * 0.05
                    
                    # íŠ¸ë Œë“œë¡œ ì¡°ì •
                    target_short_return = overall_trend * (short_h / 24)
                    target_long_return = overall_trend * (long_h / 24)
                    
                    adjusted[short_h] = short_pred * (1 - adjustment_strength) + \
                                      (current_price * (1 + target_short_return)) * adjustment_strength
                    adjusted[long_h] = long_pred * (1 - adjustment_strength) + \
                                     (current_price * (1 + target_long_return)) * adjustment_strength
        
        return adjusted
    
    def _apply_volatility_scaling(self, predictions: Dict[int, float], 
                                weights: Dict[int, float], 
                                current_price: float) -> Dict[int, float]:
        """ë³€ë™ì„± ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§"""
        adjusted = predictions.copy()
        
        # ì‹œê°„ëŒ€ë³„ ì˜ˆìƒ ë³€ë™ì„± (ì¼ë°˜ì ì¸ BTC ë³€ë™ì„± íŒ¨í„´)
        expected_volatility = {
            1: 0.02,    # 1ì‹œê°„: 2%
            4: 0.04,    # 4ì‹œê°„: 4%
            24: 0.08,   # 1ì¼: 8%
            72: 0.12,   # 3ì¼: 12%
            168: 0.15   # 1ì£¼: 15%
        }
        
        for horizon, pred in adjusted.items():
            return_rate = (pred - current_price) / current_price
            expected_vol = expected_volatility.get(horizon, 0.1)
            
            # ì˜ˆì¸¡ ìˆ˜ìµë¥ ì´ ì˜ˆìƒ ë³€ë™ì„±ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ì¡°ì •
            if abs(return_rate) > expected_vol * 2:  # 2ë°° ì´ˆê³¼ì‹œ
                # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ë” ê°•í•˜ê²Œ ì¡°ì •
                confidence = weights.get(horizon, 0.5)
                adjustment_strength = 0.1 * (1 - confidence)
                
                # ë³€ë™ì„± í•œê³„ë¡œ ì¡°ì •
                max_return = expected_vol * 1.5 * np.sign(return_rate)
                target_price = current_price * (1 + max_return)
                
                adjusted[horizon] = pred * (1 - adjustment_strength) + target_price * adjustment_strength
        
        return adjusted

class MultiObjectiveOptimizer:
    """ë‹¤ëª©ì  ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.objectives = {
            'accuracy': self._accuracy_objective,
            'consistency': self._consistency_objective,
            'risk': self._risk_objective,
            'stability': self._stability_objective
        }
        self.objective_weights = {
            'accuracy': 0.4,
            'consistency': 0.2,
            'risk': 0.2,
            'stability': 0.2
        }
        
    def optimize_integration(self, prediction_records: List[PredictionRecord],
                           performance_history: Dict[int, List[float]],
                           constraints: Dict = None) -> Dict[int, float]:
        """í†µí•© ìµœì í™”"""
        
        if not prediction_records:
            return {}
        
        # ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ê°’ ê·¸ë£¹í™”
        horizon_predictions = defaultdict(list)
        for record in prediction_records:
            horizon_predictions[record.horizon].append(record)
        
        # ìµœì í™” ë³€ìˆ˜: ê° ì‹œê°„ëŒ€ë³„ ê°€ì¤‘ì¹˜
        horizons = list(horizon_predictions.keys())
        
        def objective_function(weights):
            """ë‹¤ëª©ì  ëª©ì  í•¨ìˆ˜"""
            weights_dict = dict(zip(horizons, weights))
            
            total_score = 0.0
            for obj_name, obj_weight in self.objective_weights.items():
                obj_score = self.objectives[obj_name](
                    weights_dict, horizon_predictions, performance_history
                )
                total_score += obj_weight * obj_score
            
            return -total_score  # ìµœëŒ€í™”ë¥¼ ìœ„í•´ ìŒìˆ˜
        
        # ì œì•½ ì¡°ê±´
        constraints_list = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]
        bounds = [(0, 1) for _ in horizons]
        
        # ì´ˆê¸°ê°’
        x0 = np.array([1.0/len(horizons)] * len(horizons))
        
        # ìµœì í™” ì‹¤í–‰
        result = minimize(
            objective_function,
            x0,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints_list
        )
        
        if result.success:
            optimal_weights = dict(zip(horizons, result.x))
        else:
            # ì‹¤íŒ¨ì‹œ ì„±ê³¼ ê¸°ë°˜ ê°€ì¤‘ì¹˜
            optimal_weights = self._performance_based_weights(performance_history)
        
        return optimal_weights
    
    def _accuracy_objective(self, weights: Dict[int, float], 
                          predictions: Dict[int, List[PredictionRecord]],
                          performance_history: Dict[int, List[float]]) -> float:
        """ì •í™•ë„ ëª©ì  í•¨ìˆ˜"""
        total_accuracy = 0.0
        total_weight = 0.0
        
        for horizon, weight in weights.items():
            if horizon in performance_history:
                recent_accuracy = np.mean(performance_history[horizon][-10:]) if performance_history[horizon] else 0.5
                total_accuracy += weight * recent_accuracy
                total_weight += weight
        
        return total_accuracy / total_weight if total_weight > 0 else 0.0
    
    def _consistency_objective(self, weights: Dict[int, float], 
                             predictions: Dict[int, List[PredictionRecord]],
                             performance_history: Dict[int, List[float]]) -> float:
        """ì¼ê´€ì„± ëª©ì  í•¨ìˆ˜"""
        if len(predictions) < 2:
            return 1.0
        
        # ì˜ˆì¸¡ê°’ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°
        horizon_means = {}
        for horizon, records in predictions.items():
            if records:
                horizon_means[horizon] = np.mean([r.prediction for r in records])
        
        if len(horizon_means) < 2:
            return 1.0
        
        correlations = []
        horizon_list = list(horizon_means.keys())
        
        for i in range(len(horizon_list)):
            for j in range(i+1, len(horizon_list)):
                h1, h2 = horizon_list[i], horizon_list[j]
                
                # ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ íŠ¸ë Œë“œ ìƒê´€ê´€ê³„
                if len(predictions[h1]) > 1 and len(predictions[h2]) > 1:
                    trend1 = [r.prediction for r in predictions[h1][-10:]]
                    trend2 = [r.prediction for r in predictions[h2][-10:]]
                    
                    min_len = min(len(trend1), len(trend2))
                    if min_len > 1:
                        corr, _ = pearsonr(trend1[:min_len], trend2[:min_len])
                        if not np.isnan(corr):
                            correlations.append(abs(corr))
        
        return np.mean(correlations) if correlations else 0.5
    
    def _risk_objective(self, weights: Dict[int, float], 
                       predictions: Dict[int, List[PredictionRecord]],
                       performance_history: Dict[int, List[float]]) -> float:
        """ìœ„í—˜ ëª©ì  í•¨ìˆ˜ (ìœ„í—˜ ìµœì†Œí™”)"""
        total_risk = 0.0
        
        for horizon, weight in weights.items():
            if horizon in predictions:
                # ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±
                uncertainties = [r.uncertainty for r in predictions[horizon] if r.uncertainty > 0]
                avg_uncertainty = np.mean(uncertainties) if uncertainties else 0.1
                
                # ì„±ê³¼ ë³€ë™ì„±
                if horizon in performance_history and len(performance_history[horizon]) > 5:
                    performance_volatility = np.std(performance_history[horizon][-20:])
                else:
                    performance_volatility = 0.1
                
                horizon_risk = avg_uncertainty + performance_volatility
                total_risk += weight * horizon_risk
        
        return max(0, 1 - total_risk)  # ìœ„í—˜ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
    
    def _stability_objective(self, weights: Dict[int, float], 
                           predictions: Dict[int, List[PredictionRecord]],
                           performance_history: Dict[int, List[float]]) -> float:
        """ì•ˆì •ì„± ëª©ì  í•¨ìˆ˜"""
        # ê°€ì¤‘ì¹˜ ë¶„ì‚° ìµœì†Œí™” (ë‹¤ì–‘ì„± ì„ í˜¸)
        weight_variance = np.var(list(weights.values()))
        
        # ì„±ê³¼ ì•ˆì •ì„±
        stability_scores = []
        for horizon in weights.keys():
            if horizon in performance_history and len(performance_history[horizon]) > 10:
                recent_std = np.std(performance_history[horizon][-20:])
                stability_score = max(0, 1 - recent_std)
                stability_scores.append(stability_score)
        
        performance_stability = np.mean(stability_scores) if stability_scores else 0.5
        
        # ê°€ì¤‘ì¹˜ ê· í˜•ì„± (0.5 = ì™„ì „ ê· ë“±)
        weight_balance = 1 - abs(weight_variance - 0.25)  # ì ë‹¹í•œ ë¶„ì‚° ì„ í˜¸
        
        return (performance_stability + weight_balance) / 2
    
    def _performance_based_weights(self, performance_history: Dict[int, List[float]]) -> Dict[int, float]:
        """ì„±ê³¼ ê¸°ë°˜ ëŒ€ì²´ ê°€ì¤‘ì¹˜"""
        if not performance_history:
            return {}
        
        horizon_scores = {}
        for horizon, history in performance_history.items():
            if history:
                recent_performance = np.mean(history[-10:])
                horizon_scores[horizon] = max(0.01, recent_performance)  # ìµœì†Œ 1%
            else:
                horizon_scores[horizon] = 0.5
        
        # ì •ê·œí™”
        total_score = sum(horizon_scores.values())
        weights = {h: score/total_score for h, score in horizon_scores.items()}
        
        return weights

class PerformanceAttributionAnalyzer:
    """ì„±ê³¼ ê¸°ì—¬ë„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.attribution_history = []
        
    def analyze_attribution(self, predictions: Dict[int, float],
                          weights: Dict[int, float],
                          actual_outcomes: Dict[int, float],
                          timestamp: datetime) -> Dict[str, float]:
        """ì„±ê³¼ ê¸°ì—¬ë„ ë¶„ì„"""
        
        attribution = {
            'total_performance': 0.0,
            'horizon_contributions': {},
            'weight_effectiveness': 0.0,
            'integration_benefit': 0.0
        }
        
        if not predictions or not actual_outcomes:
            return attribution
        
        # ê°œë³„ ì‹œê°„ëŒ€ ì„±ê³¼
        individual_performances = {}
        for horizon in predictions.keys():
            if horizon in actual_outcomes:
                pred = predictions[horizon]
                actual = actual_outcomes[horizon]
                
                # ì •í™•ë„ (MAPE ê¸°ë°˜)
                accuracy = max(0, 1 - abs(actual - pred) / abs(actual)) if actual != 0 else 0
                individual_performances[horizon] = accuracy
        
        # ê°€ì¤‘ í‰ê·  ì„±ê³¼
        total_weighted_performance = 0.0
        total_weight = 0.0
        
        for horizon, performance in individual_performances.items():
            weight = weights.get(horizon, 0)
            contribution = weight * performance
            
            attribution['horizon_contributions'][horizon] = {
                'individual_performance': performance,
                'weight': weight,
                'contribution': contribution
            }
            
            total_weighted_performance += contribution
            total_weight += weight
        
        attribution['total_performance'] = total_weighted_performance
        
        # ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± (ê°€ì¤‘ ì„±ê³¼ vs ê· ë“± ê°€ì¤‘ ì„±ê³¼)
        if individual_performances:
            equal_weight_performance = np.mean(list(individual_performances.values()))
            attribution['weight_effectiveness'] = total_weighted_performance - equal_weight_performance
        
        # í†µí•© ì´ìµ (ìµœê³  ê°œë³„ ì„±ê³¼ vs í†µí•© ì„±ê³¼)
        if individual_performances:
            best_individual = max(individual_performances.values())
            attribution['integration_benefit'] = total_weighted_performance - best_individual
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.attribution_history.append({
            'timestamp': timestamp,
            'attribution': attribution.copy()
        })
        
        # íˆìŠ¤í† ë¦¬ ì œí•œ
        if len(self.attribution_history) > 1000:
            self.attribution_history = self.attribution_history[-800:]
        
        return attribution
    
    def get_attribution_summary(self, lookback_days: int = 7) -> Dict:
        """ê¸°ì—¬ë„ ìš”ì•½ ë¶„ì„"""
        cutoff_time = datetime.now() - timedelta(days=lookback_days)
        recent_attributions = [
            a for a in self.attribution_history 
            if a['timestamp'] >= cutoff_time
        ]
        
        if not recent_attributions:
            return {'error': 'insufficient_data'}
        
        # í‰ê·  ì„±ê³¼
        avg_performance = np.mean([
            a['attribution']['total_performance'] 
            for a in recent_attributions
        ])
        
        # ì‹œê°„ëŒ€ë³„ ê¸°ì—¬ë„ í‰ê· 
        horizon_contributions = defaultdict(list)
        for a in recent_attributions:
            for horizon, contrib in a['attribution']['horizon_contributions'].items():
                horizon_contributions[horizon].append(contrib['contribution'])
        
        avg_contributions = {
            h: np.mean(contribs) 
            for h, contribs in horizon_contributions.items()
        }
        
        # ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± í‰ê· 
        avg_weight_effectiveness = np.mean([
            a['attribution']['weight_effectiveness'] 
            for a in recent_attributions
        ])
        
        # í†µí•© ì´ìµ í‰ê· 
        avg_integration_benefit = np.mean([
            a['attribution']['integration_benefit'] 
            for a in recent_attributions
        ])
        
        return {
            'period': f'{lookback_days} days',
            'sample_count': len(recent_attributions),
            'average_performance': avg_performance,
            'horizon_contributions': avg_contributions,
            'weight_effectiveness': avg_weight_effectiveness,
            'integration_benefit': avg_integration_benefit,
            'best_contributing_horizon': max(avg_contributions.items(), key=lambda x: x[1])[0] if avg_contributions else None
        }

class AdaptiveEnsemble:
    """ì ì‘í˜• ì•™ìƒë¸”"""
    
    def __init__(self, methods: List[str]):
        self.methods = methods
        self.method_weights = {method: 1.0/len(methods) for method in methods}
        self.performance_tracker = defaultdict(lambda: deque(maxlen=100))
        self.meta_model = None
        
    def update_method_performance(self, method: str, accuracy: float):
        """ë°©ë²•ë³„ ì„±ê³¼ ì—…ë°ì´íŠ¸"""
        self.performance_tracker[method].append(accuracy)
        
        # ê°€ì¤‘ì¹˜ ì¬ê³„ì‚° (ìµœê·¼ ì„±ê³¼ ê¸°ë°˜)
        self._recompute_weights()
    
    def _recompute_weights(self):
        """ê°€ì¤‘ì¹˜ ì¬ê³„ì‚°"""
        method_scores = {}
        
        for method in self.methods:
            if method in self.performance_tracker:
                recent_performance = list(self.performance_tracker[method])[-20:]  # ìµœê·¼ 20ê°œ
                if recent_performance:
                    # ì„±ê³¼ + ì•ˆì •ì„± ê³ ë ¤
                    avg_performance = np.mean(recent_performance)
                    stability = 1 - np.std(recent_performance) if len(recent_performance) > 1 else 1
                    method_scores[method] = avg_performance * 0.7 + stability * 0.3
                else:
                    method_scores[method] = 0.5
            else:
                method_scores[method] = 0.5
        
        # ì •ê·œí™”
        total_score = sum(method_scores.values())
        if total_score > 0:
            self.method_weights = {method: score/total_score for method, score in method_scores.items()}
        
    def combine_predictions(self, method_predictions: Dict[str, Dict[int, float]]) -> Dict[int, float]:
        """ì˜ˆì¸¡ ê²°í•©"""
        combined = {}
        
        # ëª¨ë“  ì‹œê°„ëŒ€ ìˆ˜ì§‘
        all_horizons = set()
        for predictions in method_predictions.values():
            all_horizons.update(predictions.keys())
        
        # ì‹œê°„ëŒ€ë³„ ê²°í•©
        for horizon in all_horizons:
            weighted_pred = 0.0
            total_weight = 0.0
            
            for method, predictions in method_predictions.items():
                if horizon in predictions:
                    weight = self.method_weights.get(method, 0)
                    weighted_pred += predictions[horizon] * weight
                    total_weight += weight
            
            if total_weight > 0:
                combined[horizon] = weighted_pred / total_weight
            else:
                # ëŒ€ì•ˆ: ë‹¨ìˆœ í‰ê· 
                horizon_preds = [pred[horizon] for pred in method_predictions.values() if horizon in pred]
                combined[horizon] = np.mean(horizon_preds) if horizon_preds else 0.0
        
        return combined
    
    def get_ensemble_confidence(self, method_predictions: Dict[str, Dict[int, float]]) -> Dict[int, float]:
        """ì•™ìƒë¸” ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_scores = {}
        
        for horizon in set().union(*[p.keys() for p in method_predictions.values()]):
            horizon_preds = []
            horizon_weights = []
            
            for method, predictions in method_predictions.items():
                if horizon in predictions:
                    horizon_preds.append(predictions[horizon])
                    horizon_weights.append(self.method_weights.get(method, 0))
            
            if len(horizon_preds) > 1:
                # ê°€ì¤‘ ë¶„ì‚° ê³„ì‚°
                weighted_mean = np.average(horizon_preds, weights=horizon_weights)
                weighted_var = np.average([(p - weighted_mean)**2 for p in horizon_preds], weights=horizon_weights)
                
                # ì‹ ë¢°ë„: ë¶„ì‚°ì˜ ì—­ìˆ˜
                confidence = 1.0 / (1.0 + weighted_var)
                confidence_scores[horizon] = confidence
            else:
                confidence_scores[horizon] = 0.5  # ê¸°ë³¸ê°’
        
        return confidence_scores

class IntegrationStrategiesSystem:
    """í†µí•© ì „ëµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, horizons: List[int]):
        self.horizons = horizons
        
        # êµ¬ì„± ìš”ì†Œ
        self.reconciliation = HierarchicalReconciliation(horizons)
        self.optimizer = MultiObjectiveOptimizer()
        self.attribution_analyzer = PerformanceAttributionAnalyzer()
        self.adaptive_ensemble = AdaptiveEnsemble(['neural_network', 'random_forest', 'gradient_boosting'])
        
        # ìƒíƒœ ì¶”ì 
        self.prediction_records = deque(maxlen=1000)
        self.performance_history = defaultdict(list)
        self.integration_history = []
        
        self.setup_logging()
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def integrate_predictions(self, 
                            method_predictions: Dict[str, Dict[int, float]],
                            confidence_scores: Dict[str, Dict[int, float]],
                            uncertainty_bounds: Dict[str, Dict[int, Tuple[float, float]]],
                            current_price: float,
                            market_context: Dict = None) -> IntegrationResult:
        """ì˜ˆì¸¡ í†µí•©"""
        
        self.logger.info(f"ğŸ”„ ë‹¤ì¤‘ ì˜ˆì¸¡ í†µí•© ì‹œì‘ - ë°©ë²• ìˆ˜: {len(method_predictions)}")
        
        if not method_predictions:
            return self._create_empty_result()
        
        # 1. ì ì‘í˜• ì•™ìƒë¸”ë¡œ ì˜ˆì¸¡ ê²°í•©
        ensemble_predictions = self.adaptive_ensemble.combine_predictions(method_predictions)
        ensemble_confidence = self.adaptive_ensemble.get_ensemble_confidence(method_predictions)
        
        # 2. ê³„ì¸µì  ì¡°ì •
        reconciled_predictions = self.reconciliation.reconcile_predictions(
            ensemble_predictions, ensemble_confidence, current_price
        )
        
        # 3. ë‹¤ëª©ì  ìµœì í™”
        # ì˜ˆì¸¡ ê¸°ë¡ ìƒì„±
        current_time = datetime.now()
        prediction_records = []
        
        for method, predictions in method_predictions.items():
            for horizon, pred in predictions.items():
                confidence = confidence_scores.get(method, {}).get(horizon, 0.5)
                uncertainty = 0.0
                if method in uncertainty_bounds and horizon in uncertainty_bounds[method]:
                    lower, upper = uncertainty_bounds[method][horizon]
                    uncertainty = (upper - lower) / 2
                
                record = PredictionRecord(
                    timestamp=current_time,
                    horizon=horizon,
                    prediction=pred,
                    confidence=confidence,
                    uncertainty=uncertainty,
                    method=method,
                    market_regime=market_context.get('regime', '') if market_context else '',
                    volatility=market_context.get('volatility', 0.0) if market_context else 0.0
                )
                prediction_records.append(record)
        
        self.prediction_records.extend(prediction_records)
        
        # ìµœì  ê°€ì¤‘ì¹˜ ê³„ì‚°
        optimal_weights = self.optimizer.optimize_integration(
            prediction_records, self.performance_history
        )
        
        # 4. ìµœì¢… í†µí•© ì˜ˆì¸¡
        final_predictions = {}
        final_confidence = {}
        final_uncertainty_bounds = {}
        
        for horizon in self.horizons:
            if horizon in reconciled_predictions:
                # ê¸°ë³¸ ì˜ˆì¸¡ê°’
                final_predictions[horizon] = reconciled_predictions[horizon]
                
                # ì‹ ë¢°ë„ ì§‘ê³„
                horizon_confidences = []
                for method in method_predictions.keys():
                    if method in confidence_scores and horizon in confidence_scores[method]:
                        horizon_confidences.append(confidence_scores[method][horizon])
                
                final_confidence[horizon] = np.mean(horizon_confidences) if horizon_confidences else 0.5
                
                # ë¶ˆí™•ì‹¤ì„± êµ¬ê°„ ì§‘ê³„
                all_bounds = []
                for method in method_predictions.keys():
                    if method in uncertainty_bounds and horizon in uncertainty_bounds[method]:
                        all_bounds.append(uncertainty_bounds[method][horizon])
                
                if all_bounds:
                    lower_bounds = [b[0] for b in all_bounds]
                    upper_bounds = [b[1] for b in all_bounds]
                    final_uncertainty_bounds[horizon] = (
                        np.mean(lower_bounds),
                        np.mean(upper_bounds)
                    )
                else:
                    pred = final_predictions[horizon]
                    std_error = abs(pred - current_price) * 0.1  # 10% ì˜¤ì°¨ ê°€ì •
                    final_uncertainty_bounds[horizon] = (pred - std_error, pred + std_error)
        
        # 5. ì„±ê³¼ ê¸°ì—¬ë„ ë¶„ì„ (ì´ì „ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°)
        attribution_scores = {}
        if len(self.integration_history) > 0:
            # ë‹¨ìˆœí™”ëœ ê¸°ì—¬ë„ ì ìˆ˜
            for method in method_predictions.keys():
                # ìµœê·¼ ì„±ê³¼ ê¸°ë°˜ ê¸°ì—¬ë„
                method_performance = self.performance_history.get(method, [0.5])
                recent_performance = np.mean(method_performance[-10:]) if method_performance else 0.5
                attribution_scores[method] = recent_performance
        
        # 6. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        performance_metrics = {
            'integration_confidence': np.mean(list(final_confidence.values())),
            'prediction_diversity': self._calculate_prediction_diversity(method_predictions),
            'ensemble_coherence': self._calculate_ensemble_coherence(reconciled_predictions, current_price),
            'optimization_quality': self._evaluate_optimization_quality(optimal_weights)
        }
        
        # ê²°ê³¼ ìƒì„±
        result = IntegrationResult(
            integrated_predictions=final_predictions,
            confidence_scores=final_confidence,
            uncertainty_bounds=final_uncertainty_bounds,
            attribution_scores=attribution_scores,
            performance_metrics=performance_metrics,
            optimization_details={
                'optimal_weights': optimal_weights,
                'ensemble_weights': self.adaptive_ensemble.method_weights.copy(),
                'reconciliation_applied': True
            }
        )
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.integration_history.append({
            'timestamp': current_time,
            'result': result,
            'market_context': market_context
        })
        
        self.logger.info(f"âœ… ì˜ˆì¸¡ í†µí•© ì™„ë£Œ - í†µí•© ì‹ ë¢°ë„: {performance_metrics['integration_confidence']:.3f}")
        
        return result
    
    def _calculate_prediction_diversity(self, method_predictions: Dict[str, Dict[int, float]]) -> float:
        """ì˜ˆì¸¡ ë‹¤ì–‘ì„± ê³„ì‚°"""
        if len(method_predictions) < 2:
            return 0.0
        
        diversity_scores = []
        
        # ëª¨ë“  ì‹œê°„ëŒ€ì— ëŒ€í•´ ë‹¤ì–‘ì„± ê³„ì‚°
        all_horizons = set().union(*[p.keys() for p in method_predictions.values()])
        
        for horizon in all_horizons:
            horizon_preds = []
            for predictions in method_predictions.values():
                if horizon in predictions:
                    horizon_preds.append(predictions[horizon])
            
            if len(horizon_preds) > 1:
                # ë³€ì´ê³„ìˆ˜ (CV) ê³„ì‚°
                mean_pred = np.mean(horizon_preds)
                std_pred = np.std(horizon_preds)
                cv = std_pred / abs(mean_pred) if abs(mean_pred) > 0 else 0
                diversity_scores.append(cv)
        
        return np.mean(diversity_scores) if diversity_scores else 0.0
    
    def _calculate_ensemble_coherence(self, predictions: Dict[int, float], current_price: float) -> float:
        """ì•™ìƒë¸” ì¼ê´€ì„± ê³„ì‚°"""
        if len(predictions) < 2:
            return 1.0
        
        # ìˆ˜ìµë¥  ê¸°ë°˜ ì¼ê´€ì„±
        returns = {}
        for horizon, pred in predictions.items():
            returns[horizon] = (pred - current_price) / current_price
        
        return_values = list(returns.values())
        
        # ìˆ˜ìµë¥  ê°„ ìƒê´€ê´€ê³„
        if len(return_values) > 1:
            correlations = []
            for i in range(len(return_values)):
                for j in range(i+1, len(return_values)):
                    # ì‹œê°„ ê°€ì¤‘ ìƒê´€ê´€ê³„ (ì‹œê°„ì°¨ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ìƒê´€ê´€ê³„ ê¸°ëŒ€)
                    horizons_list = list(returns.keys())
                    time_factor = 1.0 / (1.0 + abs(horizons_list[i] - horizons_list[j]) / 24)  # ì¼ ë‹¨ìœ„
                    correlation = abs(return_values[i] - return_values[j])  # ë‹¨ìˆœ ì°¨ì´
                    correlations.append((1.0 - correlation) * time_factor)
            
            return np.mean(correlations)
        
        return 1.0
    
    def _evaluate_optimization_quality(self, weights: Dict[int, float]) -> float:
        """ìµœì í™” í’ˆì§ˆ í‰ê°€"""
        if not weights:
            return 0.0
        
        # ê°€ì¤‘ì¹˜ ë¶„í¬ í’ˆì§ˆ (ë„ˆë¬´ ì§‘ì¤‘ë˜ì§€ ì•Šê³  ì ë‹¹íˆ ë¶„ì‚°)
        weight_values = list(weights.values())
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        entropy = -sum(w * np.log(w + 1e-10) for w in weight_values)
        max_entropy = np.log(len(weight_values))
        normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0
        
        # ìµœì  ì—”íŠ¸ë¡œí”¼ëŠ” ì™„ì „ ê· ë“±(1.0)ê³¼ ì™„ì „ ì§‘ì¤‘(0.0)ì˜ ì¤‘ê°„
        optimal_entropy = 0.7  # ì•½ê°„ì˜ ì§‘ì¤‘ì„ ì„ í˜¸
        quality = 1.0 - abs(normalized_entropy - optimal_entropy)
        
        return max(0.0, quality)
    
    def update_performance(self, method: str, horizon: int, actual: float, predicted: float):
        """ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        # ì •í™•ë„ ê³„ì‚°
        accuracy = max(0, 1 - abs(actual - predicted) / abs(actual)) if actual != 0 else 0
        
        # ë°©ë²•ë³„ ì„±ëŠ¥ ì¶”ì 
        method_key = f"{method}_{horizon}"
        self.performance_history[method_key].append(accuracy)
        
        # ì ì‘í˜• ì•™ìƒë¸” ì—…ë°ì´íŠ¸
        self.adaptive_ensemble.update_method_performance(method, accuracy)
        
        # íˆìŠ¤í† ë¦¬ ì œí•œ
        if len(self.performance_history[method_key]) > 200:
            self.performance_history[method_key] = self.performance_history[method_key][-150:]
    
    def _create_empty_result(self) -> IntegrationResult:
        """ë¹ˆ ê²°ê³¼ ìƒì„±"""
        return IntegrationResult(
            integrated_predictions={},
            confidence_scores={},
            uncertainty_bounds={},
            attribution_scores={},
            performance_metrics={
                'integration_confidence': 0.0,
                'prediction_diversity': 0.0,
                'ensemble_coherence': 0.0,
                'optimization_quality': 0.0
            }
        )
    
    def get_system_summary(self) -> Dict:
        """ì‹œìŠ¤í…œ ìš”ì•½"""
        recent_performance = []
        for method_key, history in self.performance_history.items():
            if history:
                recent_performance.append(np.mean(history[-20:]))
        
        return {
            'total_integrations': len(self.integration_history),
            'average_recent_performance': np.mean(recent_performance) if recent_performance else 0.0,
            'active_methods': len(self.adaptive_ensemble.methods),
            'method_weights': self.adaptive_ensemble.method_weights.copy(),
            'prediction_record_count': len(self.prediction_records),
            'performance_tracking': {
                method: len(history) for method, history in self.performance_history.items()
            }
        }
    
    def save_system_state(self, filepath: str):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥"""
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ë³€í™˜
        serializable_data = {
            'horizons': self.horizons,
            'method_weights': self.adaptive_ensemble.method_weights,
            'performance_history': {
                method: list(history)[-100:]  # ìµœê·¼ 100ê°œë§Œ
                for method, history in self.performance_history.items()
            },
            'integration_history': [
                {
                    'timestamp': entry['timestamp'].isoformat(),
                    'performance_metrics': entry['result'].performance_metrics,
                    'market_context': entry.get('market_context', {})
                }
                for entry in self.integration_history[-100:]  # ìµœê·¼ 100ê°œë§Œ
            ],
            'system_summary': self.get_system_summary()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"í†µí•© ì „ëµ ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥: {filepath}")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    # í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    horizons = [1, 4, 24, 72, 168]
    integration_system = IntegrationStrategiesSystem(horizons)
    
    print("ğŸ¯ Integration Strategies System Test")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
    current_price = 55000.0
    
    # ë‹¤ì–‘í•œ ë°©ë²•ì˜ ì˜ˆì¸¡ê°’ ì‹œë®¬ë ˆì´ì…˜
    np.random.seed(42)
    
    # ë°©ë²•ë³„ ì˜ˆì¸¡ ìƒì„±
    methods = ['neural_network', 'random_forest', 'gradient_boosting']
    method_predictions = {}
    confidence_scores = {}
    uncertainty_bounds = {}
    
    for method in methods:
        method_predictions[method] = {}
        confidence_scores[method] = {}
        uncertainty_bounds[method] = {}
        
        for horizon in horizons:
            # ë°©ë²•ë³„ íŠ¹ì„±ì„ ë°˜ì˜í•œ ì˜ˆì¸¡
            base_return = np.random.normal(0.02, 0.1)  # ê¸°ë³¸ 2% ìƒìŠ¹ ê²½í–¥
            
            # ë°©ë²•ë³„ í¸í–¥
            if method == 'neural_network':
                method_bias = np.random.normal(0.001, 0.02)  # ì•½ê°„ ë‚™ê´€ì 
            elif method == 'random_forest':
                method_bias = np.random.normal(-0.001, 0.015)  # ì•½ê°„ ë³´ìˆ˜ì 
            else:  # gradient_boosting
                method_bias = np.random.normal(0, 0.01)  # ì¤‘ë¦½ì 
            
            # ì‹œê°„ëŒ€ë³„ íŠ¹ì„±
            time_factor = 1.0 + (horizon / 168) * 0.1  # ì¥ê¸°ì¼ìˆ˜ë¡ ë¶ˆí™•ì‹¤ì„± ì¦ê°€
            
            predicted_return = (base_return + method_bias) * time_factor
            predicted_price = current_price * (1 + predicted_return)
            
            method_predictions[method][horizon] = predicted_price
            
            # ì‹ ë¢°ë„ (ì‹œê°„ëŒ€ê°€ ì§§ì„ìˆ˜ë¡ ë†’ìŒ)
            base_confidence = 0.9 - (horizon / 168) * 0.3
            method_confidence = base_confidence + np.random.normal(0, 0.05)
            confidence_scores[method][horizon] = max(0.3, min(0.95, method_confidence))
            
            # ë¶ˆí™•ì‹¤ì„± êµ¬ê°„
            uncertainty = abs(predicted_price - current_price) * (0.05 + horizon / 168 * 0.1)
            lower_bound = predicted_price - uncertainty
            upper_bound = predicted_price + uncertainty
            uncertainty_bounds[method][horizon] = (lower_bound, upper_bound)
    
    # ì‹œì¥ ì»¨í…ìŠ¤íŠ¸
    market_context = {
        'regime': 'low_volatility_bull',
        'volatility': 0.04,
        'trend_strength': 0.6
    }
    
    print(f"ğŸ“Š ì…ë ¥ ì˜ˆì¸¡ê°’:")
    for method in methods:
        print(f"  {method}:")
        for horizon in horizons:
            pred = method_predictions[method][horizon]
            conf = confidence_scores[method][horizon]
            print(f"    {horizon}h: ${pred:,.0f} (ì‹ ë¢°ë„: {conf:.3f})")
        print()
    
    # í†µí•© ì‹¤í–‰
    integration_result = integration_system.integrate_predictions(
        method_predictions=method_predictions,
        confidence_scores=confidence_scores,
        uncertainty_bounds=uncertainty_bounds,
        current_price=current_price,
        market_context=market_context
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ”„ í†µí•© ê²°ê³¼:")
    print(f"  í˜„ì¬ê°€: ${current_price:,.0f}")
    print()
    
    print(f"ğŸ“ˆ í†µí•© ì˜ˆì¸¡ê°’:")
    for horizon in horizons:
        if horizon in integration_result.integrated_predictions:
            pred = integration_result.integrated_predictions[horizon]
            conf = integration_result.confidence_scores[horizon]
            lower, upper = integration_result.uncertainty_bounds[horizon]
            
            return_pct = (pred - current_price) / current_price * 100
            print(f"  {horizon}h: ${pred:,.0f} ({return_pct:+.2f}%)")
            print(f"       ì‹ ë¢°ë„: {conf:.3f}")
            print(f"       êµ¬ê°„: [${lower:,.0f}, ${upper:,.0f}]")
    
    print(f"\nâš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
    metrics = integration_result.performance_metrics
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.3f}")
    
    print(f"\nğŸ”§ ìµœì í™” ì„¸ë¶€ì‚¬í•­:")
    details = integration_result.optimization_details
    print(f"  ìµœì  ê°€ì¤‘ì¹˜:")
    for horizon, weight in details.get('optimal_weights', {}).items():
        print(f"    {horizon}h: {weight:.3f}")
    
    print(f"  ì•™ìƒë¸” ê°€ì¤‘ì¹˜:")
    for method, weight in details.get('ensemble_weights', {}).items():
        print(f"    {method}: {weight:.3f}")
    
    # ì„±ëŠ¥ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
    print(f"\nğŸ¯ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜:")
    for method in methods:
        for horizon in horizons:
            # ê°€ìƒì˜ ì‹¤ì œê°’ (ì˜ˆì¸¡ê°’ ê·¼ì²˜)
            predicted = method_predictions[method][horizon]
            actual = predicted + np.random.normal(0, abs(predicted - current_price) * 0.1)
            
            integration_system.update_performance(method, horizon, actual, predicted)
            
            accuracy = max(0, 1 - abs(actual - predicted) / abs(actual)) if actual != 0 else 0
            print(f"  {method} {horizon}h: ì •í™•ë„ {accuracy:.3f}")
    
    # ì‹œìŠ¤í…œ ìš”ì•½
    summary = integration_system.get_system_summary()
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìš”ì•½:")
    print(f"  ì´ í†µí•© ìˆ˜: {summary['total_integrations']}")
    print(f"  í‰ê·  ì„±ëŠ¥: {summary['average_recent_performance']:.3f}")
    print(f"  í™œì„± ë°©ë²•: {summary['active_methods']}")
    print(f"  ì˜ˆì¸¡ ê¸°ë¡: {summary['prediction_record_count']}")
    
    # ê²°ê³¼ ì €ì¥
    integration_system.save_system_state('integration_strategies_results.json')
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: integration_strategies_results.json")
    
    return integration_system

if __name__ == "__main__":
    main()