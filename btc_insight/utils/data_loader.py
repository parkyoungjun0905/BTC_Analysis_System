#!/usr/bin/env python3
"""
ğŸ“Š ë°ì´í„° ë¡œë”
- ai_optimized_3month_data í´ë”ì˜ 1ì‹œê°„ ë‹¨ìœ„ í†µí•© ë°ì´í„° ë¡œë“œ
- ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
from typing import Dict, List, Optional

from .logger import get_logger

class DataLoader:
    """BTC ë¶„ì„ìš© ë°ì´í„° ë¡œë”"""
    
    def __init__(self, data_path: str):
        self.logger = get_logger(__name__)
        self.data_path = Path(data_path)
        self.data = None
        self.data_info = {}
        
        print(f"ğŸ“Š ë°ì´í„° ë¡œë” ì´ˆê¸°í™”: {self.data_path}")
        
    def load_data(self) -> bool:
        """
        3ê°œì›”ì¹˜ 1ì‹œê°„ ë‹¨ìœ„ í†µí•© ë°ì´í„° ë¡œë“œ
        
        Returns:
            ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        print("ğŸ“¥ 3ê°œì›”ì¹˜ í†µí•© ë°ì´í„° ë¡œë”© ì‹œì‘...")
        
        try:
            # ai_matrix_complete.csv íŒŒì¼ ë¡œë“œ
            csv_file = self.data_path / "ai_matrix_complete.csv"
            
            if not csv_file.exists():
                self.logger.error(f"ë°ì´í„° íŒŒì¼ ì—†ìŒ: {csv_file}")
                return False
            
            # ë°ì´í„° ì½ê¸°
            self.data = pd.read_csv(csv_file)
            print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° ë¡œë“œ: {self.data.shape}")
            
            # ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
            if not self._validate_and_preprocess():
                return False
            
            # ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
            self._collect_data_info()
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
            print(f"   ğŸ“ í¬ê¸°: {self.data.shape[0]}í–‰ x {self.data.shape[1]}ì—´")
            print(f"   ğŸ“… ê¸°ê°„: {self.data_info.get('time_range', 'N/A')}")
            print(f"   ğŸ”¢ ì§€í‘œ ìˆ˜: {self.data_info.get('indicator_count', 0)}ê°œ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_and_preprocess(self) -> bool:
        """ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬"""
        print("ğŸ” ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬...")
        
        # ë¹ˆ ë°ì´í„° ì²´í¬
        if self.data.empty:
            self.logger.error("ë¹ˆ ë°ì´í„°ì…‹")
            return False
        
        # timestamp ì»¬ëŸ¼ ì²˜ë¦¬
        if 'timestamp' in self.data.columns:
            try:
                self.data['timestamp'] = pd.to_datetime(self.data['timestamp'])
                # ì‹œê°„ìˆœ ì •ë ¬
                self.data = self.data.sort_values('timestamp').reset_index(drop=True)
                print("âœ… timestamp ì²˜ë¦¬ ë° ì‹œê°„ìˆœ ì •ë ¬ ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"timestamp ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()
        
        # timestampê°€ ìˆìœ¼ë©´ í¬í•¨
        if 'timestamp' in self.data.columns:
            columns_to_keep = ['timestamp'] + numeric_columns
        else:
            columns_to_keep = numeric_columns
            
        self.data = self.data[columns_to_keep]
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        missing_before = self.data.isnull().sum().sum()
        if missing_before > 0:
            print(f"âš ï¸ ê²°ì¸¡ì¹˜ ë°œê²¬: {missing_before}ê°œ")
            
            # ì‹œê³„ì—´ íŠ¹ì„±ì„ ê³ ë ¤í•œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            # 1. ì „ì§„ ì±„ì›€ (forward fill)
            self.data = self.data.fillna(method='ffill')
            
            # 2. í›„ì§„ ì±„ì›€ (backward fill)
            self.data = self.data.fillna(method='bfill')
            
            # 3. ì—¬ì „íˆ ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬
            self.data = self.data.fillna(0)
            
            missing_after = self.data.isnull().sum().sum()
            print(f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {missing_before} â†’ {missing_after}")
        
        # ë¬´í•œê°’ ì²˜ë¦¬
        inf_count = np.isinf(self.data.select_dtypes(include=[np.number])).sum().sum()
        if inf_count > 0:
            print(f"âš ï¸ ë¬´í•œê°’ ë°œê²¬: {inf_count}ê°œ")
            self.data = self.data.replace([np.inf, -np.inf], 0)
            print("âœ… ë¬´í•œê°’ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ë°ì´í„° íƒ€ì… ìµœì í™”
        self._optimize_data_types()
        
        print("âœ… ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬ ì™„ë£Œ")
        return True
    
    def _optimize_data_types(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¥¼ ìœ„í•œ ë°ì´í„° íƒ€ì… ë³€í™˜"""
        numeric_columns = self.data.select_dtypes(include=[np.number]).columns
        
        for col in numeric_columns:
            if self.data[col].dtype == 'float64':
                # float32ë¡œ ë‹¤ìš´ìºìŠ¤íŠ¸ ì‹œë„
                if self.data[col].min() >= np.finfo(np.float32).min and \
                   self.data[col].max() <= np.finfo(np.float32).max:
                    self.data[col] = self.data[col].astype(np.float32)
            
            elif self.data[col].dtype == 'int64':
                # int32ë¡œ ë‹¤ìš´ìºìŠ¤íŠ¸ ì‹œë„
                if self.data[col].min() >= np.iinfo(np.int32).min and \
                   self.data[col].max() <= np.iinfo(np.int32).max:
                    self.data[col] = self.data[col].astype(np.int32)
    
    def _collect_data_info(self):
        """ë°ì´í„° ì •ë³´ ìˆ˜ì§‘"""
        self.data_info = {
            'shape': self.data.shape,
            'columns': list(self.data.columns),
            'numeric_columns': list(self.data.select_dtypes(include=[np.number]).columns),
            'indicator_count': len(self.data.select_dtypes(include=[np.number]).columns),
            'memory_usage_mb': self.data.memory_usage(deep=True).sum() / 1024 / 1024
        }
        
        # ì‹œê°„ ë²”ìœ„ ì •ë³´
        if 'timestamp' in self.data.columns:
            self.data_info['time_range'] = f"{self.data['timestamp'].min()} ~ {self.data['timestamp'].max()}"
            self.data_info['time_span_hours'] = int((self.data['timestamp'].max() - self.data['timestamp'].min()).total_seconds() / 3600)
        
        # BTC ê°€ê²© ì»¬ëŸ¼ ì‹ë³„
        btc_price_col = self._identify_btc_price_column()
        if btc_price_col:
            self.data_info['btc_price_column'] = btc_price_col
            self.data_info['btc_price_range'] = {
                'min': float(self.data[btc_price_col].min()),
                'max': float(self.data[btc_price_col].max()),
                'current': float(self.data[btc_price_col].iloc[-1])
            }
    
    def _identify_btc_price_column(self) -> Optional[str]:
        """BTC ê°€ê²© ì»¬ëŸ¼ ì‹ë³„"""
        candidates = [
            'onchain_blockchain_info_network_stats_market_price_usd',
            'btc_price', 'price', 'close', 'market_price_usd'
        ]
        
        # í›„ë³´ ì»¬ëŸ¼ ìš°ì„  ê²€ìƒ‰
        for candidate in candidates:
            if candidate in self.data.columns:
                return candidate
        
        # í° ìˆ˜ì¹˜ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ì°¾ê¸° (BTC ê°€ê²© íŠ¹ì„±)
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if self.data[col].mean() > 10000:  # BTC ê°€ê²© ë²”ìœ„
                return col
                
        return None
    
    def get_data(self) -> pd.DataFrame:
        """ì „ì²´ ë°ì´í„° ë°˜í™˜"""
        return self.data
    
    def get_latest_data(self, hours: int = 168) -> pd.DataFrame:
        """
        ìµœê·¼ Nì‹œê°„ ë°ì´í„° ë°˜í™˜
        
        Args:
            hours: ê°€ì ¸ì˜¬ ì‹œê°„ (ê¸°ë³¸ 168ì‹œê°„ = 1ì£¼ì¼)
            
        Returns:
            ìµœê·¼ Nì‹œê°„ ë°ì´í„°
        """
        if self.data is None:
            self.logger.error("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            return pd.DataFrame()
        
        return self.data.tail(hours).copy()
    
    def get_btc_price_series(self) -> pd.Series:
        """BTC ê°€ê²© ì‹œê³„ì—´ ë°˜í™˜"""
        btc_col = self._identify_btc_price_column()
        if btc_col and self.data is not None:
            return self.data[btc_col]
        else:
            return pd.Series()
    
    def get_data_info(self) -> Dict:
        """ë°ì´í„° ì •ë³´ ë°˜í™˜"""
        return self.data_info.copy()
    
    def get_feature_columns(self) -> List[str]:
        """í”¼ì²˜ ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜ (BTC ê°€ê²© ì œì™¸)"""
        if self.data is None:
            return []
        
        btc_col = self._identify_btc_price_column()
        all_numeric = self.data.select_dtypes(include=[np.number]).columns.tolist()
        
        if btc_col and btc_col in all_numeric:
            all_numeric.remove(btc_col)
        
        return all_numeric
    
    def validate_data_continuity(self) -> Dict:
        """ë°ì´í„° ì—°ì†ì„± ê²€ì¦"""
        if self.data is None or 'timestamp' not in self.data.columns:
            return {'continuity': False, 'reason': 'No timestamp data'}
        
        # ì‹œê°„ ê°„ê²© í™•ì¸
        time_diffs = self.data['timestamp'].diff().dt.total_seconds() / 3600  # ì‹œê°„ ë‹¨ìœ„
        
        # 1ì‹œê°„ ê°„ê²©ì´ ì•„ë‹Œ ë¶€ë¶„ ì°¾ê¸°
        irregular_intervals = time_diffs[(time_diffs != 1.0) & (~time_diffs.isna())]
        
        continuity_info = {
            'continuity': len(irregular_intervals) == 0,
            'total_points': len(self.data),
            'irregular_intervals': len(irregular_intervals),
            'expected_hours': int((self.data['timestamp'].max() - self.data['timestamp'].min()).total_seconds() / 3600),
            'actual_hours': len(self.data),
            'data_completeness': len(self.data) / int((self.data['timestamp'].max() - self.data['timestamp'].min()).total_seconds() / 3600) * 100
        }
        
        return continuity_info
    
    def get_data_quality_report(self) -> Dict:
        """ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        if self.data is None:
            return {'status': 'No data loaded'}
        
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        quality_report = {
            'data_shape': self.data.shape,
            'missing_values': self.data.isnull().sum().sum(),
            'duplicate_rows': self.data.duplicated().sum(),
            'numeric_columns': len(numeric_data.columns),
            'zero_variance_columns': (numeric_data.var() == 0).sum(),
            'high_correlation_pairs': self._find_high_correlations(numeric_data),
            'data_continuity': self.validate_data_continuity(),
            'memory_usage_mb': round(self.data.memory_usage(deep=True).sum() / 1024 / 1024, 2)
        }
        
        return quality_report
    
    def _find_high_correlations(self, numeric_data: pd.DataFrame, threshold: float = 0.95) -> List[tuple]:
        """ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ìŒ ì°¾ê¸°"""
        if numeric_data.shape[1] < 2:
            return []
        
        corr_matrix = numeric_data.corr().abs()
        
        # ìƒì‚¼ê° í–‰ë ¬ë§Œ ê³ ë ¤ (ì¤‘ë³µ ì œê±°)
        upper_triangle = corr_matrix.where(
            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
        )
        
        # ë†’ì€ ìƒê´€ê´€ê³„ ìŒ ì°¾ê¸°
        high_corr_pairs = []
        for col1 in upper_triangle.columns:
            for col2 in upper_triangle.index:
                corr_val = upper_triangle.loc[col2, col1]
                if not np.isnan(corr_val) and corr_val > threshold:
                    high_corr_pairs.append((col1, col2, round(corr_val, 3)))
        
        return high_corr_pairs[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜