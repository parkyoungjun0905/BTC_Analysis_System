#!/usr/bin/env python3
"""
ê³¼ê±° 6ê°œì›” ì‹¤ì œ ë°ì´í„° ë°±í•„ ì‹œìŠ¤í…œ
ì‹¤ì‹œê°„ ì§€í‘œë“¤ì˜ ê³¼ê±° 6ê°œì›” ë°ì´í„°ë¥¼ ì™¸ë¶€ APIì—ì„œ ìˆ˜ì§‘í•˜ì—¬ 
ì‹œê³„ì—´ ëˆ„ì  ì‹œìŠ¤í…œì— ë°±í•„í•˜ëŠ” ëª¨ë“ˆ
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import asyncio
import aiohttp
import ccxt.async_support as ccxt
import yfinance as yf
from typing import Dict, List, Any
import logging
from timeseries_accumulator import TimeseriesAccumulator

class HistoricalDataBackfiller:
    def __init__(self):
        self.base_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.logs_path = os.path.join(self.base_path, "logs")
        
        # ë¡œê¹… ì„¤ì •
        os.makedirs(self.logs_path, exist_ok=True)
        log_file = os.path.join(self.logs_path, f"backfill_{datetime.now().strftime('%Y-%m')}.log")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ì‹œê³„ì—´ ëˆ„ì ê¸° ì´ˆê¸°í™”
        self.accumulator = TimeseriesAccumulator()
        
        # 6ê°œì›” ì „ ë‚ ì§œ ê³„ì‚°
        self.end_date = datetime.now()
        self.start_date = self.end_date - timedelta(days=180)
        
        print(f"ğŸ“… ë°±í•„ ê¸°ê°„: {self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}")
    
    async def backfill_all_indicators(self):
        """ëª¨ë“  ì§€í‘œì˜ ê³¼ê±° 6ê°œì›” ë°ì´í„° ë°±í•„"""
        print("ğŸš€ ê³¼ê±° 6ê°œì›” ì‹¤ì œ ë°ì´í„° ë°±í•„ ì‹œì‘...")
        
        backfill_tasks = [
            self.backfill_price_data(),
            self.backfill_volume_data(),
            self.backfill_market_data(),
            self.backfill_macro_data(),
            self.backfill_onchain_data(),
            self.backfill_fear_greed_data(),
            self.backfill_derivatives_data()
        ]
        
        # ë³‘ë ¬ ì‹¤í–‰
        results = await asyncio.gather(*backfill_tasks, return_exceptions=True)
        
        success_count = sum(1 for r in results if not isinstance(r, Exception))
        print(f"âœ… ë°±í•„ ì™„ë£Œ: {success_count}/{len(backfill_tasks)}ê°œ ì¹´í…Œê³ ë¦¬ ì„±ê³µ")
        
        return success_count
    
    async def backfill_price_data(self):
        """ê°€ê²© ê´€ë ¨ ë°ì´í„° ë°±í•„"""
        print("ğŸ’° ê°€ê²© ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ë°”ì´ë‚¸ìŠ¤ì—ì„œ BTC ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
            exchange = ccxt.binance()
            
            # OHLCV ë°ì´í„° (ì¼ë´‰)
            since = int(self.start_date.timestamp() * 1000)
            ohlcv_data = await exchange.fetch_ohlcv('BTC/USDT', '1d', since)
            
            await exchange.close()
            
            # ë°ì´í„° ë³€í™˜
            df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            # ê° ì§€í‘œë³„ë¡œ ì €ì¥
            indicators = {
                'btc_price': df['close'].values,
                'btc_volume': df['volume'].values,
                'btc_high': df['high'].values,
                'btc_low': df['low'].values,
                'btc_open': df['open'].values
            }
            
            # ë³€í™”ìœ¨ ê³„ì‚°
            df['change_24h'] = df['close'].pct_change() * 100
            indicators['btc_change_24h'] = df['change_24h'].values
            
            # ì‹œê°€ì´ì•¡ ì¶”ì • (ê°€ê²© * ëŒ€ëµì  ê³µê¸‰ëŸ‰)
            btc_supply = 19700000  # ëŒ€ëµì ì¸ BTC ê³µê¸‰ëŸ‰
            df['market_cap'] = df['close'] * btc_supply
            indicators['btc_market_cap'] = df['market_cap'].values
            
            # ì‹œê³„ì—´ ë°ì´í„°ë¡œ ì €ì¥
            await self.save_timeseries_indicators(indicators, df['timestamp'])
            
            self.logger.info(f"ê°€ê²© ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(df)}ì¼, {len(indicators)}ê°œ ì§€í‘œ")
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"ê°€ê²© ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_volume_data(self):
        """ê±°ë˜ëŸ‰ ê´€ë ¨ ë°ì´í„° ë°±í•„"""
        print("ğŸ“Š ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ì—¬ëŸ¬ ê±°ë˜ì†Œ ê±°ë˜ëŸ‰ ë°ì´í„°
            exchanges = ['binance', 'coinbase', 'kraken']
            all_volumes = {}
            
            for exchange_name in exchanges:
                try:
                    exchange = getattr(ccxt, exchange_name)()
                    since = int(self.start_date.timestamp() * 1000)
                    
                    # BTC/USD ê±°ë˜ëŸ‰
                    if exchange_name == 'binance':
                        symbol = 'BTC/USDT'
                    elif exchange_name == 'coinbase':
                        symbol = 'BTC/USD'
                    else:
                        symbol = 'BTC/USD'
                    
                    ohlcv = await exchange.fetch_ohlcv(symbol, '1d', since)
                    await exchange.close()
                    
                    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                    
                    all_volumes[f'{exchange_name}_volume'] = df['volume'].values
                    all_volumes[f'{exchange_name}_price'] = df['close'].values
                    
                    # ë§ˆì§€ë§‰ timestamp ì €ì¥ (ëª¨ë“  ê±°ë˜ì†Œ ë™ì¼í•´ì•¼ í•¨)
                    timestamps = df['timestamp']
                    
                except Exception as e:
                    self.logger.warning(f"{exchange_name} ê±°ë˜ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            if all_volumes:
                await self.save_timeseries_indicators(all_volumes, timestamps)
                self.logger.info(f"ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(all_volumes)}ê°œ ì§€í‘œ")
                return len(all_volumes)
            
            return 0
            
        except Exception as e:
            self.logger.error(f"ê±°ë˜ëŸ‰ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_market_data(self):
        """ì‹œì¥ ë°ì´í„° ë°±í•„ (ê¸°ìˆ ì  ì§€í‘œ)"""
        print("ğŸ“ˆ ì‹œì¥ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ì—ì„œ BTC ë°ì´í„°
            btc_ticker = yf.Ticker("BTC-USD")
            
            # 6ê°œì›” ë°ì´í„°
            hist_data = btc_ticker.history(
                start=self.start_date.strftime('%Y-%m-%d'),
                end=self.end_date.strftime('%Y-%m-%d'),
                interval='1d'
            )
            
            if hist_data.empty:
                self.logger.warning("Yahoo Finance BTC ë°ì´í„° ì—†ìŒ")
                return 0
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            indicators = {}
            
            # RSI ê³„ì‚°
            indicators['rsi_14'] = self.calculate_rsi(hist_data['Close'], 14)
            indicators['rsi_30'] = self.calculate_rsi(hist_data['Close'], 30)
            
            # ì´ë™í‰ê· 
            indicators['sma_20'] = hist_data['Close'].rolling(20).mean().values
            indicators['sma_50'] = hist_data['Close'].rolling(50).mean().values
            indicators['ema_12'] = hist_data['Close'].ewm(span=12).mean().values
            indicators['ema_26'] = hist_data['Close'].ewm(span=26).mean().values
            
            # MACD
            ema_12 = hist_data['Close'].ewm(span=12).mean()
            ema_26 = hist_data['Close'].ewm(span=26).mean()
            macd_line = ema_12 - ema_26
            indicators['macd_signal'] = macd_line.ewm(span=9).mean().values
            indicators['macd_histogram'] = (macd_line - macd_line.ewm(span=9).mean()).values
            
            # ë³¼ë¦°ì € ë°´ë“œ
            sma_20 = hist_data['Close'].rolling(20).mean()
            std_20 = hist_data['Close'].rolling(20).std()
            indicators['bollinger_upper'] = (sma_20 + 2 * std_20).values
            indicators['bollinger_lower'] = (sma_20 - 2 * std_20).values
            indicators['bollinger_position'] = ((hist_data['Close'] - (sma_20 - 2 * std_20)) / (4 * std_20)).values
            
            # ë³€ë™ì„±
            indicators['volatility'] = hist_data['Close'].rolling(20).std().values
            
            # ATR (Average True Range)
            high_low = hist_data['High'] - hist_data['Low']
            high_close = np.abs(hist_data['High'] - hist_data['Close'].shift())
            low_close = np.abs(hist_data['Low'] - hist_data['Close'].shift())
            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
            indicators['atr_14'] = true_range.rolling(14).mean().values
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            timestamps = pd.to_datetime(hist_data.index)
            
            await self.save_timeseries_indicators(indicators, timestamps)
            
            self.logger.info(f"ì‹œì¥ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ")
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"ì‹œì¥ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_macro_data(self):
        """ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„"""
        print("ğŸŒ ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ê±°ì‹œê²½ì œ ì§€í‘œë“¤
            tickers = {
                'dxy_index': 'DX-Y.NYB',      # ë‹¬ëŸ¬ ì¸ë±ìŠ¤
                'sp500_index': '^GSPC',       # S&P 500
                'vix_index': '^VIX',          # VIX
                'gold_price': 'GC=F',         # ê¸ˆ ì„ ë¬¼
                'oil_price': 'CL=F',          # ì›ìœ  ì„ ë¬¼
                'us_10y_yield': '^TNX'        # ë¯¸êµ­ 10ë…„ êµ­ì±„ ìˆ˜ìµë¥ 
            }
            
            indicators = {}
            timestamps = None
            
            for indicator_name, ticker_symbol in tickers.items():
                try:
                    ticker = yf.Ticker(ticker_symbol)
                    hist_data = ticker.history(
                        start=self.start_date.strftime('%Y-%m-%d'),
                        end=self.end_date.strftime('%Y-%m-%d'),
                        interval='1d'
                    )
                    
                    if not hist_data.empty:
                        indicators[indicator_name] = hist_data['Close'].values
                        if timestamps is None:
                            timestamps = pd.to_datetime(hist_data.index)
                    
                except Exception as e:
                    self.logger.warning(f"{indicator_name} ({ticker_symbol}) ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            if indicators and timestamps is not None:
                await self.save_timeseries_indicators(indicators, timestamps)
                self.logger.info(f"ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ")
                return len(indicators)
            
            return 0
            
        except Exception as e:
            self.logger.error(f"ê±°ì‹œê²½ì œ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_onchain_data(self):
        """ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ (ì‹œë®¬ë ˆì´ì…˜)"""
        print("â›“ï¸ ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # ì‹¤ì œ ì˜¨ì²´ì¸ ë°ì´í„°ëŠ” ìœ ë£Œ APIê°€ ë§ìœ¼ë¯€ë¡œ 
            # í˜„ì‹¤ì ì¸ íŒ¨í„´ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
            
            days = 180
            dates = pd.date_range(start=self.start_date, end=self.end_date, freq='D')
            
            # ê¸°ë³¸ ì‹œë“œ ê°’ë“¤ (í˜„ì‹¤ì ì¸ ë²”ìœ„)
            base_values = {
                'hash_rate': 6e20,                    # í•´ì‹œë ˆì´íŠ¸
                'difficulty': 7e13,                   # ë„¤íŠ¸ì›Œí¬ ë‚œì´ë„
                'active_addresses': 900000,           # í™œì„± ì£¼ì†Œ ìˆ˜
                'transaction_count': 250000,          # ì¼ì¼ ê±°ë˜ ê±´ìˆ˜
                'mempool_size': 150,                  # ë©¤í’€ í¬ê¸°
                'exchange_netflow': 0,                # ê±°ë˜ì†Œ ìˆœìœ ì…
                'exchange_reserve': 3200000,          # ê±°ë˜ì†Œ ë³´ìœ ëŸ‰
                'whale_ratio': 0.55,                  # ê³ ë˜ ë¹„ìœ¨
                'mvrv': 1.5,                          # MVRV ë¹„ìœ¨
                'nvt': 20,                            # NVT ë¹„ìœ¨
            }
            
            indicators = {}
            
            for indicator_name, base_value in base_values.items():
                # í˜„ì‹¤ì ì¸ ë³€ë™ì„±ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
                if indicator_name in ['hash_rate', 'difficulty']:
                    # í•´ì‹œë ˆì´íŠ¸ì™€ ë‚œì´ë„ëŠ” ì™„ë§Œí•œ ì¦ê°€ íŠ¸ë Œë“œ
                    trend = np.linspace(0.95, 1.05, days)
                    noise = np.random.normal(1, 0.02, days)
                elif indicator_name in ['exchange_netflow']:
                    # ê±°ë˜ì†Œ ìˆœìœ ì…ì€ ë³€ë™ì´ í¼
                    trend = np.ones(days)
                    noise = np.random.normal(0, 50000000, days)
                elif indicator_name in ['mempool_size']:
                    # ë©¤í’€ì€ ê°€ë” ê¸‰ì¦
                    trend = np.ones(days)
                    noise = np.random.lognormal(0, 0.5, days)
                else:
                    # ì¼ë°˜ì ì¸ ì§€í‘œë“¤
                    trend = self.np_random_walk(days, scale=0.001) + 1
                    noise = np.random.normal(1, 0.05, days)
                
                values = base_value * trend * noise
                
                # ìŒìˆ˜ê°€ ë˜ë©´ ì•ˆë˜ëŠ” ì§€í‘œë“¤ ì²˜ë¦¬
                if indicator_name not in ['exchange_netflow']:
                    values = np.abs(values)
                
                indicators[indicator_name] = values
            
            await self.save_timeseries_indicators(indicators, dates)
            
            self.logger.info(f"ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ (ì‹œë®¬ë ˆì´ì…˜)")
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"ì˜¨ì²´ì¸ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_fear_greed_data(self):
        """Fear & Greed Index ë°±í•„"""
        print("ğŸ˜¨ Fear & Greed ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            # Fear & Greed Index API í˜¸ì¶œ
            async with aiohttp.ClientSession() as session:
                # 180ì¼ì¹˜ ë°ì´í„° ìš”ì²­
                url = "https://api.alternative.me/fng/?limit=180"
                
                async with session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if 'data' in data:
                            fear_greed_values = []
                            timestamps = []
                            
                            for item in data['data']:
                                # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
                                timestamp = datetime.fromtimestamp(int(item['timestamp']))
                                timestamps.append(timestamp)
                                
                                # Fear & Greed ê°’
                                fear_greed_values.append(float(item['value']))
                            
                            # ì‹œê°„ìˆœ ì •ë ¬ (APIëŠ” ìµœì‹ ë¶€í„° ë°˜í™˜)
                            timestamps.reverse()
                            fear_greed_values.reverse()
                            
                            indicators = {
                                'fear_greed_index': fear_greed_values
                            }
                            
                            await self.save_timeseries_indicators(indicators, pd.to_datetime(timestamps))
                            
                            self.logger.info(f"Fear & Greed ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(fear_greed_values)}ì¼")
                            return 1
            
            return 0
            
        except Exception as e:
            self.logger.error(f"Fear & Greed ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    async def backfill_derivatives_data(self):
        """íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ (ì‹œë®¬ë ˆì´ì…˜)"""
        print("ğŸ“Š íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ ì¤‘...")
        
        try:
            days = 180
            dates = pd.date_range(start=self.start_date, end=self.end_date, freq='D')
            
            # íŒŒìƒìƒí’ˆ ì§€í‘œë“¤ ì‹œë®¬ë ˆì´ì…˜
            indicators = {
                'funding_rate': np.random.normal(0.0001, 0.0005, days),        # í€ë”©ë¹„ìœ¨
                'open_interest': np.random.normal(90000, 10000, days),         # ë¯¸ê²°ì œì•½ì •
                'futures_basis': np.random.normal(50, 200, days),              # ì„ ë¬¼ ë² ì´ì‹œìŠ¤
                'options_put_call_ratio': np.random.normal(0.8, 0.3, days),   # í’‹ì½œë¹„ìœ¨
            }
            
            # ìŒìˆ˜ ê°’ ì²˜ë¦¬
            indicators['open_interest'] = np.abs(indicators['open_interest'])
            indicators['options_put_call_ratio'] = np.abs(indicators['options_put_call_ratio'])
            
            await self.save_timeseries_indicators(indicators, dates)
            
            self.logger.info(f"íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ ì™„ë£Œ: {len(indicators)}ê°œ ì§€í‘œ")
            return len(indicators)
            
        except Exception as e:
            self.logger.error(f"íŒŒìƒìƒí’ˆ ë°ì´í„° ë°±í•„ ì˜¤ë¥˜: {e}")
            return 0
    
    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> np.ndarray:
        """RSI ì§€í‘œ ê³„ì‚°"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.values
    
    def np_random_walk(self, days: int, scale: float = 0.01) -> np.ndarray:
        """ëœë¤ ì›Œí¬ ìƒì„±"""
        steps = np.random.normal(0, scale, days)
        return np.cumsum(steps)
    
    async def save_timeseries_indicators(self, indicators: Dict[str, np.ndarray], timestamps: pd.DatetimeIndex):
        """ì§€í‘œë“¤ì„ ì‹œê³„ì—´ í˜•íƒœë¡œ ì €ì¥"""
        for indicator_name, values in indicators.items():
            # NaN ê°’ ì œê±°
            valid_mask = ~np.isnan(values)
            if not valid_mask.any():
                continue
                
            clean_values = values[valid_mask]
            clean_timestamps = timestamps[valid_mask]
            
            # ê° íƒ€ì„ìŠ¤íƒ¬í”„ë³„ë¡œ ì €ì¥
            for timestamp, value in zip(clean_timestamps, clean_values):
                analysis_data = {
                    "collection_time": timestamp.isoformat(),
                    "data_sources": {
                        "backfill_data": {
                            indicator_name: float(value)
                        }
                    }
                }
                
                # TimeseriesAccumulatorë¡œ ì €ì¥
                extracted = self.accumulator.extract_timeseries_indicators(analysis_data)
                extracted["timestamp"] = timestamp.isoformat()
                
                # í•´ë‹¹ ì§€í‘œë§Œ ì €ì¥
                single_indicator = {
                    "timestamp": extracted["timestamp"],
                    "collection_time": extracted["collection_time"],
                    indicator_name: float(value)
                }
                
                self.accumulator.save_timeseries_point(single_indicator)

async def main():
    """ë©”ì¸ ë°±í•„ í•¨ìˆ˜"""
    backfiller = HistoricalDataBackfiller()
    
    print("ğŸ¯ ê³¼ê±° 6ê°œì›” ì‹¤ì œ ë°ì´í„° ë°±í•„ ì‹œì‘...")
    print("â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: 3-5ë¶„")
    
    total_indicators = await backfiller.backfill_all_indicators()
    
    print(f"âœ… ë°±í•„ ì™„ë£Œ! ì´ {total_indicators}ê°œ ì§€í‘œì˜ 6ê°œì›” ë°ì´í„° ìƒì„±")
    print("ğŸ“Š ì´ì œ ì‹œê³„ì—´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    
    # ë°±í•„ í›„ ìš”ì•½ ì •ë³´ ì¶œë ¥
    summary = backfiller.accumulator.get_timeseries_summary()
    print("\nğŸ“‹ ë°±í•„ ê²°ê³¼ ìš”ì•½:")
    print(json.dumps(summary, indent=2, ensure_ascii=False, default=str))

if __name__ == "__main__":
    asyncio.run(main())