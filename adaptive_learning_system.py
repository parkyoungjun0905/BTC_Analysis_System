"""
ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ v1.0
ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•™ìŠµí•˜ì—¬ ì •í™•ë„ë¥¼ ì§€ì†ì ìœ¼ë¡œ ê°œì„ 
"""

import os
import json
import sqlite3
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import asyncio
import logging
from dataclasses import dataclass, asdict
import pickle

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class PredictionRecord:
    """ì˜ˆì¸¡ ê¸°ë¡"""
    id: str
    timestamp: datetime
    current_price: float
    predicted_price: float
    predicted_direction: str
    confidence: float
    actual_price: Optional[float] = None
    actual_direction: Optional[str] = None
    accuracy_score: Optional[float] = None
    verified_at: Optional[datetime] = None
    model_version: str = "v1.0"

@dataclass
class ModelPerformance:
    """ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ"""
    model_name: str
    accuracy: float
    directional_accuracy: float
    mae: float  # Mean Absolute Error
    mse: float  # Mean Squared Error
    sample_count: int
    last_updated: datetime

class AdaptiveLearningSystem:
    """ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.base_path = "/Users/parkyoungjun/Desktop/BTC_Analysis_System"
        self.db_path = os.path.join(self.base_path, "learning_database.db")
        self.model_weights_path = os.path.join(self.base_path, "adaptive_weights.pkl")
        
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ì‹œì‘ì )
        self.base_weights = {
            "momentum_divergence": 0.20,
            "volume_price_analysis": 0.18,
            "whale_sentiment": 0.15,
            "funding_momentum": 0.12,
            "order_flow_imbalance": 0.10,
            "correlation_break": 0.08,
            "volatility_regime": 0.07,
            "social_momentum": 0.05,
            "institutional_flow": 0.05
        }
        
        # í˜„ì¬ ê°€ì¤‘ì¹˜ (í•™ìŠµìœ¼ë¡œ ì—…ë°ì´íŠ¸ë¨)
        self.current_weights = self.load_weights()
        
        # ì„±ëŠ¥ ì„ê³„ê°’
        self.performance_thresholds = {
            "min_accuracy": 0.6,      # ìµœì†Œ 60% ì •í™•ë„
            "min_samples": 10,        # ìµœì†Œ 10ê°œ ìƒ˜í”Œ
            "confidence_threshold": 0.7,  # 70% ì´ìƒ ì‹ ë¢°ë„ë§Œ í•™ìŠµì— ì‚¬ìš©
            "learning_rate": 0.1      # í•™ìŠµë¥ 
        }
        
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ì˜ˆì¸¡ ê¸°ë¡ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS predictions (
                    id TEXT PRIMARY KEY,
                    timestamp TEXT NOT NULL,
                    current_price REAL NOT NULL,
                    predicted_price REAL NOT NULL,
                    predicted_direction TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    actual_price REAL,
                    actual_direction TEXT,
                    accuracy_score REAL,
                    verified_at TEXT,
                    model_version TEXT,
                    raw_data TEXT
                )
            ''')
            
            # ëª¨ë¸ ì„±ëŠ¥ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS model_performance (
                    model_name TEXT PRIMARY KEY,
                    accuracy REAL NOT NULL,
                    directional_accuracy REAL NOT NULL,
                    mae REAL NOT NULL,
                    mse REAL NOT NULL,
                    sample_count INTEGER NOT NULL,
                    last_updated TEXT NOT NULL
                )
            ''')
            
            # ê°€ì¤‘ì¹˜ íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS weight_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    weights TEXT NOT NULL,
                    performance_score REAL,
                    reason TEXT
                )
            ''')
            
            conn.commit()
            conn.close()
            
            logger.info("âœ… í•™ìŠµ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def save_prediction(self, prediction_data: Dict) -> str:
        """ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        try:
            prediction_id = f"pred_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            record = PredictionRecord(
                id=prediction_id,
                timestamp=datetime.now(),
                current_price=prediction_data.get("current_price", 0),
                predicted_price=prediction_data.get("predicted_price", 0),
                predicted_direction=prediction_data.get("direction", "NEUTRAL"),
                confidence=prediction_data.get("confidence", 0.5),
                model_version=prediction_data.get("model_version", "v1.0")
            )
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO predictions 
                (id, timestamp, current_price, predicted_price, predicted_direction, 
                 confidence, model_version, raw_data)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                record.id,
                record.timestamp.isoformat(),
                record.current_price,
                record.predicted_price,
                record.predicted_direction,
                record.confidence,
                record.model_version,
                json.dumps(prediction_data)
            ))
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… ì˜ˆì¸¡ ì €ì¥: {prediction_id}")
            return prediction_id
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    async def verify_and_learn(self) -> Dict:
        """ì˜ˆì¸¡ ê²€ì¦ ë° í•™ìŠµ"""
        try:
            logger.info("ğŸ” ì˜ˆì¸¡ ê²°ê³¼ ê²€ì¦ ì‹œì‘...")
            
            # ê²€ì¦ ëŒ€ìƒ ì˜ˆì¸¡ë“¤ ì¡°íšŒ (1ì‹œê°„ ì´ìƒ ì§€ë‚œ ê²ƒë“¤)
            cutoff_time = datetime.now() - timedelta(hours=1)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM predictions 
                WHERE verified_at IS NULL 
                AND timestamp < ? 
                ORDER BY timestamp DESC 
                LIMIT 50
            ''', (cutoff_time.isoformat(),))
            
            unverified = cursor.fetchall()
            conn.close()
            
            if not unverified:
                logger.info("ê²€ì¦í•  ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤")
                return {"verified": 0, "learned": 0}
            
            # í˜„ì¬ ê°€ê²© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            current_data = await self.get_current_market_data()
            current_price = current_data.get("price", 0) if current_data else 0
            
            verified_count = 0
            learned_count = 0
            
            for record in unverified:
                # ì˜ˆì¸¡ ê²€ì¦
                verification_result = await self.verify_prediction(record, current_price)
                
                if verification_result["verified"]:
                    verified_count += 1
                    
                    # ë†’ì€ ì‹ ë¢°ë„ ì˜ˆì¸¡ë§Œ í•™ìŠµì— ì‚¬ìš©
                    if record[5] >= self.performance_thresholds["confidence_threshold"]:  # confidence
                        await self.learn_from_prediction(record, verification_result)
                        learned_count += 1
            
            # ëª¨ë¸ ì„±ëŠ¥ ì—…ë°ì´íŠ¸
            await self.update_model_performance()
            
            # ê°€ì¤‘ì¹˜ ìµœì í™”
            if learned_count > 0:
                await self.optimize_weights()
            
            logger.info(f"âœ… ê²€ì¦: {verified_count}ê°œ, í•™ìŠµ: {learned_count}ê°œ")
            
            return {
                "verified": verified_count,
                "learned": learned_count,
                "current_accuracy": await self.get_current_accuracy()
            }
            
        except Exception as e:
            logger.error(f"ê²€ì¦ ë° í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def verify_prediction(self, record: tuple, current_price: float) -> Dict:
        """ê°œë³„ ì˜ˆì¸¡ ê²€ì¦"""
        try:
            # record êµ¬ì¡°: id, timestamp, current_price, predicted_price, predicted_direction, confidence, ...
            pred_id = record[0]
            timestamp = datetime.fromisoformat(record[1])
            original_price = record[2]
            predicted_price = record[3]
            predicted_direction = record[4]
            confidence = record[5]
            
            # ì‹¤ì œ ë°©í–¥ ê³„ì‚°
            price_change = current_price - original_price
            actual_direction = "BULLISH" if price_change > 0 else "BEARISH" if price_change < 0 else "NEUTRAL"
            
            # ì •í™•ë„ ì ìˆ˜ ê³„ì‚°
            price_accuracy = 1 - abs(predicted_price - current_price) / original_price
            direction_correct = (predicted_direction == actual_direction)
            
            # ì¢…í•© ì •í™•ë„ (ê°€ê²© 50% + ë°©í–¥ 50%)
            accuracy_score = (price_accuracy * 0.5) + (1.0 if direction_correct else 0.0) * 0.5
            
            # DB ì—…ë°ì´íŠ¸
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                UPDATE predictions 
                SET actual_price = ?, actual_direction = ?, accuracy_score = ?, verified_at = ?
                WHERE id = ?
            ''', (
                current_price,
                actual_direction,
                accuracy_score,
                datetime.now().isoformat(),
                pred_id
            ))
            
            conn.commit()
            conn.close()
            
            return {
                "verified": True,
                "accuracy_score": accuracy_score,
                "direction_correct": direction_correct,
                "price_accuracy": price_accuracy,
                "actual_direction": actual_direction
            }
            
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {"verified": False, "error": str(e)}
    
    async def learn_from_prediction(self, record: tuple, verification: Dict):
        """ì˜ˆì¸¡ ê²°ê³¼ë¡œë¶€í„° í•™ìŠµ"""
        try:
            # ì˜ˆì¸¡ì´ ì¢‹ì•˜ë‹¤ë©´ í•´ë‹¹ ì‹ í˜¸ë“¤ì˜ ê°€ì¤‘ì¹˜ ì¦ê°€
            # ì˜ˆì¸¡ì´ ë‚˜ë¹´ë‹¤ë©´ ê°€ì¤‘ì¹˜ ê°ì†Œ
            
            accuracy_score = verification["accuracy_score"]
            learning_rate = self.performance_thresholds["learning_rate"]
            
            # ê°€ì¤‘ì¹˜ ì¡°ì • ë¡œì§
            if accuracy_score > 0.7:  # ì¢‹ì€ ì˜ˆì¸¡
                # ì„±ê³µì ì¸ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ìš”ì†Œë“¤ ê°•í™”
                await self.strengthen_successful_patterns(record, accuracy_score)
            elif accuracy_score < 0.3:  # ë‚˜ìœ ì˜ˆì¸¡
                # ì‹¤íŒ¨í•œ ì˜ˆì¸¡ì— ê¸°ì—¬í•œ ìš”ì†Œë“¤ ì•½í™”
                await self.weaken_failed_patterns(record, accuracy_score)
            
            logger.debug(f"í•™ìŠµ ì™„ë£Œ: ì •í™•ë„ {accuracy_score:.2f}")
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ì‹¤íŒ¨: {e}")
    
    async def strengthen_successful_patterns(self, record: tuple, accuracy: float):
        """ì„±ê³µ íŒ¨í„´ ê°•í™”"""
        try:
            # ì„±ê³µë„ì— ë¹„ë¡€í•˜ì—¬ ì£¼ìš” ì§€í‘œë“¤ì˜ ê°€ì¤‘ì¹˜ ì¦ê°€
            boost_factor = (accuracy - 0.7) * 0.1  # ìµœëŒ€ 3% ì¦ê°€
            
            # í˜„ì¬ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ì§€í‘œë“¤ì„ ë” ê°•í™”
            high_weight_indicators = [
                "momentum_divergence",
                "volume_price_analysis", 
                "whale_sentiment"
            ]
            
            for indicator in high_weight_indicators:
                if indicator in self.current_weights:
                    self.current_weights[indicator] += boost_factor
                    
            self.normalize_weights()
            
        except Exception as e:
            logger.error(f"ì„±ê³µ íŒ¨í„´ ê°•í™” ì‹¤íŒ¨: {e}")
    
    async def weaken_failed_patterns(self, record: tuple, accuracy: float):
        """ì‹¤íŒ¨ íŒ¨í„´ ì•½í™”"""
        try:
            # ì‹¤íŒ¨ë„ì— ë¹„ë¡€í•˜ì—¬ ê°€ì¤‘ì¹˜ ê°ì†Œ
            penalty_factor = (0.3 - accuracy) * 0.05  # ìµœëŒ€ 1.5% ê°ì†Œ
            
            # ëª¨ë“  ì§€í‘œë¥¼ ì•½ê°„ì”© ê°ì†Œ
            for indicator in self.current_weights:
                self.current_weights[indicator] -= penalty_factor
                # ìµœì†Œê°’ ë³´ì¥
                self.current_weights[indicator] = max(self.current_weights[indicator], 0.01)
                
            self.normalize_weights()
            
        except Exception as e:
            logger.error(f"ì‹¤íŒ¨ íŒ¨í„´ ì•½í™” ì‹¤íŒ¨: {e}")
    
    def normalize_weights(self):
        """ê°€ì¤‘ì¹˜ ì •ê·œí™”"""
        total_weight = sum(self.current_weights.values())
        if total_weight > 0:
            for key in self.current_weights:
                self.current_weights[key] /= total_weight
    
    async def update_model_performance(self):
        """ëª¨ë¸ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ì§€ë‚œ 7ì¼ê°„ì˜ ê²€ì¦ëœ ì˜ˆì¸¡ë“¤ ì¡°íšŒ
            week_ago = (datetime.now() - timedelta(days=7)).isoformat()
            
            cursor.execute('''
                SELECT accuracy_score, predicted_direction, actual_direction,
                       predicted_price, actual_price, current_price
                FROM predictions 
                WHERE verified_at IS NOT NULL 
                AND timestamp > ?
            ''', (week_ago,))
            
            results = cursor.fetchall()
            
            if len(results) >= self.performance_thresholds["min_samples"]:
                accuracies = [r[0] for r in results if r[0] is not None]
                direction_correct = [r[1] == r[2] for r in results if r[1] and r[2]]
                
                # ì„±ëŠ¥ ê³„ì‚°
                avg_accuracy = np.mean(accuracies) if accuracies else 0
                directional_accuracy = np.mean(direction_correct) if direction_correct else 0
                
                # MAE, MSE ê³„ì‚°
                price_errors = []
                for r in results:
                    if r[3] and r[4]:  # predicted_price, actual_price
                        error = abs(r[3] - r[4])
                        price_errors.append(error)
                
                mae = np.mean(price_errors) if price_errors else 0
                mse = np.mean([e**2 for e in price_errors]) if price_errors else 0
                
                # ì„±ëŠ¥ ì €ì¥
                performance = ModelPerformance(
                    model_name="enhanced_v2.0",
                    accuracy=avg_accuracy,
                    directional_accuracy=directional_accuracy,
                    mae=mae,
                    mse=mse,
                    sample_count=len(results),
                    last_updated=datetime.now()
                )
                
                cursor.execute('''
                    INSERT OR REPLACE INTO model_performance
                    (model_name, accuracy, directional_accuracy, mae, mse, sample_count, last_updated)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    performance.model_name,
                    performance.accuracy,
                    performance.directional_accuracy,
                    performance.mae,
                    performance.mse,
                    performance.sample_count,
                    performance.last_updated.isoformat()
                ))
                
                conn.commit()
                logger.info(f"âœ… ëª¨ë¸ ì„±ëŠ¥ ì—…ë°ì´íŠ¸: ì •í™•ë„ {avg_accuracy:.1%}, ë°©í–¥ì„± {directional_accuracy:.1%}")
            
            conn.close()
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def optimize_weights(self):
        """ê°€ì¤‘ì¹˜ ìµœì í™”"""
        try:
            # í˜„ì¬ ì„±ëŠ¥ì´ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¬ì¡°ì •
            current_accuracy = await self.get_current_accuracy()
            
            if current_accuracy < self.performance_thresholds["min_accuracy"]:
                logger.info("ì„±ëŠ¥ì´ ë‚®ì•„ ê°€ì¤‘ì¹˜ ì¬ì¡°ì • ì‹¤í–‰")
                
                # ë² ì´ìŠ¤ ê°€ì¤‘ì¹˜ë¡œ ì¼ë¶€ íšŒê·€
                regression_factor = 0.2
                for key in self.current_weights:
                    current_val = self.current_weights[key]
                    base_val = self.base_weights.get(key, 0.1)
                    self.current_weights[key] = current_val * (1 - regression_factor) + base_val * regression_factor
            
            # ê°€ì¤‘ì¹˜ ì €ì¥
            self.save_weights()
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            await self.save_weight_history("optimization", current_accuracy)
            
        except Exception as e:
            logger.error(f"ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤íŒ¨: {e}")
    
    def save_weights(self):
        """ê°€ì¤‘ì¹˜ ì €ì¥"""
        try:
            with open(self.model_weights_path, 'wb') as f:
                pickle.dump(self.current_weights, f)
            logger.debug("ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ê°€ì¤‘ì¹˜ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_weights(self) -> Dict:
        """ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        try:
            if os.path.exists(self.model_weights_path):
                with open(self.model_weights_path, 'rb') as f:
                    weights = pickle.load(f)
                logger.info("âœ… ê¸°ì¡´ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
                return weights
            else:
                logger.info("ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì‚¬ìš©")
                return self.base_weights.copy()
        except Exception as e:
            logger.error(f"ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self.base_weights.copy()
    
    async def save_weight_history(self, reason: str, performance_score: float):
        """ê°€ì¤‘ì¹˜ ë³€ê²½ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO weight_history (timestamp, weights, performance_score, reason)
                VALUES (?, ?, ?, ?)
            ''', (
                datetime.now().isoformat(),
                json.dumps(self.current_weights),
                performance_score,
                reason
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ê°€ì¤‘ì¹˜ íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def get_current_accuracy(self) -> float:
        """í˜„ì¬ ì •í™•ë„ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT accuracy FROM model_performance 
                WHERE model_name = 'enhanced_v2.0'
                ORDER BY last_updated DESC LIMIT 1
            ''')
            
            result = cursor.fetchone()
            conn.close()
            
            return result[0] if result else 0.5
            
        except Exception as e:
            logger.error(f"í˜„ì¬ ì •í™•ë„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def get_current_market_data(self) -> Optional[Dict]:
        """í˜„ì¬ ì‹œì¥ ë°ì´í„° ì¡°íšŒ"""
        try:
            # enhanced_data_collectorì—ì„œ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            historical_path = os.path.join(self.base_path, "historical_data")
            if not os.path.exists(historical_path):
                return None
                
            files = [f for f in os.listdir(historical_path) 
                     if f.startswith("btc_analysis_") and f.endswith(".json")]
            
            if not files:
                return None
                
            latest_file = sorted(files)[-1]
            file_path = os.path.join(historical_path, latest_file)
            
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            # ê°€ê²© ì¶”ì¶œ
            paths = [
                ["data_sources", "legacy_analyzer", "market_data", "avg_price"],
                ["summary", "current_btc_price"]
            ]
            
            for path in paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value and value > 0:
                        return {"price": float(value), "data": data}
                except:
                    continue
            
            return None
            
        except Exception as e:
            logger.error(f"ì‹œì¥ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    async def get_learning_report(self) -> Dict:
        """í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # ìµœê·¼ ì„±ëŠ¥
            perf_df = pd.read_sql_query('''
                SELECT * FROM model_performance 
                ORDER BY last_updated DESC LIMIT 1
            ''', conn)
            
            # ìµœê·¼ ì˜ˆì¸¡ë“¤
            pred_df = pd.read_sql_query('''
                SELECT * FROM predictions 
                WHERE verified_at IS NOT NULL 
                ORDER BY timestamp DESC LIMIT 20
            ''', conn)
            
            # ê°€ì¤‘ì¹˜ ë³€í™”
            weight_df = pd.read_sql_query('''
                SELECT * FROM weight_history 
                ORDER BY timestamp DESC LIMIT 5
            ''', conn)
            
            conn.close()
            
            return {
                "current_performance": perf_df.to_dict('records')[0] if not perf_df.empty else {},
                "recent_predictions": pred_df.to_dict('records'),
                "weight_changes": weight_df.to_dict('records'),
                "current_weights": self.current_weights
            }
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

async def run_learning_cycle():
    """í•™ìŠµ ì‚¬ì´í´ ì‹¤í–‰"""
    print("ğŸ¤– ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘")
    print("="*50)
    
    learning_system = AdaptiveLearningSystem()
    
    # í•™ìŠµ ì‹¤í–‰
    result = await learning_system.verify_and_learn()
    
    if "error" in result:
        print(f"âŒ í•™ìŠµ ì‹¤íŒ¨: {result['error']}")
        return
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"âœ… ê²€ì¦: {result['verified']}ê°œ")
    print(f"ğŸ“š í•™ìŠµ: {result['learned']}ê°œ") 
    print(f"ğŸ¯ í˜„ì¬ ì •í™•ë„: {result['current_accuracy']:.1%}")
    
    # ìƒì„¸ ë¦¬í¬íŠ¸
    report = await learning_system.get_learning_report()
    
    if report.get("current_performance"):
        perf = report["current_performance"]
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
        print(f"  â€¢ ì „ì²´ ì •í™•ë„: {perf.get('accuracy', 0):.1%}")
        print(f"  â€¢ ë°©í–¥ì„± ì •í™•ë„: {perf.get('directional_accuracy', 0):.1%}")
        print(f"  â€¢ í‰ê·  ì˜¤ì°¨: ${perf.get('mae', 0):.0f}")
        print(f"  â€¢ ìƒ˜í”Œ ìˆ˜: {perf.get('sample_count', 0)}ê°œ")
    
    print(f"\nâš–ï¸ í˜„ì¬ ê°€ì¤‘ì¹˜ (ìƒìœ„ 5ê°œ):")
    weights = report.get("current_weights", {})
    sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)
    for name, weight in sorted_weights[:5]:
        print(f"  â€¢ {name}: {weight:.1%}")
    
    print("="*50)
    print("ğŸ‰ ì ì‘í˜• í•™ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(run_learning_cycle())