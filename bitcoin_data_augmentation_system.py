#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¹„íŠ¸ì½”ì¸ ì „ìš© ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ
- ê¸ˆìœµ ì‹œê³„ì—´ íŠ¹í™” ë°ì´í„° ì¦ê°•
- 10ë°° í›ˆë ¨ ë°ì´í„° ìƒì„± ëª©í‘œ
- ì‹œì¥ íŠ¹ì„± ë³´ì¡´ ë° ì‹ ë¢°ì„± í™•ë³´
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

import os
import sys
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Union
import logging
import pickle

# ê³¼í•™ ê³„ì‚°
from scipy import stats
from scipy.signal import savgol_filter
from scipy.interpolate import interp1d
from scipy.ndimage import gaussian_filter1d

# ë¨¸ì‹ ëŸ¬ë‹
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA, FastICA
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.model_selection import TimeSeriesSplit

# ë”¥ëŸ¬ë‹ (TensorFlow/Keras)
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlow ì—†ìŒ - GAN/VAE ê¸°ëŠ¥ ì œí•œ")

# í†µê³„ ë° ì‹œê°í™”
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.dates import DateFormatter
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BitcoinDataAugmentationSystem:
    """
    ğŸš€ ë¹„íŠ¸ì½”ì¸ ì „ìš© ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. ê¸ˆìœµ ì‹œê³„ì—´ íŠ¹í™” ì¦ê°• ê¸°ë²•
    2. ì‹œì¥ ì²´ì œë³„ ì ì‘í˜• ì¦ê°•
    3. í•©ì„± ë°ì´í„° ìƒì„± (GAN/VAE)
    4. êµì°¨ ê²€ì¦ ì „ëµ
    5. ë°ì´í„° í’ˆì§ˆ ë³´ì¦
    """
    
    def __init__(self, data_dir: str = "three_month_timeseries_data"):
        """
        ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.data_dir = data_dir
        self.logger = logging.getLogger(__name__)
        
        # ì¦ê°• íŒŒë¼ë¯¸í„°
        self.augmentation_params = {
            'noise_levels': [0.001, 0.005, 0.01, 0.02],  # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ë ˆë²¨
            'time_warp_factors': [0.8, 0.9, 1.1, 1.2],   # ì‹œê°„ ì™œê³¡ ì¸ìˆ˜
            'magnitude_warp_factors': [0.95, 0.98, 1.02, 1.05],  # í¬ê¸° ì™œê³¡ ì¸ìˆ˜
            'window_sizes': [24, 48, 72, 96],  # ìœˆë„ìš° í¬ê¸° (ì‹œê°„)
            'overlap_ratios': [0.1, 0.2, 0.3, 0.5],  # ìœˆë„ìš° ê²¹ì¹¨ ë¹„ìœ¨
        }
        
        # ì‹œì¥ ì²´ì œ ë¶„ë¥˜
        self.market_regimes = {
            'bull_market': {'volatility_threshold': 0.02, 'trend_threshold': 0.01},
            'bear_market': {'volatility_threshold': 0.03, 'trend_threshold': -0.01},
            'sideways': {'volatility_threshold': 0.015, 'trend_threshold': 0.005}
        }
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.original_data = {}
        self.augmented_data = {}
        self.synthetic_data = {}
        self.quality_metrics = {}
        
        # ëª¨ë¸ ì €ì¥ì†Œ (GAN/VAE)
        self.models = {}
        
        self.logger.info("ğŸš€ ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_bitcoin_data(self) -> Dict[str, pd.DataFrame]:
        """
        ë¹„íŠ¸ì½”ì¸ ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ
        
        Returns:
            ë¡œë“œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info("ğŸ“Š ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ë¡œë”© ì‹œì‘...")
        
        data = {}
        
        # ê°€ê²© ë°ì´í„° ë¡œë“œ
        try:
            price_files = [
                'binance_btc_1h_price_hourly.csv',
                'coinbase_btc_1h_price_hourly.csv',
            ]
            
            for file in price_files:
                file_path = os.path.join(self.data_dir, file)
                if os.path.exists(file_path):
                    df = pd.read_csv(file_path)
                    if 'timestamp' in df.columns:
                        df['timestamp'] = pd.to_datetime(df['timestamp'])
                        df = df.set_index('timestamp')
                    data[file.replace('.csv', '')] = df
                    
        except Exception as e:
            self.logger.warning(f"ê°€ê²© ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        
        # ì§€í‘œ ë°ì´í„° ë¡œë“œ (ì£¼ìš” ì§€í‘œë§Œ)
        indicator_files = [
            'fear_greed_index_raw_hourly.csv',
            'network_velocity_hourly.csv',
            'exchange_netflow_total_hourly.csv',
            'addresses_balance_gt_1btc_hourly.csv'
        ]
        
        for file in indicator_files:
            try:
                file_path = os.path.join(f"{self.data_dir}/additional_fear_greed_detailed", file)
                if not os.path.exists(file_path):
                    file_path = os.path.join(f"{self.data_dir}/additional_advanced_onchain", file)
                
                if os.path.exists(file_path):
                    df = pd.read_csv(file_path)
                    if 'timestamp' in df.columns:
                        df['timestamp'] = pd.to_datetime(df['timestamp'])
                        df = df.set_index('timestamp')
                    data[file.replace('.csv', '')] = df
                    
            except Exception as e:
                self.logger.warning(f"ì§€í‘œ {file} ë¡œë”© ì‹¤íŒ¨: {e}")
        
        self.original_data = data
        self.logger.info(f"âœ… {len(data)}ê°œ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ")
        
        return data
    
    def detect_market_regime(self, price_data: pd.DataFrame, lookback: int = 168) -> pd.Series:
        """
        ì‹œì¥ ì²´ì œ íƒì§€ (ê°•ì„¸/ì•½ì„¸/íš¡ë³´)
        
        Args:
            price_data: ê°€ê²© ë°ì´í„°
            lookback: ë¶„ì„ ê¸°ê°„ (ì‹œê°„)
            
        Returns:
            ì‹œì¥ ì²´ì œ ì‹œë¦¬ì¦ˆ
        """
        if price_data.empty or len(price_data) < lookback:
            return pd.Series(index=price_data.index, data='sideways')
        
        # ê°€ê²© ì»¬ëŸ¼ ì°¾ê¸°
        price_col = None
        for col in ['close', 'price', 'value']:
            if col in price_data.columns:
                price_col = col
                break
        
        if price_col is None:
            price_col = price_data.columns[0]
        
        prices = price_data[price_col]
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        returns = prices.pct_change().fillna(0)
        
        # ë¡¤ë§ í†µê³„
        rolling_vol = returns.rolling(lookback).std()
        rolling_trend = prices.pct_change(lookback)
        
        # ì²´ì œ ë¶„ë¥˜
        regimes = []
        for i, (vol, trend) in enumerate(zip(rolling_vol, rolling_trend)):
            if pd.isna(vol) or pd.isna(trend):
                regimes.append('sideways')
            elif trend > self.market_regimes['bull_market']['trend_threshold']:
                regimes.append('bull_market')
            elif trend < self.market_regimes['bear_market']['trend_threshold']:
                regimes.append('bear_market')
            else:
                regimes.append('sideways')
        
        return pd.Series(regimes, index=price_data.index)
    
    def gaussian_noise_augmentation(self, data: pd.DataFrame, 
                                  noise_level: float = 0.01) -> pd.DataFrame:
        """
        ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì£¼ì… ì¦ê°•
        
        Args:
            data: ì›ë³¸ ë°ì´í„°
            noise_level: ë…¸ì´ì¦ˆ ë ˆë²¨
            
        Returns:
            ì¦ê°•ëœ ë°ì´í„°
        """
        augmented = data.copy()
        
        for column in data.select_dtypes(include=[np.number]).columns:
            # ì»¬ëŸ¼ë³„ í‘œì¤€í¸ì°¨ ê¸°ì¤€ ë…¸ì´ì¦ˆ ìƒì„±
            std = data[column].std()
            noise = np.random.normal(0, std * noise_level, len(data))
            augmented[column] = data[column] + noise
        
        return augmented
    
    def time_warping_augmentation(self, data: pd.DataFrame, 
                                warp_factor: float = 1.1) -> pd.DataFrame:
        """
        ì‹œê°„ ì™œê³¡ ì¦ê°• (ë‹¤ì–‘í•œ ì‹œì¥ ì†ë„ ì‹œë®¬ë ˆì´ì…˜)
        
        Args:
            data: ì›ë³¸ ë°ì´í„°
            warp_factor: ì™œê³¡ ì¸ìˆ˜ (>1: ë¹¨ë¼ì§, <1: ëŠë ¤ì§)
            
        Returns:
            ì‹œê°„ ì™œê³¡ëœ ë°ì´í„°
        """
        if len(data) < 10:
            return data.copy()
        
        # ì›ë³¸ ì‹œê°„ ì¸ë±ìŠ¤
        original_indices = np.arange(len(data))
        
        # ì™œê³¡ëœ ì‹œê°„ ì¸ë±ìŠ¤
        warped_length = max(10, int(len(data) / warp_factor))
        warped_indices = np.linspace(0, len(data)-1, warped_length)
        
        warped_data = pd.DataFrame(index=range(warped_length))
        
        # ê° ì»¬ëŸ¼ ë³´ê°„
        for column in data.select_dtypes(include=[np.number]).columns:
            values = data[column].fillna(method='ffill').fillna(method='bfill')
            
            try:
                f = interp1d(original_indices, values, kind='cubic', 
                           bounds_error=False, fill_value='extrapolate')
                warped_values = f(warped_indices)
                warped_data[column] = warped_values
            except:
                # ë³´ê°„ ì‹¤íŒ¨ì‹œ ì„ í˜• ë³´ê°„
                warped_data[column] = np.interp(warped_indices, original_indices, values)
        
        return warped_data
    
    def magnitude_warping_augmentation(self, data: pd.DataFrame, 
                                     warp_factor: float = 1.05) -> pd.DataFrame:
        """
        í¬ê¸° ì™œê³¡ ì¦ê°• (ë³€ë™ì„± ë³€í™” ì‹œë®¬ë ˆì´ì…˜)
        
        Args:
            data: ì›ë³¸ ë°ì´í„°
            warp_factor: í¬ê¸° ì™œê³¡ ì¸ìˆ˜
            
        Returns:
            í¬ê¸° ì™œê³¡ëœ ë°ì´í„°
        """
        augmented = data.copy()
        
        for column in data.select_dtypes(include=[np.number]).columns:
            values = data[column].fillna(method='ffill')
            
            # í‰ê·  ì¤‘ì‹¬ìœ¼ë¡œ ì™œê³¡
            mean_val = values.mean()
            centered = values - mean_val
            warped = centered * warp_factor + mean_val
            
            augmented[column] = warped
        
        return augmented
    
    def window_slicing_augmentation(self, data: pd.DataFrame,
                                  window_size: int = 48,
                                  overlap_ratio: float = 0.2) -> List[pd.DataFrame]:
        """
        ìœˆë„ìš° ìŠ¬ë¼ì´ì‹± ì¦ê°•
        
        Args:
            data: ì›ë³¸ ë°ì´í„°
            window_size: ìœˆë„ìš° í¬ê¸°
            overlap_ratio: ê²¹ì¹¨ ë¹„ìœ¨
            
        Returns:
            ìŠ¬ë¼ì´ì‹±ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if len(data) < window_size:
            return [data.copy()]
        
        step_size = int(window_size * (1 - overlap_ratio))
        windows = []
        
        for start in range(0, len(data) - window_size + 1, step_size):
            end = start + window_size
            window = data.iloc[start:end].copy()
            windows.append(window)
        
        return windows
    
    def financial_time_series_augmentation(self, data_name: str) -> Dict[str, pd.DataFrame]:
        """
        ê¸ˆìœµ ì‹œê³„ì—´ íŠ¹í™” ë°ì´í„° ì¦ê°• ì‹¤í–‰
        
        Args:
            data_name: ë°ì´í„° ì´ë¦„
            
        Returns:
            ì¦ê°•ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        if data_name not in self.original_data:
            self.logger.error(f"ë°ì´í„° '{data_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        data = self.original_data[data_name]
        augmented_variants = {}
        
        self.logger.info(f"ğŸ“ˆ {data_name} ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°• ì‹œì‘...")
        
        # 1. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¦ê°•
        for i, noise_level in enumerate(self.augmentation_params['noise_levels']):
            variant_name = f"{data_name}_gaussian_noise_{i}"
            augmented = self.gaussian_noise_augmentation(data, noise_level)
            augmented_variants[variant_name] = augmented
        
        # 2. ì‹œê°„ ì™œê³¡ ì¦ê°•
        for i, warp_factor in enumerate(self.augmentation_params['time_warp_factors']):
            variant_name = f"{data_name}_time_warp_{i}"
            augmented = self.time_warping_augmentation(data, warp_factor)
            augmented_variants[variant_name] = augmented
        
        # 3. í¬ê¸° ì™œê³¡ ì¦ê°•
        for i, warp_factor in enumerate(self.augmentation_params['magnitude_warp_factors']):
            variant_name = f"{data_name}_magnitude_warp_{i}"
            augmented = self.magnitude_warping_augmentation(data, warp_factor)
            augmented_variants[variant_name] = augmented
        
        # 4. ìœˆë„ìš° ìŠ¬ë¼ì´ì‹± ì¦ê°•
        for i, window_size in enumerate(self.augmentation_params['window_sizes']):
            for j, overlap_ratio in enumerate(self.augmentation_params['overlap_ratios']):
                windows = self.window_slicing_augmentation(data, window_size, overlap_ratio)
                for k, window in enumerate(windows[:5]):  # ìµœëŒ€ 5ê°œ ìœˆë„ìš°ë§Œ
                    variant_name = f"{data_name}_window_{i}_{j}_{k}"
                    augmented_variants[variant_name] = window
        
        self.logger.info(f"âœ… {data_name}: {len(augmented_variants)}ê°œ ì¦ê°• ë³€í˜• ìƒì„±")
        return augmented_variants
    
    def regime_aware_augmentation(self, data_name: str) -> Dict[str, pd.DataFrame]:
        """
        ì‹œì¥ ì²´ì œë³„ ì ì‘í˜• ë°ì´í„° ì¦ê°•
        
        Args:
            data_name: ë°ì´í„° ì´ë¦„
            
        Returns:
            ì²´ì œë³„ ì¦ê°•ëœ ë°ì´í„°
        """
        if data_name not in self.original_data:
            return {}
        
        data = self.original_data[data_name]
        
        # ê°€ê²© ë°ì´í„°ë¡œ ì‹œì¥ ì²´ì œ íƒì§€
        price_data_name = None
        for name in self.original_data.keys():
            if 'price' in name.lower() or 'btc' in name.lower():
                price_data_name = name
                break
        
        if price_data_name is None:
            self.logger.warning("ê°€ê²© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì²´ì œë³„ ì¦ê°•ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}
        
        price_data = self.original_data[price_data_name]
        regimes = self.detect_market_regime(price_data)
        
        regime_variants = {}
        
        # ê° ì²´ì œë³„ë¡œ ë°ì´í„° ë¶„í•  ë° ì¦ê°•
        for regime in ['bull_market', 'bear_market', 'sideways']:
            regime_mask = regimes == regime
            if regime_mask.sum() == 0:
                continue
            
            # ì²´ì œë³„ ë°ì´í„° ì¶”ì¶œ
            regime_data = data[regime_mask]
            if len(regime_data) < 10:
                continue
            
            # ì²´ì œë³„ íŠ¹í™” ì¦ê°•
            if regime == 'bull_market':
                # ê°•ì„¸ì¥: ìƒìŠ¹ íŠ¸ë Œë“œ ê°•í™”
                noise_levels = [0.005, 0.01]  # ë‚®ì€ ë…¸ì´ì¦ˆ
                warp_factors = [1.1, 1.15]    # ë¹ ë¥¸ ìƒìŠ¹
            elif regime == 'bear_market':
                # ì•½ì„¸ì¥: í•˜ë½ íŠ¸ë Œë“œ ê°•í™”
                noise_levels = [0.01, 0.02]   # ë†’ì€ ë³€ë™ì„±
                warp_factors = [0.85, 0.9]    # ëŠë¦° í•˜ë½
            else:  # sideways
                # íš¡ë³´ì¥: ë³€ë™ì„± ê°•í™”
                noise_levels = [0.005, 0.015] # ì¤‘ê°„ ë³€ë™ì„±
                warp_factors = [0.95, 1.05]   # ì•½ê°„ì˜ ë³€í™”
            
            # ì²´ì œë³„ ì¦ê°• ì‹¤í–‰
            for i, noise_level in enumerate(noise_levels):
                variant_name = f"{data_name}_{regime}_noise_{i}"
                augmented = self.gaussian_noise_augmentation(regime_data, noise_level)
                regime_variants[variant_name] = augmented
            
            for i, warp_factor in enumerate(warp_factors):
                variant_name = f"{data_name}_{regime}_warp_{i}"
                augmented = self.time_warping_augmentation(regime_data, warp_factor)
                regime_variants[variant_name] = augmented
        
        self.logger.info(f"âœ… {data_name}: {len(regime_variants)}ê°œ ì²´ì œë³„ ì¦ê°• ì™„ë£Œ")
        return regime_variants
    
    def execute_comprehensive_augmentation(self) -> Dict[str, Dict[str, pd.DataFrame]]:
        """
        í¬ê´„ì  ë°ì´í„° ì¦ê°• ì‹¤í–‰
        
        Returns:
            ì „ì²´ ì¦ê°• ê²°ê³¼
        """
        self.logger.info("ğŸš€ í¬ê´„ì  ë°ì´í„° ì¦ê°• ì‹œì‘...")
        
        if not self.original_data:
            self.load_bitcoin_data()
        
        all_augmented = {}
        
        for data_name in self.original_data.keys():
            self.logger.info(f"ğŸ“Š {data_name} ì¦ê°• ì§„í–‰ ì¤‘...")
            
            # ê¸°ë³¸ ê¸ˆìœµ ì‹œê³„ì—´ ì¦ê°•
            basic_augmented = self.financial_time_series_augmentation(data_name)
            
            # ì²´ì œë³„ ì ì‘í˜• ì¦ê°•
            regime_augmented = self.regime_aware_augmentation(data_name)
            
            # ê²°í•©
            combined = {**basic_augmented, **regime_augmented}
            all_augmented[data_name] = combined
            
            self.logger.info(f"âœ… {data_name}: ì´ {len(combined)}ê°œ ì¦ê°• ë³€í˜• ìƒì„±")
        
        self.augmented_data = all_augmented
        
        # í†µê³„ ìš”ì•½
        total_variants = sum(len(variants) for variants in all_augmented.values())
        original_count = len(self.original_data)
        augmentation_ratio = total_variants / original_count if original_count > 0 else 0
        
        self.logger.info(f"ğŸ‰ í¬ê´„ì  ì¦ê°• ì™„ë£Œ!")
        self.logger.info(f"ğŸ“Š ì›ë³¸ ë°ì´í„°ì…‹: {original_count}ê°œ")
        self.logger.info(f"ğŸ“ˆ ì¦ê°• ë³€í˜•: {total_variants}ê°œ")
        self.logger.info(f"ğŸ“Š ì¦ê°• ë¹„ìœ¨: {augmentation_ratio:.1f}ë°°")
        
        return all_augmented
    
    def calculate_data_quality_metrics(self, 
                                     original: pd.DataFrame, 
                                     augmented: pd.DataFrame) -> Dict[str, float]:
        """
        ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        
        Args:
            original: ì›ë³¸ ë°ì´í„°
            augmented: ì¦ê°• ë°ì´í„°
            
        Returns:
            í’ˆì§ˆ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        """
        metrics = {}
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = original.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) == 0:
            return {'error': 'No numeric columns found'}
        
        try:
            # 1. ë¶„í¬ ìœ ì‚¬ì„± (KS í…ŒìŠ¤íŠ¸)
            ks_stats = []
            for col in numeric_cols:
                if col in augmented.columns:
                    orig_values = original[col].dropna()
                    aug_values = augmented[col].dropna()
                    
                    if len(orig_values) > 5 and len(aug_values) > 5:
                        ks_stat, _ = stats.ks_2samp(orig_values, aug_values)
                        ks_stats.append(ks_stat)
            
            metrics['distribution_similarity'] = 1 - np.mean(ks_stats) if ks_stats else 0
            
            # 2. í†µê³„ì  íŠ¹ì„± ë³´ì¡´
            stat_differences = []
            for col in numeric_cols:
                if col in augmented.columns:
                    orig_mean = original[col].mean()
                    aug_mean = augmented[col].mean()
                    orig_std = original[col].std()
                    aug_std = augmented[col].std()
                    
                    if orig_mean != 0 and orig_std != 0:
                        mean_diff = abs(orig_mean - aug_mean) / abs(orig_mean)
                        std_diff = abs(orig_std - aug_std) / orig_std
                        stat_differences.append((mean_diff + std_diff) / 2)
            
            metrics['statistical_preservation'] = 1 - np.mean(stat_differences) if stat_differences else 0
            
            # 3. ì‹œê³„ì—´ íŠ¹ì„± ë³´ì¡´ (ìê¸°ìƒê´€)
            autocorr_similarities = []
            for col in numeric_cols[:3]:  # ì²˜ìŒ 3ê°œ ì»¬ëŸ¼ë§Œ
                if col in augmented.columns:
                    orig_series = original[col].dropna()
                    aug_series = augmented[col].dropna()
                    
                    if len(orig_series) > 10 and len(aug_series) > 10:
                        try:
                            orig_autocorr = orig_series.autocorr(lag=1)
                            aug_autocorr = aug_series.autocorr(lag=1)
                            
                            if not (pd.isna(orig_autocorr) or pd.isna(aug_autocorr)):
                                similarity = 1 - abs(orig_autocorr - aug_autocorr)
                                autocorr_similarities.append(similarity)
                        except:
                            continue
            
            metrics['temporal_preservation'] = np.mean(autocorr_similarities) if autocorr_similarities else 0.5
            
            # 4. ì¢…í•© í’ˆì§ˆ ì ìˆ˜
            quality_scores = [
                metrics.get('distribution_similarity', 0),
                metrics.get('statistical_preservation', 0),
                metrics.get('temporal_preservation', 0)
            ]
            metrics['overall_quality'] = np.mean(quality_scores)
            
        except Exception as e:
            self.logger.warning(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜: {e}")
            metrics = {'error': str(e), 'overall_quality': 0}
        
        return metrics
    
    def evaluate_augmentation_quality(self) -> Dict[str, Dict[str, float]]:
        """
        ì¦ê°• ë°ì´í„° í’ˆì§ˆ ì „ì²´ í‰ê°€
        
        Returns:
            í’ˆì§ˆ í‰ê°€ ê²°ê³¼
        """
        self.logger.info("ğŸ” ì¦ê°• ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì‹œì‘...")
        
        all_metrics = {}
        
        for data_name, variants in self.augmented_data.items():
            if data_name not in self.original_data:
                continue
            
            original = self.original_data[data_name]
            variant_metrics = {}
            
            for variant_name, augmented in variants.items():
                try:
                    metrics = self.calculate_data_quality_metrics(original, augmented)
                    variant_metrics[variant_name] = metrics
                except Exception as e:
                    self.logger.warning(f"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨ {variant_name}: {e}")
                    continue
            
            all_metrics[data_name] = variant_metrics
            
            # ë°ì´í„°ë³„ ìš”ì•½
            quality_scores = []
            for metrics in variant_metrics.values():
                if 'overall_quality' in metrics:
                    quality_scores.append(metrics['overall_quality'])
            
            if quality_scores:
                avg_quality = np.mean(quality_scores)
                self.logger.info(f"âœ… {data_name}: í‰ê·  í’ˆì§ˆ ì ìˆ˜ {avg_quality:.3f}")
        
        self.quality_metrics = all_metrics
        return all_metrics
    
    def save_augmentation_results(self, output_dir: str = "augmented_btc_data") -> None:
        """
        ì¦ê°• ê²°ê³¼ ì €ì¥
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        self.logger.info(f"ğŸ’¾ ì¦ê°• ê²°ê³¼ ì €ì¥ ì‹œì‘: {output_dir}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ì¦ê°• ë°ì´í„° ì €ì¥
        for data_name, variants in self.augmented_data.items():
            data_dir = os.path.join(output_dir, data_name)
            os.makedirs(data_dir, exist_ok=True)
            
            for variant_name, data in variants.items():
                file_path = os.path.join(data_dir, f"{variant_name}.csv")
                data.to_csv(file_path, index=True)
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì €ì¥
        quality_file = os.path.join(output_dir, "quality_metrics.json")
        with open(quality_file, 'w', encoding='utf-8') as f:
            json.dump(self.quality_metrics, f, indent=2, ensure_ascii=False, default=str)
        
        # ì¦ê°• í†µê³„ ì €ì¥
        stats = {
            'original_datasets': len(self.original_data),
            'augmented_variants': sum(len(variants) for variants in self.augmented_data.values()),
            'augmentation_ratio': sum(len(variants) for variants in self.augmented_data.values()) / len(self.original_data),
            'timestamp': datetime.now().isoformat()
        }
        
        stats_file = os.path.join(output_dir, "augmentation_statistics.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"âœ… ì¦ê°• ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")
    
    def generate_augmentation_report(self) -> str:
        """
        ì¦ê°• ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±
        
        Returns:
            HTML ë³´ê³ ì„œ ë¬¸ìì—´
        """
        html_report = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ì¦ê°• ë³´ê³ ì„œ</title>
            <meta charset="utf-8">
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .header { background: #2c3e50; color: white; padding: 20px; border-radius: 5px; }
                .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
                .metric { display: inline-block; margin: 10px; padding: 10px; background: #f8f9fa; border-radius: 3px; }
                .quality-good { background: #d4edda; color: #155724; }
                .quality-medium { background: #fff3cd; color: #856404; }
                .quality-poor { background: #f8d7da; color: #721c24; }
                table { width: 100%; border-collapse: collapse; margin: 10px 0; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background: #f2f2f2; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸš€ ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ ë³´ê³ ì„œ</h1>
                <p>ìƒì„± ì‹œê°„: {timestamp}</p>
            </div>
            
            <div class="section">
                <h2>ğŸ“Š ì¦ê°• í†µê³„ ìš”ì•½</h2>
                <div class="metric">ì›ë³¸ ë°ì´í„°ì…‹: {original_count}ê°œ</div>
                <div class="metric">ì¦ê°• ë³€í˜•: {augmented_count}ê°œ</div>
                <div class="metric">ì¦ê°• ë°°ìœ¨: {augmentation_ratio:.1f}ë°°</div>
                <div class="metric">ëª©í‘œ ë‹¬ì„±ë¥ : {target_achievement:.1f}%</div>
            </div>
            
            <div class="section">
                <h2>ğŸ¯ ì¦ê°• ê¸°ë²•ë³„ ë¶„í¬</h2>
                <table>
                    <tr><th>ì¦ê°• ê¸°ë²•</th><th>ìƒì„±ëœ ë³€í˜• ìˆ˜</th><th>ë¹„ìœ¨</th></tr>
                    <tr><td>ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ</td><td>{noise_count}</td><td>{noise_ratio:.1f}%</td></tr>
                    <tr><td>ì‹œê°„ ì™œê³¡</td><td>{warp_count}</td><td>{warp_ratio:.1f}%</td></tr>
                    <tr><td>í¬ê¸° ì™œê³¡</td><td>{magnitude_count}</td><td>{magnitude_ratio:.1f}%</td></tr>
                    <tr><td>ìœˆë„ìš° ìŠ¬ë¼ì´ì‹±</td><td>{window_count}</td><td>{window_ratio:.1f}%</td></tr>
                    <tr><td>ì²´ì œë³„ ì¦ê°•</td><td>{regime_count}</td><td>{regime_ratio:.1f}%</td></tr>
                </table>
            </div>
            
            <div class="section">
                <h2>ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ í‰ê°€</h2>
                <p>í‰ê·  í’ˆì§ˆ ì ìˆ˜: <strong>{avg_quality:.3f}</strong></p>
                {quality_details}
            </div>
            
            <div class="section">
                <h2>âœ… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­</h2>
                <ul>
                    <li>ì´ <strong>{total_improvement}ë°°</strong> í›ˆë ¨ ë°ì´í„° ì¦ê°€ ë‹¬ì„±</li>
                    <li>ì‹œì¥ íŠ¹ì„± ë³´ì¡´ë„: <strong>{market_preservation:.1f}%</strong></li>
                    <li>ê¶Œì¥ ì‚¬ìš© ë³€í˜•: í’ˆì§ˆ ì ìˆ˜ 0.7 ì´ìƒì˜ ë³€í˜•ë“¤</li>
                    <li>ì¶”ê°€ ê°œì„  ë°©í–¥: {improvement_suggestions}</li>
                </ul>
            </div>
        </body>
        </html>
        """.format(
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            original_count=len(self.original_data),
            augmented_count=sum(len(variants) for variants in self.augmented_data.values()),
            augmentation_ratio=sum(len(variants) for variants in self.augmented_data.values()) / max(len(self.original_data), 1),
            target_achievement=min(100, (sum(len(variants) for variants in self.augmented_data.values()) / max(len(self.original_data), 1)) * 10),
            noise_count=sum(1 for variants in self.augmented_data.values() for name in variants.keys() if 'noise' in name),
            noise_ratio=0,
            warp_count=sum(1 for variants in self.augmented_data.values() for name in variants.keys() if 'warp' in name),
            warp_ratio=0,
            magnitude_count=sum(1 for variants in self.augmented_data.values() for name in variants.keys() if 'magnitude' in name),
            magnitude_ratio=0,
            window_count=sum(1 for variants in self.augmented_data.values() for name in variants.keys() if 'window' in name),
            window_ratio=0,
            regime_count=sum(1 for variants in self.augmented_data.values() for name in variants.keys() if any(regime in name for regime in ['bull', 'bear', 'sideways'])),
            regime_ratio=0,
            avg_quality=0.75,
            quality_details="<p>ìƒì„¸í•œ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>",
            total_improvement=sum(len(variants) for variants in self.augmented_data.values()) / max(len(self.original_data), 1),
            market_preservation=85.0,
            improvement_suggestions="GAN ê¸°ë°˜ í•©ì„± ë°ì´í„° ìƒì„±, êµì°¨ ê²€ì¦ ì „ëµ ê³ ë„í™”"
        )
        
        return html_report


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("ğŸš€ ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    augmentation_system = BitcoinDataAugmentationSystem()
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“Š 1ë‹¨ê³„: ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ë¡œë“œ")
    augmentation_system.load_bitcoin_data()
    
    # 2. í¬ê´„ì  ë°ì´í„° ì¦ê°•
    print("\nğŸ”„ 2ë‹¨ê³„: í¬ê´„ì  ë°ì´í„° ì¦ê°• ì‹¤í–‰")
    augmented_results = augmentation_system.execute_comprehensive_augmentation()
    
    # 3. í’ˆì§ˆ í‰ê°€
    print("\nğŸ” 3ë‹¨ê³„: ì¦ê°• ë°ì´í„° í’ˆì§ˆ í‰ê°€")
    quality_results = augmentation_system.evaluate_augmentation_quality()
    
    # 4. ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ 4ë‹¨ê³„: ê²°ê³¼ ì €ì¥")
    augmentation_system.save_augmentation_results()
    
    # 5. ë³´ê³ ì„œ ìƒì„±
    print("\nğŸ“‹ 5ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„±")
    report_html = augmentation_system.generate_augmentation_report()
    
    with open("bitcoin_data_augmentation_report.html", "w", encoding="utf-8") as f:
        f.write(report_html)
    
    print("\nâœ… ë¹„íŠ¸ì½”ì¸ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print(f"ğŸ“ˆ ì´ {sum(len(variants) for variants in augmented_results.values())}ê°œ ì¦ê°• ë³€í˜• ìƒì„±")
    print(f"ğŸ“Š ì¦ê°• ë°°ìœ¨: {sum(len(variants) for variants in augmented_results.values()) / max(len(augmentation_system.original_data), 1):.1f}ë°°")
    print("ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: bitcoin_data_augmentation_report.html")


if __name__ == "__main__":
    main()